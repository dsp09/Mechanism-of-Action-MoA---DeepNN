{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smishr97/Mechanism-of-Action-MoA---DeepNN/blob/main/GPU_MoA_Optimizing_NN_(using_Optuna).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukNZReOC73SZ",
        "outputId": "5754a848-73f6-4b48-9a1d-f4128a4aef29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting iterative-stratification\n",
            "  Downloading iterative_stratification-0.1.7-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from iterative-stratification) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->iterative-stratification) (1.0.1)\n",
            "Installing collected packages: iterative-stratification\n",
            "Successfully installed iterative-stratification-0.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install iterative-stratification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CX5JmE_nanj"
      },
      "source": [
        "**KAGGLE - Download the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7L3nq_J8XmC",
        "outputId": "fc92fc4e-0be0-4d55-e5ec-92ea11aa7536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading train_targets_scored.csv.zip to /content\n",
            "  0% 0.00/257k [00:00<?, ?B/s]\n",
            "100% 257k/257k [00:00<00:00, 35.1MB/s]\n",
            "Downloading train_targets_nonscored.csv.zip to /content\n",
            "  0% 0.00/233k [00:00<?, ?B/s]\n",
            "100% 233k/233k [00:00<00:00, 70.3MB/s]\n",
            "Downloading train_features.csv.zip to /content\n",
            " 77% 42.0M/54.8M [00:00<00:00, 53.7MB/s]\n",
            "100% 54.8M/54.8M [00:00<00:00, 86.4MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/38.9k [00:00<?, ?B/s]\n",
            "100% 38.9k/38.9k [00:00<00:00, 34.1MB/s]\n",
            "Downloading test_features.csv.zip to /content\n",
            "  0% 0.00/9.16M [00:00<?, ?B/s]\n",
            "100% 9.16M/9.16M [00:00<00:00, 83.6MB/s]\n",
            "Downloading train_drug.csv to /content\n",
            "  0% 0.00/535k [00:00<?, ?B/s]\n",
            "100% 535k/535k [00:00<00:00, 176MB/s]\n",
            "usage: kaggle config set [-h] -n NAME -v VALUE\n",
            "kaggle config set: error: argument -v/--value is required\n",
            "Archive:  sample_submission.csv.zip\n",
            "  inflating: sample_submission.csv   \n",
            "Archive:  train_features.csv.zip\n",
            "  inflating: train_features.csv      \n",
            "Archive:  train_targets_nonscored.csv.zip\n",
            "  inflating: train_targets_nonscored.csv  \n",
            "Archive:  train_drug.csv\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of train_drug.csv or\n",
            "        train_drug.csv.zip, and cannot find train_drug.csv.ZIP, period.\n",
            "Archive:  train_targets_scored.csv.zip\n",
            "  inflating: train_targets_scored.csv  \n",
            "Archive:  test_features.csv.zip\n",
            "  inflating: test_features.csv       \n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c lish-moa\n",
        "! kaggle config set -n iterativestratification\n",
        "! unzip sample_submission.csv.zip\n",
        "! unzip train_features.csv.zip\n",
        "! unzip train_targets_nonscored.csv.zip\n",
        "! unzip train_drug.csv\n",
        "! unzip train_targets_scored.csv.zip\n",
        "! unzip test_features.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nPMu4lgk79JO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "if __name__ == \"__main__\":\n",
        "    TARGET_PATH = \"/content/train_targets_scored.csv\"\n",
        "    df = pd.read_csv(TARGET_PATH)\n",
        "    df.loc[:, 'kfold'] = -1\n",
        "    targets = df.drop(\"sig_id\", axis=1).values\n",
        "\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=5)\n",
        "\n",
        "    for fold, (train_idx, valid_idx) in enumerate(mskf.split(X=df, y=targets)):\n",
        "        df.loc[valid_idx, 'kfold'] = fold\n",
        "\n",
        "    df.to_csv(\"/content/train_targets_fold.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EILZhHr_8ttB",
        "outputId": "b81237a3-012a-4f13-b8d7-e7bec08ee82f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.4-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.9.0-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.5.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.2.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.4.0-py3-none-any.whl (20 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.2.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.2.1)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.6.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 44.4 MB/s \n",
            "\u001b[?25hCollecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11136 sha256=cc00434ad75723ee014507ff981f45fcb6d396d323431d4bdfbd38828072ea0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, colorama, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.5 alembic-1.7.4 autopage-0.4.0 cliff-3.9.0 cmaes-0.8.2 cmd2-2.2.0 colorama-0.4.4 colorlog-6.5.0 optuna-2.10.0 pbr-5.6.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "! pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yAHfhxMkJSdO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MoaDataset:\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return {\n",
        "            \"x\" : torch.tensor(self.features[item, :], dtype=torch.float32),\n",
        "            \"y\": torch.tensor(self.targets[item, :], dtype=torch.float32),\n",
        "        }\n",
        "\n",
        "# Engine class is use for evaluating and training\n",
        "class Engine:\n",
        "    def __init__(self, model, optimizer, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    @staticmethod\n",
        "    def loss_fn(targets, outputs):\n",
        "        return nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "\n",
        "    # Training functions\n",
        "    def train(self, data_loader):\n",
        "        self.model.train()\n",
        "        final_loss = 0\n",
        "        for data in data_loader:\n",
        "            self.optimizer.zero_grad()\n",
        "            inputs = data[\"x\"].to(self.device)\n",
        "            targets = data[\"y\"].to(self.device)\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss_fn(targets, outputs)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            final_loss += loss.item()\n",
        "        return final_loss / len(data_loader)\n",
        "\n",
        "    # Evaluating function\n",
        "    def evaluate(self, data_loader):\n",
        "        self.model.eval()\n",
        "        final_loss = 0\n",
        "        for data in data_loader:\n",
        "            inputs = data[\"x\"].to(self.device)\n",
        "            targets = data[\"y\"].to(self.device)\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss_fn(targets, outputs)\n",
        "            final_loss += loss.item()\n",
        "        return final_loss / len(data_loader)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, num_features, num_targets, hidden_size, num_layers, dropout):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        for _ in range(num_layers):\n",
        "            if len(layers) == 0:\n",
        "                layers.append(nn.Linear(num_features, hidden_size))\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "                layers.append(nn.ReLU())\n",
        "            else:\n",
        "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "                \n",
        "                layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "                layers.append(nn.BatchNorm1d(hidden_size))\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "                layers.append(nn.ReLU())\n",
        "\n",
        "        layers.append(nn.Linear(hidden_size, num_targets))\n",
        "        self.model = nn.Sequential(*layers)   # Layers in the list\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLG0MAJnKHgB",
        "outputId": "e3f0e350-9e17-4d5e-dc62-9620212a1733"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-11-01 13:30:41,217]\u001b[0m A new study created in memory with name: no-name-510bb59c-5bb7-4bfa-8553-582b5870b4ee\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 0, EPOCH : 0, TRAIN_LOSS : 0.4040809022752862, VALIDATION_LOSS : 0.3319945454597473\n",
            "FOLD : 0, EPOCH : 1, TRAIN_LOSS : 0.10106267446750089, VALIDATION_LOSS : 0.026108254119753836\n",
            "FOLD : 0, EPOCH : 2, TRAIN_LOSS : 0.038867049213302765, VALIDATION_LOSS : 0.02504754178225994\n",
            "FOLD : 0, EPOCH : 3, TRAIN_LOSS : 0.02663332488583891, VALIDATION_LOSS : 0.021101005002856256\n",
            "FOLD : 0, EPOCH : 4, TRAIN_LOSS : 0.023859893903136253, VALIDATION_LOSS : 0.022065461799502372\n",
            "FOLD : 0, EPOCH : 5, TRAIN_LOSS : 0.022614449556720883, VALIDATION_LOSS : 0.021850796416401863\n",
            "FOLD : 0, EPOCH : 6, TRAIN_LOSS : 0.02179811649808758, VALIDATION_LOSS : 0.02145155519247055\n",
            "FOLD : 0, EPOCH : 7, TRAIN_LOSS : 0.021151708537026456, VALIDATION_LOSS : 0.020864711701869966\n",
            "FOLD : 0, EPOCH : 8, TRAIN_LOSS : 0.020715935645919097, VALIDATION_LOSS : 0.02048543095588684\n",
            "FOLD : 0, EPOCH : 9, TRAIN_LOSS : 0.020340132085900558, VALIDATION_LOSS : 0.020109176635742188\n",
            "FOLD : 0, EPOCH : 10, TRAIN_LOSS : 0.020020980485960058, VALIDATION_LOSS : 0.019836585223674773\n",
            "FOLD : 0, EPOCH : 11, TRAIN_LOSS : 0.019820914750820713, VALIDATION_LOSS : 0.01968686208128929\n",
            "FOLD : 0, EPOCH : 12, TRAIN_LOSS : 0.01954308426693866, VALIDATION_LOSS : 0.019561226665973663\n",
            "FOLD : 0, EPOCH : 13, TRAIN_LOSS : 0.019281274982188876, VALIDATION_LOSS : 0.01929212436079979\n",
            "FOLD : 0, EPOCH : 14, TRAIN_LOSS : 0.019024536111637166, VALIDATION_LOSS : 0.018940754234790802\n",
            "FOLD : 0, EPOCH : 15, TRAIN_LOSS : 0.01869196307502295, VALIDATION_LOSS : 0.018770848214626313\n",
            "FOLD : 0, EPOCH : 16, TRAIN_LOSS : 0.01841740604293974, VALIDATION_LOSS : 0.018283004686236382\n",
            "FOLD : 0, EPOCH : 17, TRAIN_LOSS : 0.018062897908844446, VALIDATION_LOSS : 0.018062706291675567\n",
            "FOLD : 0, EPOCH : 18, TRAIN_LOSS : 0.01781372373041354, VALIDATION_LOSS : 0.017827645316720007\n",
            "FOLD : 0, EPOCH : 19, TRAIN_LOSS : 0.017548280424977605, VALIDATION_LOSS : 0.017592234164476396\n",
            "FOLD : 0, EPOCH : 20, TRAIN_LOSS : 0.017343892274718536, VALIDATION_LOSS : 0.017443624883890153\n",
            "FOLD : 0, EPOCH : 21, TRAIN_LOSS : 0.017107760827792317, VALIDATION_LOSS : 0.01732260175049305\n",
            "FOLD : 0, EPOCH : 22, TRAIN_LOSS : 0.016938524516789538, VALIDATION_LOSS : 0.017146633192896842\n",
            "FOLD : 0, EPOCH : 23, TRAIN_LOSS : 0.01677173709398822, VALIDATION_LOSS : 0.0170494444668293\n",
            "FOLD : 0, EPOCH : 24, TRAIN_LOSS : 0.016586420763480037, VALIDATION_LOSS : 0.016956777125597\n",
            "FOLD : 0, EPOCH : 25, TRAIN_LOSS : 0.0164480126021724, VALIDATION_LOSS : 0.016888483241200448\n",
            "FOLD : 0, EPOCH : 26, TRAIN_LOSS : 0.016323339390127284, VALIDATION_LOSS : 0.016765961050987245\n",
            "FOLD : 0, EPOCH : 27, TRAIN_LOSS : 0.01618486628132431, VALIDATION_LOSS : 0.016779271140694618\n",
            "FOLD : 0, EPOCH : 28, TRAIN_LOSS : 0.01608350961224029, VALIDATION_LOSS : 0.016615786030888556\n",
            "FOLD : 0, EPOCH : 29, TRAIN_LOSS : 0.015940648209499687, VALIDATION_LOSS : 0.016558948904275894\n",
            "FOLD : 0, EPOCH : 30, TRAIN_LOSS : 0.015823889719812495, VALIDATION_LOSS : 0.01650486998260021\n",
            "FOLD : 0, EPOCH : 31, TRAIN_LOSS : 0.015716319609629482, VALIDATION_LOSS : 0.01643270254135132\n",
            "FOLD : 0, EPOCH : 32, TRAIN_LOSS : 0.015540833388896365, VALIDATION_LOSS : 0.01642245277762413\n",
            "FOLD : 0, EPOCH : 33, TRAIN_LOSS : 0.0154206473870497, VALIDATION_LOSS : 0.016397830843925477\n",
            "FOLD : 0, EPOCH : 34, TRAIN_LOSS : 0.015332913859502265, VALIDATION_LOSS : 0.016260597109794616\n",
            "FOLD : 0, EPOCH : 35, TRAIN_LOSS : 0.015157125056966356, VALIDATION_LOSS : 0.01633480191230774\n",
            "FOLD : 0, EPOCH : 36, TRAIN_LOSS : 0.015031130347204836, VALIDATION_LOSS : 0.01632184199988842\n",
            "FOLD : 0, EPOCH : 37, TRAIN_LOSS : 0.014846070032370718, VALIDATION_LOSS : 0.016365379467606543\n",
            "FOLD : 0, EPOCH : 38, TRAIN_LOSS : 0.01469331548402184, VALIDATION_LOSS : 0.0163958664983511\n",
            "FOLD : 0, EPOCH : 39, TRAIN_LOSS : 0.014560932538619167, VALIDATION_LOSS : 0.016305792704224588\n",
            "FOLD : 0, EPOCH : 40, TRAIN_LOSS : 0.014365012659446189, VALIDATION_LOSS : 0.016409773379564285\n",
            "FOLD : 0, EPOCH : 41, TRAIN_LOSS : 0.014204152712696478, VALIDATION_LOSS : 0.01644858568906784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 1, EPOCH : 0, TRAIN_LOSS : 0.3974768346861789, VALIDATION_LOSS : 0.34213905334472655\n",
            "FOLD : 1, EPOCH : 1, TRAIN_LOSS : 0.09994569009071902, VALIDATION_LOSS : 0.026289477199316024\n",
            "FOLD : 1, EPOCH : 2, TRAIN_LOSS : 0.038999615237116814, VALIDATION_LOSS : 0.024790650606155394\n",
            "FOLD : 1, EPOCH : 3, TRAIN_LOSS : 0.026557885894649906, VALIDATION_LOSS : 0.02087402492761612\n",
            "FOLD : 1, EPOCH : 4, TRAIN_LOSS : 0.023736826487277683, VALIDATION_LOSS : 0.021731382980942727\n",
            "FOLD : 1, EPOCH : 5, TRAIN_LOSS : 0.02249982668773124, VALIDATION_LOSS : 0.021721676364541052\n",
            "FOLD : 1, EPOCH : 6, TRAIN_LOSS : 0.021675664637433856, VALIDATION_LOSS : 0.021343250572681428\n",
            "FOLD : 1, EPOCH : 7, TRAIN_LOSS : 0.02110685202244081, VALIDATION_LOSS : 0.020780109986662864\n",
            "FOLD : 1, EPOCH : 8, TRAIN_LOSS : 0.02065186584858518, VALIDATION_LOSS : 0.020426512509584428\n",
            "FOLD : 1, EPOCH : 9, TRAIN_LOSS : 0.02030294261088497, VALIDATION_LOSS : 0.020069700479507447\n",
            "FOLD : 1, EPOCH : 10, TRAIN_LOSS : 0.02003007970358196, VALIDATION_LOSS : 0.019859984144568445\n",
            "FOLD : 1, EPOCH : 11, TRAIN_LOSS : 0.019747277525694745, VALIDATION_LOSS : 0.019653180614113808\n",
            "FOLD : 1, EPOCH : 12, TRAIN_LOSS : 0.01951453060303864, VALIDATION_LOSS : 0.019298747554421423\n",
            "FOLD : 1, EPOCH : 13, TRAIN_LOSS : 0.0192352334331525, VALIDATION_LOSS : 0.01924678459763527\n",
            "FOLD : 1, EPOCH : 14, TRAIN_LOSS : 0.019013114469616038, VALIDATION_LOSS : 0.01888287700712681\n",
            "FOLD : 1, EPOCH : 15, TRAIN_LOSS : 0.01877211691125443, VALIDATION_LOSS : 0.01872890256345272\n",
            "FOLD : 1, EPOCH : 16, TRAIN_LOSS : 0.018547219763460913, VALIDATION_LOSS : 0.01858203634619713\n",
            "FOLD : 1, EPOCH : 17, TRAIN_LOSS : 0.018270439125205342, VALIDATION_LOSS : 0.018114902079105377\n",
            "FOLD : 1, EPOCH : 18, TRAIN_LOSS : 0.01806217177133811, VALIDATION_LOSS : 0.017888188362121582\n",
            "FOLD : 1, EPOCH : 19, TRAIN_LOSS : 0.017827605436507025, VALIDATION_LOSS : 0.01780163012444973\n",
            "FOLD : 1, EPOCH : 20, TRAIN_LOSS : 0.017622002253406925, VALIDATION_LOSS : 0.01759946085512638\n",
            "FOLD : 1, EPOCH : 21, TRAIN_LOSS : 0.017401995039299914, VALIDATION_LOSS : 0.01747897043824196\n",
            "FOLD : 1, EPOCH : 22, TRAIN_LOSS : 0.01715511152226674, VALIDATION_LOSS : 0.01732296645641327\n",
            "FOLD : 1, EPOCH : 23, TRAIN_LOSS : 0.016933669973360866, VALIDATION_LOSS : 0.01703275851905346\n",
            "FOLD : 1, EPOCH : 24, TRAIN_LOSS : 0.016719782234806763, VALIDATION_LOSS : 0.016911737248301507\n",
            "FOLD : 1, EPOCH : 25, TRAIN_LOSS : 0.016574039663139143, VALIDATION_LOSS : 0.016787000000476837\n",
            "FOLD : 1, EPOCH : 26, TRAIN_LOSS : 0.016439212584181837, VALIDATION_LOSS : 0.01671627052128315\n",
            "FOLD : 1, EPOCH : 27, TRAIN_LOSS : 0.016289841579763514, VALIDATION_LOSS : 0.01672957092523575\n",
            "FOLD : 1, EPOCH : 28, TRAIN_LOSS : 0.01616340552113558, VALIDATION_LOSS : 0.016597025468945502\n",
            "FOLD : 1, EPOCH : 29, TRAIN_LOSS : 0.016031833218508644, VALIDATION_LOSS : 0.016527342796325683\n",
            "FOLD : 1, EPOCH : 30, TRAIN_LOSS : 0.01588561160391883, VALIDATION_LOSS : 0.016508563607931136\n",
            "FOLD : 1, EPOCH : 31, TRAIN_LOSS : 0.015758881296374296, VALIDATION_LOSS : 0.01645621322095394\n",
            "FOLD : 1, EPOCH : 32, TRAIN_LOSS : 0.015662540877728087, VALIDATION_LOSS : 0.016360877826809884\n",
            "FOLD : 1, EPOCH : 33, TRAIN_LOSS : 0.015513856258047255, VALIDATION_LOSS : 0.016352684795856477\n",
            "FOLD : 1, EPOCH : 34, TRAIN_LOSS : 0.015393081611316455, VALIDATION_LOSS : 0.01631101705133915\n",
            "FOLD : 1, EPOCH : 35, TRAIN_LOSS : 0.015276746579298848, VALIDATION_LOSS : 0.016266852989792822\n",
            "FOLD : 1, EPOCH : 36, TRAIN_LOSS : 0.015142470157068027, VALIDATION_LOSS : 0.016162322834134102\n",
            "FOLD : 1, EPOCH : 37, TRAIN_LOSS : 0.015030231179767534, VALIDATION_LOSS : 0.016202369704842567\n",
            "FOLD : 1, EPOCH : 38, TRAIN_LOSS : 0.014864359149023107, VALIDATION_LOSS : 0.01614413857460022\n",
            "FOLD : 1, EPOCH : 39, TRAIN_LOSS : 0.014694277589258394, VALIDATION_LOSS : 0.016171761974692344\n",
            "FOLD : 1, EPOCH : 40, TRAIN_LOSS : 0.014552060465671514, VALIDATION_LOSS : 0.01619708240032196\n",
            "FOLD : 1, EPOCH : 41, TRAIN_LOSS : 0.014372223498005616, VALIDATION_LOSS : 0.016211939603090288\n",
            "FOLD : 1, EPOCH : 42, TRAIN_LOSS : 0.014167045390135363, VALIDATION_LOSS : 0.01618877649307251\n",
            "FOLD : 1, EPOCH : 43, TRAIN_LOSS : 0.01397624082471195, VALIDATION_LOSS : 0.016266874969005585\n",
            "FOLD : 1, EPOCH : 44, TRAIN_LOSS : 0.01381357009277532, VALIDATION_LOSS : 0.01641615927219391\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 2, EPOCH : 0, TRAIN_LOSS : 0.39209592577658203, VALIDATION_LOSS : 0.3399947226047516\n",
            "FOLD : 2, EPOCH : 1, TRAIN_LOSS : 0.0996186721481775, VALIDATION_LOSS : 0.0285897932946682\n",
            "FOLD : 2, EPOCH : 2, TRAIN_LOSS : 0.04111527612334803, VALIDATION_LOSS : 0.02207910530269146\n",
            "FOLD : 2, EPOCH : 3, TRAIN_LOSS : 0.02779758603949296, VALIDATION_LOSS : 0.021083274856209755\n",
            "FOLD : 2, EPOCH : 4, TRAIN_LOSS : 0.02399904065226254, VALIDATION_LOSS : 0.02151620164513588\n",
            "FOLD : 2, EPOCH : 5, TRAIN_LOSS : 0.022553724285803343, VALIDATION_LOSS : 0.021361159160733223\n",
            "FOLD : 2, EPOCH : 6, TRAIN_LOSS : 0.021678300770489795, VALIDATION_LOSS : 0.02107197940349579\n",
            "FOLD : 2, EPOCH : 7, TRAIN_LOSS : 0.02109700392343496, VALIDATION_LOSS : 0.020634017139673232\n",
            "FOLD : 2, EPOCH : 8, TRAIN_LOSS : 0.020641739529214408, VALIDATION_LOSS : 0.02026187628507614\n",
            "FOLD : 2, EPOCH : 9, TRAIN_LOSS : 0.020232990874271644, VALIDATION_LOSS : 0.02000195123255253\n",
            "FOLD : 2, EPOCH : 10, TRAIN_LOSS : 0.019887461474067288, VALIDATION_LOSS : 0.01973314769566059\n",
            "FOLD : 2, EPOCH : 11, TRAIN_LOSS : 0.01961869020995341, VALIDATION_LOSS : 0.019425856694579125\n",
            "FOLD : 2, EPOCH : 12, TRAIN_LOSS : 0.019352537040647707, VALIDATION_LOSS : 0.01914086230099201\n",
            "FOLD : 2, EPOCH : 13, TRAIN_LOSS : 0.019123318262006108, VALIDATION_LOSS : 0.018967146053910255\n",
            "FOLD : 2, EPOCH : 14, TRAIN_LOSS : 0.018918046727776527, VALIDATION_LOSS : 0.018880652263760567\n",
            "FOLD : 2, EPOCH : 15, TRAIN_LOSS : 0.018707356562739925, VALIDATION_LOSS : 0.018642299994826316\n",
            "FOLD : 2, EPOCH : 16, TRAIN_LOSS : 0.018476206809282303, VALIDATION_LOSS : 0.018422575294971467\n",
            "FOLD : 2, EPOCH : 17, TRAIN_LOSS : 0.018198542296886444, VALIDATION_LOSS : 0.018202373757958412\n",
            "FOLD : 2, EPOCH : 18, TRAIN_LOSS : 0.017877743334362383, VALIDATION_LOSS : 0.017765054106712343\n",
            "FOLD : 2, EPOCH : 19, TRAIN_LOSS : 0.017570488939159794, VALIDATION_LOSS : 0.017476048693060874\n",
            "FOLD : 2, EPOCH : 20, TRAIN_LOSS : 0.01726999771046011, VALIDATION_LOSS : 0.017307230830192567\n",
            "FOLD : 2, EPOCH : 21, TRAIN_LOSS : 0.017017869965026255, VALIDATION_LOSS : 0.017128601670265198\n",
            "FOLD : 2, EPOCH : 22, TRAIN_LOSS : 0.016792073551761478, VALIDATION_LOSS : 0.017059045657515527\n",
            "FOLD : 2, EPOCH : 23, TRAIN_LOSS : 0.016654052526543017, VALIDATION_LOSS : 0.016859781742095948\n",
            "FOLD : 2, EPOCH : 24, TRAIN_LOSS : 0.016458744575318537, VALIDATION_LOSS : 0.016732820495963096\n",
            "FOLD : 2, EPOCH : 25, TRAIN_LOSS : 0.016299982261108726, VALIDATION_LOSS : 0.01668805778026581\n",
            "FOLD : 2, EPOCH : 26, TRAIN_LOSS : 0.016164131119455163, VALIDATION_LOSS : 0.0165584996342659\n",
            "FOLD : 2, EPOCH : 27, TRAIN_LOSS : 0.016064578275147238, VALIDATION_LOSS : 0.016470536962151526\n",
            "FOLD : 2, EPOCH : 28, TRAIN_LOSS : 0.015943760297408228, VALIDATION_LOSS : 0.01662156879901886\n",
            "FOLD : 2, EPOCH : 29, TRAIN_LOSS : 0.015794967203155943, VALIDATION_LOSS : 0.016461198404431342\n",
            "FOLD : 2, EPOCH : 30, TRAIN_LOSS : 0.01567415020575649, VALIDATION_LOSS : 0.016347234323620796\n",
            "FOLD : 2, EPOCH : 31, TRAIN_LOSS : 0.015549612966807265, VALIDATION_LOSS : 0.01632337421178818\n",
            "FOLD : 2, EPOCH : 32, TRAIN_LOSS : 0.015430914091044351, VALIDATION_LOSS : 0.016272183135151864\n",
            "FOLD : 2, EPOCH : 33, TRAIN_LOSS : 0.015300434965052102, VALIDATION_LOSS : 0.016358118504285812\n",
            "FOLD : 2, EPOCH : 34, TRAIN_LOSS : 0.015166385883563444, VALIDATION_LOSS : 0.016383413597941397\n",
            "FOLD : 2, EPOCH : 35, TRAIN_LOSS : 0.014986159230925535, VALIDATION_LOSS : 0.016272373124957086\n",
            "FOLD : 2, EPOCH : 36, TRAIN_LOSS : 0.014838720622815584, VALIDATION_LOSS : 0.016281893104314805\n",
            "FOLD : 2, EPOCH : 37, TRAIN_LOSS : 0.014664269787700553, VALIDATION_LOSS : 0.01612403281033039\n",
            "FOLD : 2, EPOCH : 38, TRAIN_LOSS : 0.014472958582796548, VALIDATION_LOSS : 0.016256970539689063\n",
            "FOLD : 2, EPOCH : 39, TRAIN_LOSS : 0.014303592866972872, VALIDATION_LOSS : 0.016225898638367653\n",
            "FOLD : 2, EPOCH : 40, TRAIN_LOSS : 0.014108225262086643, VALIDATION_LOSS : 0.01631421111524105\n",
            "FOLD : 2, EPOCH : 41, TRAIN_LOSS : 0.01390766102428499, VALIDATION_LOSS : 0.01628163680434227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 3, EPOCH : 0, TRAIN_LOSS : 0.3969805397485432, VALIDATION_LOSS : 0.3118109583854675\n",
            "FOLD : 3, EPOCH : 1, TRAIN_LOSS : 0.10003940976764027, VALIDATION_LOSS : 0.02846900150179863\n",
            "FOLD : 3, EPOCH : 2, TRAIN_LOSS : 0.03937908879628307, VALIDATION_LOSS : 0.02557736299932003\n",
            "FOLD : 3, EPOCH : 3, TRAIN_LOSS : 0.026591236948182707, VALIDATION_LOSS : 0.02095079459249973\n",
            "FOLD : 3, EPOCH : 4, TRAIN_LOSS : 0.023802146903778378, VALIDATION_LOSS : 0.022085591033101083\n",
            "FOLD : 3, EPOCH : 5, TRAIN_LOSS : 0.02249929112823386, VALIDATION_LOSS : 0.021924222633242608\n",
            "FOLD : 3, EPOCH : 6, TRAIN_LOSS : 0.021708168383491665, VALIDATION_LOSS : 0.021206342428922654\n",
            "FOLD : 3, EPOCH : 7, TRAIN_LOSS : 0.02114171936715904, VALIDATION_LOSS : 0.02070149630308151\n",
            "FOLD : 3, EPOCH : 8, TRAIN_LOSS : 0.02068428940286762, VALIDATION_LOSS : 0.020363128930330276\n",
            "FOLD : 3, EPOCH : 9, TRAIN_LOSS : 0.020369914899531164, VALIDATION_LOSS : 0.020134534686803818\n",
            "FOLD : 3, EPOCH : 10, TRAIN_LOSS : 0.01999594820173163, VALIDATION_LOSS : 0.019781257212162017\n",
            "FOLD : 3, EPOCH : 11, TRAIN_LOSS : 0.019717212178205188, VALIDATION_LOSS : 0.01937903240323067\n",
            "FOLD : 3, EPOCH : 12, TRAIN_LOSS : 0.019407652220443675, VALIDATION_LOSS : 0.019287353754043578\n",
            "FOLD : 3, EPOCH : 13, TRAIN_LOSS : 0.019103825288383586, VALIDATION_LOSS : 0.018990394473075867\n",
            "FOLD : 3, EPOCH : 14, TRAIN_LOSS : 0.018838268557661457, VALIDATION_LOSS : 0.018635081499814986\n",
            "FOLD : 3, EPOCH : 15, TRAIN_LOSS : 0.018544573728975496, VALIDATION_LOSS : 0.01832515075802803\n",
            "FOLD : 3, EPOCH : 16, TRAIN_LOSS : 0.018195666764911852, VALIDATION_LOSS : 0.01800592914223671\n",
            "FOLD : 3, EPOCH : 17, TRAIN_LOSS : 0.01793590168419637, VALIDATION_LOSS : 0.017729644477367402\n",
            "FOLD : 3, EPOCH : 18, TRAIN_LOSS : 0.01765670784209904, VALIDATION_LOSS : 0.017543182894587516\n",
            "FOLD : 3, EPOCH : 19, TRAIN_LOSS : 0.01740221679210663, VALIDATION_LOSS : 0.017289797589182854\n",
            "FOLD : 3, EPOCH : 20, TRAIN_LOSS : 0.017221211896915185, VALIDATION_LOSS : 0.01715726889669895\n",
            "FOLD : 3, EPOCH : 21, TRAIN_LOSS : 0.01705027587319675, VALIDATION_LOSS : 0.01702215299010277\n",
            "FOLD : 3, EPOCH : 22, TRAIN_LOSS : 0.016884915334613698, VALIDATION_LOSS : 0.016858987510204315\n",
            "FOLD : 3, EPOCH : 23, TRAIN_LOSS : 0.01671202137674156, VALIDATION_LOSS : 0.016745217517018317\n",
            "FOLD : 3, EPOCH : 24, TRAIN_LOSS : 0.01653510479158477, VALIDATION_LOSS : 0.016701702028512955\n",
            "FOLD : 3, EPOCH : 25, TRAIN_LOSS : 0.016432817339112882, VALIDATION_LOSS : 0.01647966355085373\n",
            "FOLD : 3, EPOCH : 26, TRAIN_LOSS : 0.016278479248285294, VALIDATION_LOSS : 0.016420986875891684\n",
            "FOLD : 3, EPOCH : 27, TRAIN_LOSS : 0.016104673574629583, VALIDATION_LOSS : 0.0164011899381876\n",
            "FOLD : 3, EPOCH : 28, TRAIN_LOSS : 0.015999187960436468, VALIDATION_LOSS : 0.01633996218442917\n",
            "FOLD : 3, EPOCH : 29, TRAIN_LOSS : 0.015886709143064524, VALIDATION_LOSS : 0.016268836706876753\n",
            "FOLD : 3, EPOCH : 30, TRAIN_LOSS : 0.015769930850518376, VALIDATION_LOSS : 0.016261373460292817\n",
            "FOLD : 3, EPOCH : 31, TRAIN_LOSS : 0.015645523016390047, VALIDATION_LOSS : 0.0163327693939209\n",
            "FOLD : 3, EPOCH : 32, TRAIN_LOSS : 0.015512971011431594, VALIDATION_LOSS : 0.016198789328336717\n",
            "FOLD : 3, EPOCH : 33, TRAIN_LOSS : 0.015422863248539599, VALIDATION_LOSS : 0.01622811295092106\n",
            "FOLD : 3, EPOCH : 34, TRAIN_LOSS : 0.015282223638343183, VALIDATION_LOSS : 0.016095934435725212\n",
            "FOLD : 3, EPOCH : 35, TRAIN_LOSS : 0.015155798608535215, VALIDATION_LOSS : 0.01613495536148548\n",
            "FOLD : 3, EPOCH : 36, TRAIN_LOSS : 0.01499615065557392, VALIDATION_LOSS : 0.016208451986312867\n",
            "FOLD : 3, EPOCH : 37, TRAIN_LOSS : 0.014847151150828913, VALIDATION_LOSS : 0.016120899841189383\n",
            "FOLD : 3, EPOCH : 38, TRAIN_LOSS : 0.014661021236526338, VALIDATION_LOSS : 0.016205743327736853\n",
            "FOLD : 3, EPOCH : 39, TRAIN_LOSS : 0.014528231940379268, VALIDATION_LOSS : 0.016074271872639656\n",
            "FOLD : 3, EPOCH : 40, TRAIN_LOSS : 0.014360414131691581, VALIDATION_LOSS : 0.016109298542141916\n",
            "FOLD : 3, EPOCH : 41, TRAIN_LOSS : 0.014184292454860713, VALIDATION_LOSS : 0.016195179894566536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 0, TRAIN_LOSS : 0.39115210269626816, VALIDATION_LOSS : 0.33117499351501467\n",
            "FOLD : 4, EPOCH : 1, TRAIN_LOSS : 0.09998878836631775, VALIDATION_LOSS : 0.034568388015031815\n",
            "FOLD : 4, EPOCH : 2, TRAIN_LOSS : 0.04208296380544964, VALIDATION_LOSS : 0.023687668889760972\n",
            "FOLD : 4, EPOCH : 3, TRAIN_LOSS : 0.027853049631965787, VALIDATION_LOSS : 0.021032439172267915\n",
            "FOLD : 4, EPOCH : 4, TRAIN_LOSS : 0.02379885041400006, VALIDATION_LOSS : 0.021263990178704263\n",
            "FOLD : 4, EPOCH : 5, TRAIN_LOSS : 0.022355637464084123, VALIDATION_LOSS : 0.02130649909377098\n",
            "FOLD : 4, EPOCH : 6, TRAIN_LOSS : 0.021492366041792065, VALIDATION_LOSS : 0.020911721512675285\n",
            "FOLD : 4, EPOCH : 7, TRAIN_LOSS : 0.020911123211446562, VALIDATION_LOSS : 0.02055349461734295\n",
            "FOLD : 4, EPOCH : 8, TRAIN_LOSS : 0.020410795941164617, VALIDATION_LOSS : 0.020180393382906912\n",
            "FOLD : 4, EPOCH : 9, TRAIN_LOSS : 0.02006117166265061, VALIDATION_LOSS : 0.019891323894262312\n",
            "FOLD : 4, EPOCH : 10, TRAIN_LOSS : 0.019737983122467995, VALIDATION_LOSS : 0.0196525402367115\n",
            "FOLD : 4, EPOCH : 11, TRAIN_LOSS : 0.019416513215554387, VALIDATION_LOSS : 0.019426456466317178\n",
            "FOLD : 4, EPOCH : 12, TRAIN_LOSS : 0.019094601469604594, VALIDATION_LOSS : 0.01900159753859043\n",
            "FOLD : 4, EPOCH : 13, TRAIN_LOSS : 0.018771338717717873, VALIDATION_LOSS : 0.018639936298131942\n",
            "FOLD : 4, EPOCH : 14, TRAIN_LOSS : 0.018437494768908148, VALIDATION_LOSS : 0.018282144144177438\n",
            "FOLD : 4, EPOCH : 15, TRAIN_LOSS : 0.018148132452839298, VALIDATION_LOSS : 0.01806230694055557\n",
            "FOLD : 4, EPOCH : 16, TRAIN_LOSS : 0.017857983218211877, VALIDATION_LOSS : 0.017769187316298486\n",
            "FOLD : 4, EPOCH : 17, TRAIN_LOSS : 0.017584259180646194, VALIDATION_LOSS : 0.017590750008821487\n",
            "FOLD : 4, EPOCH : 18, TRAIN_LOSS : 0.017361001258617954, VALIDATION_LOSS : 0.01745879724621773\n",
            "FOLD : 4, EPOCH : 19, TRAIN_LOSS : 0.01716522676380057, VALIDATION_LOSS : 0.01724138669669628\n",
            "FOLD : 4, EPOCH : 20, TRAIN_LOSS : 0.016931364214734027, VALIDATION_LOSS : 0.017111796885728836\n",
            "FOLD : 4, EPOCH : 21, TRAIN_LOSS : 0.016767438795221478, VALIDATION_LOSS : 0.01698242649435997\n",
            "FOLD : 4, EPOCH : 22, TRAIN_LOSS : 0.01658036050043608, VALIDATION_LOSS : 0.016916185989975928\n",
            "FOLD : 4, EPOCH : 23, TRAIN_LOSS : 0.016453454859162633, VALIDATION_LOSS : 0.016820577532052995\n",
            "FOLD : 4, EPOCH : 24, TRAIN_LOSS : 0.01631205244676063, VALIDATION_LOSS : 0.016712044551968574\n",
            "FOLD : 4, EPOCH : 25, TRAIN_LOSS : 0.016153962792534577, VALIDATION_LOSS : 0.016593943536281585\n",
            "FOLD : 4, EPOCH : 26, TRAIN_LOSS : 0.016002911535140715, VALIDATION_LOSS : 0.016523708775639533\n",
            "FOLD : 4, EPOCH : 27, TRAIN_LOSS : 0.01589368273945231, VALIDATION_LOSS : 0.01657305620610714\n",
            "FOLD : 4, EPOCH : 28, TRAIN_LOSS : 0.015781254605635217, VALIDATION_LOSS : 0.016449882090091704\n",
            "FOLD : 4, EPOCH : 29, TRAIN_LOSS : 0.01563071645796299, VALIDATION_LOSS : 0.016427525132894517\n",
            "FOLD : 4, EPOCH : 30, TRAIN_LOSS : 0.015544341583000986, VALIDATION_LOSS : 0.016449617221951485\n",
            "FOLD : 4, EPOCH : 31, TRAIN_LOSS : 0.01547029006638025, VALIDATION_LOSS : 0.0164415143430233\n",
            "FOLD : 4, EPOCH : 32, TRAIN_LOSS : 0.015336211966840844, VALIDATION_LOSS : 0.016316181793808938\n",
            "FOLD : 4, EPOCH : 33, TRAIN_LOSS : 0.015198847131901666, VALIDATION_LOSS : 0.016337304934859277\n",
            "FOLD : 4, EPOCH : 34, TRAIN_LOSS : 0.015036301442274922, VALIDATION_LOSS : 0.016290279850363732\n",
            "FOLD : 4, EPOCH : 35, TRAIN_LOSS : 0.014925126770609304, VALIDATION_LOSS : 0.01630302220582962\n",
            "FOLD : 4, EPOCH : 36, TRAIN_LOSS : 0.014759364537894726, VALIDATION_LOSS : 0.016318099200725557\n",
            "FOLD : 4, EPOCH : 37, TRAIN_LOSS : 0.014617967027190485, VALIDATION_LOSS : 0.016266942769289017\n",
            "FOLD : 4, EPOCH : 38, TRAIN_LOSS : 0.014430883830707324, VALIDATION_LOSS : 0.01622599773108959\n",
            "FOLD : 4, EPOCH : 39, TRAIN_LOSS : 0.014247567000749865, VALIDATION_LOSS : 0.01623559296131134\n",
            "FOLD : 4, EPOCH : 40, TRAIN_LOSS : 0.014089978398068956, VALIDATION_LOSS : 0.01634390503168106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-11-01 13:46:05,753]\u001b[0m Trial 0 finished with value: 0.016165807619690897 and parameters: {'num_layers': 7, 'hidden_size': 1377, 'dropout': 0.11473876253107858, 'learning_rate': 0.00018431084373364442}. Best is trial 0 with value: 0.016165807619690897.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 41, TRAIN_LOSS : 0.013854036891930982, VALIDATION_LOSS : 0.01648108847439289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 0, EPOCH : 0, TRAIN_LOSS : 0.7125376494307267, VALIDATION_LOSS : 0.6928583979606628\n",
            "FOLD : 0, EPOCH : 1, TRAIN_LOSS : 0.7100380878699454, VALIDATION_LOSS : 0.6918250560760498\n",
            "FOLD : 0, EPOCH : 2, TRAIN_LOSS : 0.7075285911560059, VALIDATION_LOSS : 0.690904700756073\n",
            "FOLD : 0, EPOCH : 3, TRAIN_LOSS : 0.7047579162999204, VALIDATION_LOSS : 0.6903236389160157\n",
            "FOLD : 0, EPOCH : 4, TRAIN_LOSS : 0.7024759022813094, VALIDATION_LOSS : 0.6896050572395325\n",
            "FOLD : 0, EPOCH : 5, TRAIN_LOSS : 0.700225714005922, VALIDATION_LOSS : 0.6886707544326782\n",
            "FOLD : 0, EPOCH : 6, TRAIN_LOSS : 0.6973051366053129, VALIDATION_LOSS : 0.6879731178283691\n",
            "FOLD : 0, EPOCH : 7, TRAIN_LOSS : 0.6945818474418238, VALIDATION_LOSS : 0.687137222290039\n",
            "FOLD : 0, EPOCH : 8, TRAIN_LOSS : 0.6923394140444303, VALIDATION_LOSS : 0.686053204536438\n",
            "FOLD : 0, EPOCH : 9, TRAIN_LOSS : 0.6896845980694419, VALIDATION_LOSS : 0.6853182673454284\n",
            "FOLD : 0, EPOCH : 10, TRAIN_LOSS : 0.6873027901900443, VALIDATION_LOSS : 0.6844849228858948\n",
            "FOLD : 0, EPOCH : 11, TRAIN_LOSS : 0.6848042230857047, VALIDATION_LOSS : 0.6834589600563049\n",
            "FOLD : 0, EPOCH : 12, TRAIN_LOSS : 0.6820233652466222, VALIDATION_LOSS : 0.6826073527336121\n",
            "FOLD : 0, EPOCH : 13, TRAIN_LOSS : 0.6796740073906747, VALIDATION_LOSS : 0.681579077243805\n",
            "FOLD : 0, EPOCH : 14, TRAIN_LOSS : 0.6771199013057508, VALIDATION_LOSS : 0.6804988503456115\n",
            "FOLD : 0, EPOCH : 15, TRAIN_LOSS : 0.6745554491093284, VALIDATION_LOSS : 0.6793210864067077\n",
            "FOLD : 0, EPOCH : 16, TRAIN_LOSS : 0.6719921231269836, VALIDATION_LOSS : 0.6782975554466247\n",
            "FOLD : 0, EPOCH : 17, TRAIN_LOSS : 0.6690568641612404, VALIDATION_LOSS : 0.6770555734634399\n",
            "FOLD : 0, EPOCH : 18, TRAIN_LOSS : 0.6665733111532111, VALIDATION_LOSS : 0.6758147358894349\n",
            "FOLD : 0, EPOCH : 19, TRAIN_LOSS : 0.6638793317895186, VALIDATION_LOSS : 0.6745558023452759\n",
            "FOLD : 0, EPOCH : 20, TRAIN_LOSS : 0.6611566512208236, VALIDATION_LOSS : 0.6731215834617614\n",
            "FOLD : 0, EPOCH : 21, TRAIN_LOSS : 0.658381838547556, VALIDATION_LOSS : 0.6715903520584107\n",
            "FOLD : 0, EPOCH : 22, TRAIN_LOSS : 0.6560484359138891, VALIDATION_LOSS : 0.6703412652015686\n",
            "FOLD : 0, EPOCH : 23, TRAIN_LOSS : 0.6532631140006216, VALIDATION_LOSS : 0.6689336657524109\n",
            "FOLD : 0, EPOCH : 24, TRAIN_LOSS : 0.6505678735281292, VALIDATION_LOSS : 0.6675853133201599\n",
            "FOLD : 0, EPOCH : 25, TRAIN_LOSS : 0.6478565147048548, VALIDATION_LOSS : 0.6660058617591857\n",
            "FOLD : 0, EPOCH : 26, TRAIN_LOSS : 0.645095567954214, VALIDATION_LOSS : 0.6644914746284485\n",
            "FOLD : 0, EPOCH : 27, TRAIN_LOSS : 0.6423122631876093, VALIDATION_LOSS : 0.663075578212738\n",
            "FOLD : 0, EPOCH : 28, TRAIN_LOSS : 0.6397359622152228, VALIDATION_LOSS : 0.6611646294593811\n",
            "FOLD : 0, EPOCH : 29, TRAIN_LOSS : 0.6369927933341578, VALIDATION_LOSS : 0.659911060333252\n",
            "FOLD : 0, EPOCH : 30, TRAIN_LOSS : 0.6340086334630063, VALIDATION_LOSS : 0.6580412745475769\n",
            "FOLD : 0, EPOCH : 31, TRAIN_LOSS : 0.6316439917213038, VALIDATION_LOSS : 0.6565405011177063\n",
            "FOLD : 0, EPOCH : 32, TRAIN_LOSS : 0.6288509494379947, VALIDATION_LOSS : 0.6548389554023742\n",
            "FOLD : 0, EPOCH : 33, TRAIN_LOSS : 0.6258976804582697, VALIDATION_LOSS : 0.6530108571052551\n",
            "FOLD : 0, EPOCH : 34, TRAIN_LOSS : 0.6234226101323178, VALIDATION_LOSS : 0.6514163374900818\n",
            "FOLD : 0, EPOCH : 35, TRAIN_LOSS : 0.6205715129249975, VALIDATION_LOSS : 0.6494022250175476\n",
            "FOLD : 0, EPOCH : 36, TRAIN_LOSS : 0.6179651523891249, VALIDATION_LOSS : 0.6478418588638306\n",
            "FOLD : 0, EPOCH : 37, TRAIN_LOSS : 0.6154134900946366, VALIDATION_LOSS : 0.6460891485214233\n",
            "FOLD : 0, EPOCH : 38, TRAIN_LOSS : 0.6126642070318523, VALIDATION_LOSS : 0.6445432782173157\n",
            "FOLD : 0, EPOCH : 39, TRAIN_LOSS : 0.6098048498756007, VALIDATION_LOSS : 0.6426480412483215\n",
            "FOLD : 0, EPOCH : 40, TRAIN_LOSS : 0.6073414432375055, VALIDATION_LOSS : 0.640902829170227\n",
            "FOLD : 0, EPOCH : 41, TRAIN_LOSS : 0.6048930193248548, VALIDATION_LOSS : 0.6390023231506348\n",
            "FOLD : 0, EPOCH : 42, TRAIN_LOSS : 0.6019653615198637, VALIDATION_LOSS : 0.6368615984916687\n",
            "FOLD : 0, EPOCH : 43, TRAIN_LOSS : 0.5994408412983543, VALIDATION_LOSS : 0.6350576639175415\n",
            "FOLD : 0, EPOCH : 44, TRAIN_LOSS : 0.5969906574801395, VALIDATION_LOSS : 0.6336129784584046\n",
            "FOLD : 0, EPOCH : 45, TRAIN_LOSS : 0.5942385228056657, VALIDATION_LOSS : 0.6318068981170655\n",
            "FOLD : 0, EPOCH : 46, TRAIN_LOSS : 0.5917657080449557, VALIDATION_LOSS : 0.6298002362251282\n",
            "FOLD : 0, EPOCH : 47, TRAIN_LOSS : 0.5889706799858495, VALIDATION_LOSS : 0.6282617211341858\n",
            "FOLD : 0, EPOCH : 48, TRAIN_LOSS : 0.5865082709412826, VALIDATION_LOSS : 0.6259072184562683\n",
            "FOLD : 0, EPOCH : 49, TRAIN_LOSS : 0.584216080213848, VALIDATION_LOSS : 0.6244550704956054\n",
            "FOLD : 0, EPOCH : 50, TRAIN_LOSS : 0.581593350360268, VALIDATION_LOSS : 0.6228091478347778\n",
            "FOLD : 0, EPOCH : 51, TRAIN_LOSS : 0.5787320607586911, VALIDATION_LOSS : 0.6207404136657715\n",
            "FOLD : 0, EPOCH : 52, TRAIN_LOSS : 0.5761918143222207, VALIDATION_LOSS : 0.6184677004814148\n",
            "FOLD : 0, EPOCH : 53, TRAIN_LOSS : 0.5739479817842182, VALIDATION_LOSS : 0.6171834468841553\n",
            "FOLD : 0, EPOCH : 54, TRAIN_LOSS : 0.5713399931004173, VALIDATION_LOSS : 0.6153313279151916\n",
            "FOLD : 0, EPOCH : 55, TRAIN_LOSS : 0.568810224533081, VALIDATION_LOSS : 0.6133600473403931\n",
            "FOLD : 0, EPOCH : 56, TRAIN_LOSS : 0.5664237486688715, VALIDATION_LOSS : 0.6110258936882019\n",
            "FOLD : 0, EPOCH : 57, TRAIN_LOSS : 0.5640507622769004, VALIDATION_LOSS : 0.6097565412521362\n",
            "FOLD : 0, EPOCH : 58, TRAIN_LOSS : 0.5614842145066512, VALIDATION_LOSS : 0.6080274701118469\n",
            "FOLD : 0, EPOCH : 59, TRAIN_LOSS : 0.5591967074494613, VALIDATION_LOSS : 0.6060654878616333\n",
            "FOLD : 0, EPOCH : 60, TRAIN_LOSS : 0.5564999862721092, VALIDATION_LOSS : 0.6042658686637878\n",
            "FOLD : 0, EPOCH : 61, TRAIN_LOSS : 0.5541149534677204, VALIDATION_LOSS : 0.6026398062705993\n",
            "FOLD : 0, EPOCH : 62, TRAIN_LOSS : 0.5515239395593342, VALIDATION_LOSS : 0.6004393339157105\n",
            "FOLD : 0, EPOCH : 63, TRAIN_LOSS : 0.5492647290229797, VALIDATION_LOSS : 0.5986142992973328\n",
            "FOLD : 0, EPOCH : 64, TRAIN_LOSS : 0.5472405521493209, VALIDATION_LOSS : 0.5970657944679261\n",
            "FOLD : 0, EPOCH : 65, TRAIN_LOSS : 0.5447735974663183, VALIDATION_LOSS : 0.5953647136688233\n",
            "FOLD : 0, EPOCH : 66, TRAIN_LOSS : 0.5421844877694783, VALIDATION_LOSS : 0.5932724714279175\n",
            "FOLD : 0, EPOCH : 67, TRAIN_LOSS : 0.5402836454542059, VALIDATION_LOSS : 0.5914607763290405\n",
            "FOLD : 0, EPOCH : 68, TRAIN_LOSS : 0.5376911696634794, VALIDATION_LOSS : 0.5898845791816711\n",
            "FOLD : 0, EPOCH : 69, TRAIN_LOSS : 0.535192891171104, VALIDATION_LOSS : 0.588045060634613\n",
            "FOLD : 0, EPOCH : 70, TRAIN_LOSS : 0.533000626062092, VALIDATION_LOSS : 0.5861767292022705\n",
            "FOLD : 0, EPOCH : 71, TRAIN_LOSS : 0.5307438781386927, VALIDATION_LOSS : 0.5843333005905151\n",
            "FOLD : 0, EPOCH : 72, TRAIN_LOSS : 0.5284121036529541, VALIDATION_LOSS : 0.5824237823486328\n",
            "FOLD : 0, EPOCH : 73, TRAIN_LOSS : 0.5262672148252788, VALIDATION_LOSS : 0.5805531024932862\n",
            "FOLD : 0, EPOCH : 74, TRAIN_LOSS : 0.5238235435987774, VALIDATION_LOSS : 0.5792824745178222\n",
            "FOLD : 0, EPOCH : 75, TRAIN_LOSS : 0.5215477347373962, VALIDATION_LOSS : 0.5772083640098572\n",
            "FOLD : 0, EPOCH : 76, TRAIN_LOSS : 0.5197257462300753, VALIDATION_LOSS : 0.5759183406829834\n",
            "FOLD : 0, EPOCH : 77, TRAIN_LOSS : 0.517125992398513, VALIDATION_LOSS : 0.5740423321723938\n",
            "FOLD : 0, EPOCH : 78, TRAIN_LOSS : 0.5147536522463748, VALIDATION_LOSS : 0.5724917411804199\n",
            "FOLD : 0, EPOCH : 79, TRAIN_LOSS : 0.5125071029914053, VALIDATION_LOSS : 0.5701761245727539\n",
            "FOLD : 0, EPOCH : 80, TRAIN_LOSS : 0.5105044026123849, VALIDATION_LOSS : 0.5688960790634155\n",
            "FOLD : 0, EPOCH : 81, TRAIN_LOSS : 0.5083595577039217, VALIDATION_LOSS : 0.5670519948005677\n",
            "FOLD : 0, EPOCH : 82, TRAIN_LOSS : 0.5061490912186472, VALIDATION_LOSS : 0.5651326894760131\n",
            "FOLD : 0, EPOCH : 83, TRAIN_LOSS : 0.5040832569724635, VALIDATION_LOSS : 0.5633776783943176\n",
            "FOLD : 0, EPOCH : 84, TRAIN_LOSS : 0.5019058961617319, VALIDATION_LOSS : 0.5616100907325745\n",
            "FOLD : 0, EPOCH : 85, TRAIN_LOSS : 0.49949688503616735, VALIDATION_LOSS : 0.5608499884605408\n",
            "FOLD : 0, EPOCH : 86, TRAIN_LOSS : 0.4972192299993415, VALIDATION_LOSS : 0.5587266564369202\n",
            "FOLD : 0, EPOCH : 87, TRAIN_LOSS : 0.49547896730272395, VALIDATION_LOSS : 0.5573638796806335\n",
            "FOLD : 0, EPOCH : 88, TRAIN_LOSS : 0.4933031656240162, VALIDATION_LOSS : 0.555910611152649\n",
            "FOLD : 0, EPOCH : 89, TRAIN_LOSS : 0.4912986159324646, VALIDATION_LOSS : 0.5537488341331482\n",
            "FOLD : 0, EPOCH : 90, TRAIN_LOSS : 0.488964319229126, VALIDATION_LOSS : 0.5517202138900756\n",
            "FOLD : 0, EPOCH : 91, TRAIN_LOSS : 0.4870703988953641, VALIDATION_LOSS : 0.5506232261657715\n",
            "FOLD : 0, EPOCH : 92, TRAIN_LOSS : 0.4849437475204468, VALIDATION_LOSS : 0.5492213129997253\n",
            "FOLD : 0, EPOCH : 93, TRAIN_LOSS : 0.4828635328694394, VALIDATION_LOSS : 0.5477505803108216\n",
            "FOLD : 0, EPOCH : 94, TRAIN_LOSS : 0.4808228047270524, VALIDATION_LOSS : 0.5464257955551147\n",
            "FOLD : 0, EPOCH : 95, TRAIN_LOSS : 0.47868834984929937, VALIDATION_LOSS : 0.5442223429679871\n",
            "FOLD : 0, EPOCH : 96, TRAIN_LOSS : 0.4765062896828902, VALIDATION_LOSS : 0.5433452248573303\n",
            "FOLD : 0, EPOCH : 97, TRAIN_LOSS : 0.47462496004606547, VALIDATION_LOSS : 0.5414010286331177\n",
            "FOLD : 0, EPOCH : 98, TRAIN_LOSS : 0.4729244207081042, VALIDATION_LOSS : 0.5400150537490844\n",
            "FOLD : 0, EPOCH : 99, TRAIN_LOSS : 0.4705453420940198, VALIDATION_LOSS : 0.5383106470108032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 1, EPOCH : 0, TRAIN_LOSS : 0.7161554066758407, VALIDATION_LOSS : 0.6897647857666016\n",
            "FOLD : 1, EPOCH : 1, TRAIN_LOSS : 0.7138133645057678, VALIDATION_LOSS : 0.6882781505584716\n",
            "FOLD : 1, EPOCH : 2, TRAIN_LOSS : 0.7112132404979906, VALIDATION_LOSS : 0.6875210523605346\n",
            "FOLD : 1, EPOCH : 3, TRAIN_LOSS : 0.7087209946230838, VALIDATION_LOSS : 0.6867929339408875\n",
            "FOLD : 1, EPOCH : 4, TRAIN_LOSS : 0.7062227506386606, VALIDATION_LOSS : 0.6860209941864014\n",
            "FOLD : 1, EPOCH : 5, TRAIN_LOSS : 0.7037685231158608, VALIDATION_LOSS : 0.6854628562927246\n",
            "FOLD : 1, EPOCH : 6, TRAIN_LOSS : 0.7013305174676996, VALIDATION_LOSS : 0.6849385499954224\n",
            "FOLD : 1, EPOCH : 7, TRAIN_LOSS : 0.6988543209276701, VALIDATION_LOSS : 0.6841625809669495\n",
            "FOLD : 1, EPOCH : 8, TRAIN_LOSS : 0.6961830572078103, VALIDATION_LOSS : 0.6832595109939575\n",
            "FOLD : 1, EPOCH : 9, TRAIN_LOSS : 0.693824407301451, VALIDATION_LOSS : 0.6824743628501893\n",
            "FOLD : 1, EPOCH : 10, TRAIN_LOSS : 0.6912253781368858, VALIDATION_LOSS : 0.6817584991455078\n",
            "FOLD : 1, EPOCH : 11, TRAIN_LOSS : 0.6886252886370609, VALIDATION_LOSS : 0.6807729959487915\n",
            "FOLD : 1, EPOCH : 12, TRAIN_LOSS : 0.6861533052042911, VALIDATION_LOSS : 0.6798253297805786\n",
            "FOLD : 1, EPOCH : 13, TRAIN_LOSS : 0.6838663094922116, VALIDATION_LOSS : 0.6790148258209229\n",
            "FOLD : 1, EPOCH : 14, TRAIN_LOSS : 0.6813843501241583, VALIDATION_LOSS : 0.6780256390571594\n",
            "FOLD : 1, EPOCH : 15, TRAIN_LOSS : 0.6783549001342372, VALIDATION_LOSS : 0.6770483493804932\n",
            "FOLD : 1, EPOCH : 16, TRAIN_LOSS : 0.6761777557824787, VALIDATION_LOSS : 0.6761106371879577\n",
            "FOLD : 1, EPOCH : 17, TRAIN_LOSS : 0.6734857214124579, VALIDATION_LOSS : 0.6747902750968933\n",
            "FOLD : 1, EPOCH : 18, TRAIN_LOSS : 0.6708765563211943, VALIDATION_LOSS : 0.6733747005462647\n",
            "FOLD : 1, EPOCH : 19, TRAIN_LOSS : 0.6680689861899928, VALIDATION_LOSS : 0.6724280595779419\n",
            "FOLD : 1, EPOCH : 20, TRAIN_LOSS : 0.6657115409248754, VALIDATION_LOSS : 0.6709744215011597\n",
            "FOLD : 1, EPOCH : 21, TRAIN_LOSS : 0.6629159952464857, VALIDATION_LOSS : 0.6698448896408081\n",
            "FOLD : 1, EPOCH : 22, TRAIN_LOSS : 0.6605243651490462, VALIDATION_LOSS : 0.6686405420303345\n",
            "FOLD : 1, EPOCH : 23, TRAIN_LOSS : 0.6576546587442097, VALIDATION_LOSS : 0.6671088695526123\n",
            "FOLD : 1, EPOCH : 24, TRAIN_LOSS : 0.6548769348546079, VALIDATION_LOSS : 0.6653652310371398\n",
            "FOLD : 1, EPOCH : 25, TRAIN_LOSS : 0.6523604236151043, VALIDATION_LOSS : 0.6642438054084778\n",
            "FOLD : 1, EPOCH : 26, TRAIN_LOSS : 0.6499267691060117, VALIDATION_LOSS : 0.6630052089691162\n",
            "FOLD : 1, EPOCH : 27, TRAIN_LOSS : 0.6468822736489145, VALIDATION_LOSS : 0.6612145662307739\n",
            "FOLD : 1, EPOCH : 28, TRAIN_LOSS : 0.644221494072362, VALIDATION_LOSS : 0.6598682284355164\n",
            "FOLD : 1, EPOCH : 29, TRAIN_LOSS : 0.6415662232198214, VALIDATION_LOSS : 0.6580709457397461\n",
            "FOLD : 1, EPOCH : 30, TRAIN_LOSS : 0.6388942442442241, VALIDATION_LOSS : 0.6564390301704407\n",
            "FOLD : 1, EPOCH : 31, TRAIN_LOSS : 0.6361770222061559, VALIDATION_LOSS : 0.6548389792442322\n",
            "FOLD : 1, EPOCH : 32, TRAIN_LOSS : 0.6334062312778673, VALIDATION_LOSS : 0.6530781745910644\n",
            "FOLD : 1, EPOCH : 33, TRAIN_LOSS : 0.6307976685072246, VALIDATION_LOSS : 0.6513412594795227\n",
            "FOLD : 1, EPOCH : 34, TRAIN_LOSS : 0.6279253332238448, VALIDATION_LOSS : 0.6497978568077087\n",
            "FOLD : 1, EPOCH : 35, TRAIN_LOSS : 0.6253665497428492, VALIDATION_LOSS : 0.6481162190437317\n",
            "FOLD : 1, EPOCH : 36, TRAIN_LOSS : 0.6225712079750864, VALIDATION_LOSS : 0.6461563587188721\n",
            "FOLD : 1, EPOCH : 37, TRAIN_LOSS : 0.6197326653882077, VALIDATION_LOSS : 0.6443338036537171\n",
            "FOLD : 1, EPOCH : 38, TRAIN_LOSS : 0.6172754952782079, VALIDATION_LOSS : 0.6426108360290528\n",
            "FOLD : 1, EPOCH : 39, TRAIN_LOSS : 0.6145406930070174, VALIDATION_LOSS : 0.6406274795532226\n",
            "FOLD : 1, EPOCH : 40, TRAIN_LOSS : 0.611758269761738, VALIDATION_LOSS : 0.6388035416603088\n",
            "FOLD : 1, EPOCH : 41, TRAIN_LOSS : 0.6092267193292317, VALIDATION_LOSS : 0.6372217893600464\n",
            "FOLD : 1, EPOCH : 42, TRAIN_LOSS : 0.606127280937998, VALIDATION_LOSS : 0.6351447463035583\n",
            "FOLD : 1, EPOCH : 43, TRAIN_LOSS : 0.6038562184885928, VALIDATION_LOSS : 0.6336736559867859\n",
            "FOLD : 1, EPOCH : 44, TRAIN_LOSS : 0.6012919419690183, VALIDATION_LOSS : 0.6315250754356384\n",
            "FOLD : 1, EPOCH : 45, TRAIN_LOSS : 0.5987327349813361, VALIDATION_LOSS : 0.6298529505729675\n",
            "FOLD : 1, EPOCH : 46, TRAIN_LOSS : 0.5959522818264208, VALIDATION_LOSS : 0.6278615355491638\n",
            "FOLD : 1, EPOCH : 47, TRAIN_LOSS : 0.5934764491884332, VALIDATION_LOSS : 0.6259259223937989\n",
            "FOLD : 1, EPOCH : 48, TRAIN_LOSS : 0.5908593504052413, VALIDATION_LOSS : 0.6236459851264954\n",
            "FOLD : 1, EPOCH : 49, TRAIN_LOSS : 0.588306725025177, VALIDATION_LOSS : 0.6224660277366638\n",
            "FOLD : 1, EPOCH : 50, TRAIN_LOSS : 0.5857722759246826, VALIDATION_LOSS : 0.6202425003051758\n",
            "FOLD : 1, EPOCH : 51, TRAIN_LOSS : 0.5832320200769525, VALIDATION_LOSS : 0.6184552550315857\n",
            "FOLD : 1, EPOCH : 52, TRAIN_LOSS : 0.5805300944729855, VALIDATION_LOSS : 0.6163635015487671\n",
            "FOLD : 1, EPOCH : 53, TRAIN_LOSS : 0.5780684351921082, VALIDATION_LOSS : 0.614581036567688\n",
            "FOLD : 1, EPOCH : 54, TRAIN_LOSS : 0.5756758420090926, VALIDATION_LOSS : 0.6129580736160278\n",
            "FOLD : 1, EPOCH : 55, TRAIN_LOSS : 0.5730717558609811, VALIDATION_LOSS : 0.6107088565826416\n",
            "FOLD : 1, EPOCH : 56, TRAIN_LOSS : 0.5706035337950054, VALIDATION_LOSS : 0.6091240525245667\n",
            "FOLD : 1, EPOCH : 57, TRAIN_LOSS : 0.5680696807409588, VALIDATION_LOSS : 0.6070090889930725\n",
            "FOLD : 1, EPOCH : 58, TRAIN_LOSS : 0.5655173157390795, VALIDATION_LOSS : 0.6052202820777893\n",
            "FOLD : 1, EPOCH : 59, TRAIN_LOSS : 0.5632229321881345, VALIDATION_LOSS : 0.603199052810669\n",
            "FOLD : 1, EPOCH : 60, TRAIN_LOSS : 0.5606950897919504, VALIDATION_LOSS : 0.6015631556510925\n",
            "FOLD : 1, EPOCH : 61, TRAIN_LOSS : 0.5581713507049962, VALIDATION_LOSS : 0.5995111227035522\n",
            "FOLD : 1, EPOCH : 62, TRAIN_LOSS : 0.5558861839143854, VALIDATION_LOSS : 0.5980296015739441\n",
            "FOLD : 1, EPOCH : 63, TRAIN_LOSS : 0.5533637624037894, VALIDATION_LOSS : 0.595896053314209\n",
            "FOLD : 1, EPOCH : 64, TRAIN_LOSS : 0.5512723107086984, VALIDATION_LOSS : 0.5939497113227844\n",
            "FOLD : 1, EPOCH : 65, TRAIN_LOSS : 0.5487985610961914, VALIDATION_LOSS : 0.5921201586723328\n",
            "FOLD : 1, EPOCH : 66, TRAIN_LOSS : 0.546511803802691, VALIDATION_LOSS : 0.5897204518318176\n",
            "FOLD : 1, EPOCH : 67, TRAIN_LOSS : 0.5438609374196905, VALIDATION_LOSS : 0.5882716774940491\n",
            "FOLD : 1, EPOCH : 68, TRAIN_LOSS : 0.5415869166976527, VALIDATION_LOSS : 0.586557936668396\n",
            "FOLD : 1, EPOCH : 69, TRAIN_LOSS : 0.5392348766326904, VALIDATION_LOSS : 0.5841933131217957\n",
            "FOLD : 1, EPOCH : 70, TRAIN_LOSS : 0.5368569273697702, VALIDATION_LOSS : 0.5825055122375489\n",
            "FOLD : 1, EPOCH : 71, TRAIN_LOSS : 0.5346159840884962, VALIDATION_LOSS : 0.5806857466697692\n",
            "FOLD : 1, EPOCH : 72, TRAIN_LOSS : 0.532198943589863, VALIDATION_LOSS : 0.5790292382240295\n",
            "FOLD : 1, EPOCH : 73, TRAIN_LOSS : 0.5301539176388791, VALIDATION_LOSS : 0.5774366855621338\n",
            "FOLD : 1, EPOCH : 74, TRAIN_LOSS : 0.5277640129390516, VALIDATION_LOSS : 0.5754434943199158\n",
            "FOLD : 1, EPOCH : 75, TRAIN_LOSS : 0.5255442606775385, VALIDATION_LOSS : 0.5741549253463745\n",
            "FOLD : 1, EPOCH : 76, TRAIN_LOSS : 0.5234028697013855, VALIDATION_LOSS : 0.5720518469810486\n",
            "FOLD : 1, EPOCH : 77, TRAIN_LOSS : 0.520946320734526, VALIDATION_LOSS : 0.569667375087738\n",
            "FOLD : 1, EPOCH : 78, TRAIN_LOSS : 0.5186833394201178, VALIDATION_LOSS : 0.5674395322799682\n",
            "FOLD : 1, EPOCH : 79, TRAIN_LOSS : 0.5162930394473829, VALIDATION_LOSS : 0.5661051154136658\n",
            "FOLD : 1, EPOCH : 80, TRAIN_LOSS : 0.5142044550494144, VALIDATION_LOSS : 0.5648578882217408\n",
            "FOLD : 1, EPOCH : 81, TRAIN_LOSS : 0.5119597096192209, VALIDATION_LOSS : 0.5631377696990967\n",
            "FOLD : 1, EPOCH : 82, TRAIN_LOSS : 0.5097644266329313, VALIDATION_LOSS : 0.5616260647773743\n",
            "FOLD : 1, EPOCH : 83, TRAIN_LOSS : 0.5075185957707857, VALIDATION_LOSS : 0.559855329990387\n",
            "FOLD : 1, EPOCH : 84, TRAIN_LOSS : 0.5054829371602911, VALIDATION_LOSS : 0.5578393697738647\n",
            "FOLD : 1, EPOCH : 85, TRAIN_LOSS : 0.5031501023392928, VALIDATION_LOSS : 0.5562436580657959\n",
            "FOLD : 1, EPOCH : 86, TRAIN_LOSS : 0.5012086441642359, VALIDATION_LOSS : 0.5545878767967224\n",
            "FOLD : 1, EPOCH : 87, TRAIN_LOSS : 0.499225062759299, VALIDATION_LOSS : 0.5532054781913758\n",
            "FOLD : 1, EPOCH : 88, TRAIN_LOSS : 0.49693794783793, VALIDATION_LOSS : 0.5517169237136841\n",
            "FOLD : 1, EPOCH : 89, TRAIN_LOSS : 0.49471290331137807, VALIDATION_LOSS : 0.5496676564216614\n",
            "FOLD : 1, EPOCH : 90, TRAIN_LOSS : 0.4927669998846556, VALIDATION_LOSS : 0.5476108074188233\n",
            "FOLD : 1, EPOCH : 91, TRAIN_LOSS : 0.4903204488126855, VALIDATION_LOSS : 0.5462338924407959\n",
            "FOLD : 1, EPOCH : 92, TRAIN_LOSS : 0.4882389652101617, VALIDATION_LOSS : 0.5449458956718445\n",
            "FOLD : 1, EPOCH : 93, TRAIN_LOSS : 0.4863772423643815, VALIDATION_LOSS : 0.5437260150909424\n",
            "FOLD : 1, EPOCH : 94, TRAIN_LOSS : 0.48432380274722453, VALIDATION_LOSS : 0.5416080355644226\n",
            "FOLD : 1, EPOCH : 95, TRAIN_LOSS : 0.48206162766406413, VALIDATION_LOSS : 0.5397123336791992\n",
            "FOLD : 1, EPOCH : 96, TRAIN_LOSS : 0.4803446060732791, VALIDATION_LOSS : 0.5383055925369262\n",
            "FOLD : 1, EPOCH : 97, TRAIN_LOSS : 0.4781180400597422, VALIDATION_LOSS : 0.5364781856536865\n",
            "FOLD : 1, EPOCH : 98, TRAIN_LOSS : 0.4763660336795606, VALIDATION_LOSS : 0.5355599522590637\n",
            "FOLD : 1, EPOCH : 99, TRAIN_LOSS : 0.4740275285745922, VALIDATION_LOSS : 0.5338937997817993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 2, EPOCH : 0, TRAIN_LOSS : 0.731693264685179, VALIDATION_LOSS : 0.6914484977722168\n",
            "FOLD : 2, EPOCH : 1, TRAIN_LOSS : 0.7289754779715287, VALIDATION_LOSS : 0.6914281368255615\n",
            "FOLD : 2, EPOCH : 2, TRAIN_LOSS : 0.7262711681817707, VALIDATION_LOSS : 0.6910529494285583\n",
            "FOLD : 2, EPOCH : 3, TRAIN_LOSS : 0.7237366626137182, VALIDATION_LOSS : 0.6902209043502807\n",
            "FOLD : 2, EPOCH : 4, TRAIN_LOSS : 0.7212376406318263, VALIDATION_LOSS : 0.689653193950653\n",
            "FOLD : 2, EPOCH : 5, TRAIN_LOSS : 0.7185858519453752, VALIDATION_LOSS : 0.6889223217964172\n",
            "FOLD : 2, EPOCH : 6, TRAIN_LOSS : 0.7160181905093946, VALIDATION_LOSS : 0.6881401300430298\n",
            "FOLD : 2, EPOCH : 7, TRAIN_LOSS : 0.7136910745972082, VALIDATION_LOSS : 0.6874507665634155\n",
            "FOLD : 2, EPOCH : 8, TRAIN_LOSS : 0.7111209756449649, VALIDATION_LOSS : 0.6868199348449707\n",
            "FOLD : 2, EPOCH : 9, TRAIN_LOSS : 0.708869689389279, VALIDATION_LOSS : 0.685964024066925\n",
            "FOLD : 2, EPOCH : 10, TRAIN_LOSS : 0.7063952370693809, VALIDATION_LOSS : 0.685075306892395\n",
            "FOLD : 2, EPOCH : 11, TRAIN_LOSS : 0.7040060225285982, VALIDATION_LOSS : 0.6843143224716186\n",
            "FOLD : 2, EPOCH : 12, TRAIN_LOSS : 0.7016713901569969, VALIDATION_LOSS : 0.6836075782775879\n",
            "FOLD : 2, EPOCH : 13, TRAIN_LOSS : 0.6993165957300287, VALIDATION_LOSS : 0.6826157331466675\n",
            "FOLD : 2, EPOCH : 14, TRAIN_LOSS : 0.6968276877152292, VALIDATION_LOSS : 0.6818881392478943\n",
            "FOLD : 2, EPOCH : 15, TRAIN_LOSS : 0.6946734252728914, VALIDATION_LOSS : 0.6808782100677491\n",
            "FOLD : 2, EPOCH : 16, TRAIN_LOSS : 0.692288411291022, VALIDATION_LOSS : 0.679783308506012\n",
            "FOLD : 2, EPOCH : 17, TRAIN_LOSS : 0.6897238210627907, VALIDATION_LOSS : 0.6785862684249878\n",
            "FOLD : 2, EPOCH : 18, TRAIN_LOSS : 0.687407280269422, VALIDATION_LOSS : 0.6780179023742676\n",
            "FOLD : 2, EPOCH : 19, TRAIN_LOSS : 0.6850960411523518, VALIDATION_LOSS : 0.6767125964164734\n",
            "FOLD : 2, EPOCH : 20, TRAIN_LOSS : 0.682629434685958, VALIDATION_LOSS : 0.675475811958313\n",
            "FOLD : 2, EPOCH : 21, TRAIN_LOSS : 0.6799573866944564, VALIDATION_LOSS : 0.6741596937179566\n",
            "FOLD : 2, EPOCH : 22, TRAIN_LOSS : 0.6777670603049429, VALIDATION_LOSS : 0.673025619983673\n",
            "FOLD : 2, EPOCH : 23, TRAIN_LOSS : 0.6752221019644487, VALIDATION_LOSS : 0.6716452002525329\n",
            "FOLD : 2, EPOCH : 24, TRAIN_LOSS : 0.6730894822823373, VALIDATION_LOSS : 0.6701434135437012\n",
            "FOLD : 2, EPOCH : 25, TRAIN_LOSS : 0.6704126031775224, VALIDATION_LOSS : 0.6690396785736084\n",
            "FOLD : 2, EPOCH : 26, TRAIN_LOSS : 0.6677125535513225, VALIDATION_LOSS : 0.6675276637077332\n",
            "FOLD : 2, EPOCH : 27, TRAIN_LOSS : 0.6651698005826849, VALIDATION_LOSS : 0.6655622482299804\n",
            "FOLD : 2, EPOCH : 28, TRAIN_LOSS : 0.6625365207069799, VALIDATION_LOSS : 0.6642340421676636\n",
            "FOLD : 2, EPOCH : 29, TRAIN_LOSS : 0.6601415151043942, VALIDATION_LOSS : 0.6629041194915771\n",
            "FOLD : 2, EPOCH : 30, TRAIN_LOSS : 0.6575671465773332, VALIDATION_LOSS : 0.6609907746315002\n",
            "FOLD : 2, EPOCH : 31, TRAIN_LOSS : 0.6547474233727706, VALIDATION_LOSS : 0.6594380378723145\n",
            "FOLD : 2, EPOCH : 32, TRAIN_LOSS : 0.65196062389173, VALIDATION_LOSS : 0.6580225229263306\n",
            "FOLD : 2, EPOCH : 33, TRAIN_LOSS : 0.6497062099607367, VALIDATION_LOSS : 0.6560191750526428\n",
            "FOLD : 2, EPOCH : 34, TRAIN_LOSS : 0.646748307504152, VALIDATION_LOSS : 0.6540160298347473\n",
            "FOLD : 2, EPOCH : 35, TRAIN_LOSS : 0.6441580057144165, VALIDATION_LOSS : 0.6519513607025147\n",
            "FOLD : 2, EPOCH : 36, TRAIN_LOSS : 0.641476151190306, VALIDATION_LOSS : 0.6502042055130005\n",
            "FOLD : 2, EPOCH : 37, TRAIN_LOSS : 0.6387497751336348, VALIDATION_LOSS : 0.6479908466339112\n",
            "FOLD : 2, EPOCH : 38, TRAIN_LOSS : 0.6359453577744333, VALIDATION_LOSS : 0.6463400483131408\n",
            "FOLD : 2, EPOCH : 39, TRAIN_LOSS : 0.6332554974054035, VALIDATION_LOSS : 0.6438877582550049\n",
            "FOLD : 2, EPOCH : 40, TRAIN_LOSS : 0.6303922533988953, VALIDATION_LOSS : 0.6421168565750122\n",
            "FOLD : 2, EPOCH : 41, TRAIN_LOSS : 0.6275929494907981, VALIDATION_LOSS : 0.6400296568870545\n",
            "FOLD : 2, EPOCH : 42, TRAIN_LOSS : 0.6249334686680844, VALIDATION_LOSS : 0.6382878541946411\n",
            "FOLD : 2, EPOCH : 43, TRAIN_LOSS : 0.6223127747836866, VALIDATION_LOSS : 0.6362096309661865\n",
            "FOLD : 2, EPOCH : 44, TRAIN_LOSS : 0.6197458442888761, VALIDATION_LOSS : 0.6339779615402221\n",
            "FOLD : 2, EPOCH : 45, TRAIN_LOSS : 0.6166915862183822, VALIDATION_LOSS : 0.6317668914794922\n",
            "FOLD : 2, EPOCH : 46, TRAIN_LOSS : 0.614232455429278, VALIDATION_LOSS : 0.6291620969772339\n",
            "FOLD : 2, EPOCH : 47, TRAIN_LOSS : 0.6112309976627952, VALIDATION_LOSS : 0.6273771286010742\n",
            "FOLD : 2, EPOCH : 48, TRAIN_LOSS : 0.6089128349956713, VALIDATION_LOSS : 0.6253655672073364\n",
            "FOLD : 2, EPOCH : 49, TRAIN_LOSS : 0.6059462584947285, VALIDATION_LOSS : 0.6228220701217652\n",
            "FOLD : 2, EPOCH : 50, TRAIN_LOSS : 0.6032776236534119, VALIDATION_LOSS : 0.6207464814186097\n",
            "FOLD : 2, EPOCH : 51, TRAIN_LOSS : 0.6003571184057939, VALIDATION_LOSS : 0.617888081073761\n",
            "FOLD : 2, EPOCH : 52, TRAIN_LOSS : 0.5977635760056345, VALIDATION_LOSS : 0.6165549159049988\n",
            "FOLD : 2, EPOCH : 53, TRAIN_LOSS : 0.5953160116547033, VALIDATION_LOSS : 0.6141098856925964\n",
            "FOLD : 2, EPOCH : 54, TRAIN_LOSS : 0.5926631751813387, VALIDATION_LOSS : 0.6118361830711365\n",
            "FOLD : 2, EPOCH : 55, TRAIN_LOSS : 0.5902596147436845, VALIDATION_LOSS : 0.6097623705863953\n",
            "FOLD : 2, EPOCH : 56, TRAIN_LOSS : 0.5872198970694291, VALIDATION_LOSS : 0.6077757954597474\n",
            "FOLD : 2, EPOCH : 57, TRAIN_LOSS : 0.5846037174526014, VALIDATION_LOSS : 0.605407452583313\n",
            "FOLD : 2, EPOCH : 58, TRAIN_LOSS : 0.5822752651415373, VALIDATION_LOSS : 0.6031272053718567\n",
            "FOLD : 2, EPOCH : 59, TRAIN_LOSS : 0.5796004910218088, VALIDATION_LOSS : 0.6010894775390625\n",
            "FOLD : 2, EPOCH : 60, TRAIN_LOSS : 0.5772473655248943, VALIDATION_LOSS : 0.59945729970932\n",
            "FOLD : 2, EPOCH : 61, TRAIN_LOSS : 0.5743465517696581, VALIDATION_LOSS : 0.5967054605484009\n",
            "FOLD : 2, EPOCH : 62, TRAIN_LOSS : 0.5720388732458416, VALIDATION_LOSS : 0.5949416756629944\n",
            "FOLD : 2, EPOCH : 63, TRAIN_LOSS : 0.5694403271926077, VALIDATION_LOSS : 0.5926492094993592\n",
            "FOLD : 2, EPOCH : 64, TRAIN_LOSS : 0.5668995035322089, VALIDATION_LOSS : 0.5901823520660401\n",
            "FOLD : 2, EPOCH : 65, TRAIN_LOSS : 0.5644653847343043, VALIDATION_LOSS : 0.5882286548614502\n",
            "FOLD : 2, EPOCH : 66, TRAIN_LOSS : 0.5617338167993646, VALIDATION_LOSS : 0.5863189220428466\n",
            "FOLD : 2, EPOCH : 67, TRAIN_LOSS : 0.5595022534069262, VALIDATION_LOSS : 0.5838536739349365\n",
            "FOLD : 2, EPOCH : 68, TRAIN_LOSS : 0.557051137874001, VALIDATION_LOSS : 0.5822859406471252\n",
            "FOLD : 2, EPOCH : 69, TRAIN_LOSS : 0.5544164243497347, VALIDATION_LOSS : 0.579849123954773\n",
            "FOLD : 2, EPOCH : 70, TRAIN_LOSS : 0.5520636000131306, VALIDATION_LOSS : 0.5779475569725037\n",
            "FOLD : 2, EPOCH : 71, TRAIN_LOSS : 0.5496774096237985, VALIDATION_LOSS : 0.5757214307785035\n",
            "FOLD : 2, EPOCH : 72, TRAIN_LOSS : 0.5473741387066088, VALIDATION_LOSS : 0.5735703587532044\n",
            "FOLD : 2, EPOCH : 73, TRAIN_LOSS : 0.5449520506356892, VALIDATION_LOSS : 0.5713976383209228\n",
            "FOLD : 2, EPOCH : 74, TRAIN_LOSS : 0.54243046359012, VALIDATION_LOSS : 0.569195830821991\n",
            "FOLD : 2, EPOCH : 75, TRAIN_LOSS : 0.5403675562457034, VALIDATION_LOSS : 0.5675638556480408\n",
            "FOLD : 2, EPOCH : 76, TRAIN_LOSS : 0.5380026039324308, VALIDATION_LOSS : 0.566005289554596\n",
            "FOLD : 2, EPOCH : 77, TRAIN_LOSS : 0.5355274990985268, VALIDATION_LOSS : 0.563917875289917\n",
            "FOLD : 2, EPOCH : 78, TRAIN_LOSS : 0.5332044645359642, VALIDATION_LOSS : 0.561809527873993\n",
            "FOLD : 2, EPOCH : 79, TRAIN_LOSS : 0.5309265883345353, VALIDATION_LOSS : 0.560006844997406\n",
            "FOLD : 2, EPOCH : 80, TRAIN_LOSS : 0.5285039951926783, VALIDATION_LOSS : 0.5575691223144531\n",
            "FOLD : 2, EPOCH : 81, TRAIN_LOSS : 0.5261315860246357, VALIDATION_LOSS : 0.5556846022605896\n",
            "FOLD : 2, EPOCH : 82, TRAIN_LOSS : 0.5239152469133076, VALIDATION_LOSS : 0.5539275884628296\n",
            "FOLD : 2, EPOCH : 83, TRAIN_LOSS : 0.5218268381921869, VALIDATION_LOSS : 0.5521593689918518\n",
            "FOLD : 2, EPOCH : 84, TRAIN_LOSS : 0.5194815177666513, VALIDATION_LOSS : 0.5497567415237427\n",
            "FOLD : 2, EPOCH : 85, TRAIN_LOSS : 0.5171965893946195, VALIDATION_LOSS : 0.5476215243339538\n",
            "FOLD : 2, EPOCH : 86, TRAIN_LOSS : 0.514978848005596, VALIDATION_LOSS : 0.5456840395927429\n",
            "FOLD : 2, EPOCH : 87, TRAIN_LOSS : 0.5127728079494677, VALIDATION_LOSS : 0.5439458608627319\n",
            "FOLD : 2, EPOCH : 88, TRAIN_LOSS : 0.5105820643274408, VALIDATION_LOSS : 0.5423481702804566\n",
            "FOLD : 2, EPOCH : 89, TRAIN_LOSS : 0.5084348446444461, VALIDATION_LOSS : 0.5404228806495667\n",
            "FOLD : 2, EPOCH : 90, TRAIN_LOSS : 0.5061526549489874, VALIDATION_LOSS : 0.5383545160293579\n",
            "FOLD : 2, EPOCH : 91, TRAIN_LOSS : 0.5039204923730147, VALIDATION_LOSS : 0.5366587281227112\n",
            "FOLD : 2, EPOCH : 92, TRAIN_LOSS : 0.5018971280047768, VALIDATION_LOSS : 0.5348434448242188\n",
            "FOLD : 2, EPOCH : 93, TRAIN_LOSS : 0.4996216987308703, VALIDATION_LOSS : 0.532864797115326\n",
            "FOLD : 2, EPOCH : 94, TRAIN_LOSS : 0.4975915206106086, VALIDATION_LOSS : 0.531640374660492\n",
            "FOLD : 2, EPOCH : 95, TRAIN_LOSS : 0.4953900026647668, VALIDATION_LOSS : 0.5299108028411865\n",
            "FOLD : 2, EPOCH : 96, TRAIN_LOSS : 0.49323303291672155, VALIDATION_LOSS : 0.5280832529067994\n",
            "FOLD : 2, EPOCH : 97, TRAIN_LOSS : 0.4912545775112353, VALIDATION_LOSS : 0.5260586619377137\n",
            "FOLD : 2, EPOCH : 98, TRAIN_LOSS : 0.4889242351055145, VALIDATION_LOSS : 0.5241013884544372\n",
            "FOLD : 2, EPOCH : 99, TRAIN_LOSS : 0.486783272341678, VALIDATION_LOSS : 0.5229082226753234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 3, EPOCH : 0, TRAIN_LOSS : 0.7201183375559355, VALIDATION_LOSS : 0.6947452783584595\n",
            "FOLD : 3, EPOCH : 1, TRAIN_LOSS : 0.717623161642175, VALIDATION_LOSS : 0.6947989344596863\n",
            "FOLD : 3, EPOCH : 2, TRAIN_LOSS : 0.7148794312226144, VALIDATION_LOSS : 0.693965494632721\n",
            "FOLD : 3, EPOCH : 3, TRAIN_LOSS : 0.7125862962321231, VALIDATION_LOSS : 0.6933413624763489\n",
            "FOLD : 3, EPOCH : 4, TRAIN_LOSS : 0.7098628753109982, VALIDATION_LOSS : 0.692673921585083\n",
            "FOLD : 3, EPOCH : 5, TRAIN_LOSS : 0.707296465572558, VALIDATION_LOSS : 0.6919335961341858\n",
            "FOLD : 3, EPOCH : 6, TRAIN_LOSS : 0.7047884401522184, VALIDATION_LOSS : 0.6911597371101379\n",
            "FOLD : 3, EPOCH : 7, TRAIN_LOSS : 0.7022534075536226, VALIDATION_LOSS : 0.6904961705207825\n",
            "FOLD : 3, EPOCH : 8, TRAIN_LOSS : 0.6999354299746061, VALIDATION_LOSS : 0.6894689083099366\n",
            "FOLD : 3, EPOCH : 9, TRAIN_LOSS : 0.6974940990146837, VALIDATION_LOSS : 0.6885799050331116\n",
            "FOLD : 3, EPOCH : 10, TRAIN_LOSS : 0.6948109833817733, VALIDATION_LOSS : 0.6877121210098267\n",
            "FOLD : 3, EPOCH : 11, TRAIN_LOSS : 0.6924192340750444, VALIDATION_LOSS : 0.6868171572685242\n",
            "FOLD : 3, EPOCH : 12, TRAIN_LOSS : 0.6900388033766496, VALIDATION_LOSS : 0.6855630159378052\n",
            "FOLD : 3, EPOCH : 13, TRAIN_LOSS : 0.6875883874140287, VALIDATION_LOSS : 0.6847755670547485\n",
            "FOLD : 3, EPOCH : 14, TRAIN_LOSS : 0.6850291521925675, VALIDATION_LOSS : 0.6834756731987\n",
            "FOLD : 3, EPOCH : 15, TRAIN_LOSS : 0.6824391515631425, VALIDATION_LOSS : 0.6823613166809082\n",
            "FOLD : 3, EPOCH : 16, TRAIN_LOSS : 0.6799294164306239, VALIDATION_LOSS : 0.6812056779861451\n",
            "FOLD : 3, EPOCH : 17, TRAIN_LOSS : 0.6774170869275143, VALIDATION_LOSS : 0.6798835873603821\n",
            "FOLD : 3, EPOCH : 18, TRAIN_LOSS : 0.6748627047789725, VALIDATION_LOSS : 0.6784995079040528\n",
            "FOLD : 3, EPOCH : 19, TRAIN_LOSS : 0.6721900419185036, VALIDATION_LOSS : 0.6770542621612549\n",
            "FOLD : 3, EPOCH : 20, TRAIN_LOSS : 0.6696678431410539, VALIDATION_LOSS : 0.6756579399108886\n",
            "FOLD : 3, EPOCH : 21, TRAIN_LOSS : 0.6669136128927532, VALIDATION_LOSS : 0.6742800354957581\n",
            "FOLD : 3, EPOCH : 22, TRAIN_LOSS : 0.6643541047447606, VALIDATION_LOSS : 0.6728561878204345\n",
            "FOLD : 3, EPOCH : 23, TRAIN_LOSS : 0.6618401094486839, VALIDATION_LOSS : 0.6711204171180725\n",
            "FOLD : 3, EPOCH : 24, TRAIN_LOSS : 0.6591318626152841, VALIDATION_LOSS : 0.6694909572601319\n",
            "FOLD : 3, EPOCH : 25, TRAIN_LOSS : 0.656508417505967, VALIDATION_LOSS : 0.6678040266036988\n",
            "FOLD : 3, EPOCH : 26, TRAIN_LOSS : 0.6537967292886031, VALIDATION_LOSS : 0.6661532163619995\n",
            "FOLD : 3, EPOCH : 27, TRAIN_LOSS : 0.6510145256393834, VALIDATION_LOSS : 0.6642945051193238\n",
            "FOLD : 3, EPOCH : 28, TRAIN_LOSS : 0.6484672615402624, VALIDATION_LOSS : 0.6622749090194702\n",
            "FOLD : 3, EPOCH : 29, TRAIN_LOSS : 0.6456816353295979, VALIDATION_LOSS : 0.6605867385864258\n",
            "FOLD : 3, EPOCH : 30, TRAIN_LOSS : 0.6429403612488195, VALIDATION_LOSS : 0.6587298750877381\n",
            "FOLD : 3, EPOCH : 31, TRAIN_LOSS : 0.6400183972559477, VALIDATION_LOSS : 0.6565810441970825\n",
            "FOLD : 3, EPOCH : 32, TRAIN_LOSS : 0.6376390770861977, VALIDATION_LOSS : 0.6548512220382691\n",
            "FOLD : 3, EPOCH : 33, TRAIN_LOSS : 0.6348158717155457, VALIDATION_LOSS : 0.6526130199432373\n",
            "FOLD : 3, EPOCH : 34, TRAIN_LOSS : 0.6322179781763178, VALIDATION_LOSS : 0.6504058599472046\n",
            "FOLD : 3, EPOCH : 35, TRAIN_LOSS : 0.6292823615827059, VALIDATION_LOSS : 0.6485268592834472\n",
            "FOLD : 3, EPOCH : 36, TRAIN_LOSS : 0.6266217012154428, VALIDATION_LOSS : 0.6464988827705384\n",
            "FOLD : 3, EPOCH : 37, TRAIN_LOSS : 0.6238036312555012, VALIDATION_LOSS : 0.6442743420600892\n",
            "FOLD : 3, EPOCH : 38, TRAIN_LOSS : 0.6212924373777289, VALIDATION_LOSS : 0.642055070400238\n",
            "FOLD : 3, EPOCH : 39, TRAIN_LOSS : 0.6184911602421811, VALIDATION_LOSS : 0.6394482374191284\n",
            "FOLD : 3, EPOCH : 40, TRAIN_LOSS : 0.6156538066111112, VALIDATION_LOSS : 0.6372867941856384\n",
            "FOLD : 3, EPOCH : 41, TRAIN_LOSS : 0.6131631230053148, VALIDATION_LOSS : 0.6349788546562195\n",
            "FOLD : 3, EPOCH : 42, TRAIN_LOSS : 0.610626104630922, VALIDATION_LOSS : 0.6328332543373107\n",
            "FOLD : 3, EPOCH : 43, TRAIN_LOSS : 0.6078953993947882, VALIDATION_LOSS : 0.6307394742965698\n",
            "FOLD : 3, EPOCH : 44, TRAIN_LOSS : 0.6051185507523386, VALIDATION_LOSS : 0.6284273386001586\n",
            "FOLD : 3, EPOCH : 45, TRAIN_LOSS : 0.6024911874218991, VALIDATION_LOSS : 0.6262045502662659\n",
            "FOLD : 3, EPOCH : 46, TRAIN_LOSS : 0.5998198076298362, VALIDATION_LOSS : 0.6241238594055176\n",
            "FOLD : 3, EPOCH : 47, TRAIN_LOSS : 0.5971939563751221, VALIDATION_LOSS : 0.6216488242149353\n",
            "FOLD : 3, EPOCH : 48, TRAIN_LOSS : 0.5945714367063422, VALIDATION_LOSS : 0.6192241311073303\n",
            "FOLD : 3, EPOCH : 49, TRAIN_LOSS : 0.5921001183359247, VALIDATION_LOSS : 0.6167610168457032\n",
            "FOLD : 3, EPOCH : 50, TRAIN_LOSS : 0.5896867890107004, VALIDATION_LOSS : 0.6143917798995971\n",
            "FOLD : 3, EPOCH : 51, TRAIN_LOSS : 0.5869930229688946, VALIDATION_LOSS : 0.6118478417396546\n",
            "FOLD : 3, EPOCH : 52, TRAIN_LOSS : 0.58421160045423, VALIDATION_LOSS : 0.6096127152442932\n",
            "FOLD : 3, EPOCH : 53, TRAIN_LOSS : 0.5818751956287184, VALIDATION_LOSS : 0.6075231075286865\n",
            "FOLD : 3, EPOCH : 54, TRAIN_LOSS : 0.5790834364138151, VALIDATION_LOSS : 0.6048736572265625\n",
            "FOLD : 3, EPOCH : 55, TRAIN_LOSS : 0.5768274351170188, VALIDATION_LOSS : 0.6019789099693298\n",
            "FOLD : 3, EPOCH : 56, TRAIN_LOSS : 0.5741851863108183, VALIDATION_LOSS : 0.6003337740898133\n",
            "FOLD : 3, EPOCH : 57, TRAIN_LOSS : 0.5717056581848546, VALIDATION_LOSS : 0.5977907061576844\n",
            "FOLD : 3, EPOCH : 58, TRAIN_LOSS : 0.5691966979127181, VALIDATION_LOSS : 0.5952082991600036\n",
            "FOLD : 3, EPOCH : 59, TRAIN_LOSS : 0.5667676392354464, VALIDATION_LOSS : 0.5933428287506104\n",
            "FOLD : 3, EPOCH : 60, TRAIN_LOSS : 0.5643531021318937, VALIDATION_LOSS : 0.5908151268959045\n",
            "FOLD : 3, EPOCH : 61, TRAIN_LOSS : 0.5618756162492853, VALIDATION_LOSS : 0.5883822202682495\n",
            "FOLD : 3, EPOCH : 62, TRAIN_LOSS : 0.5593674120150114, VALIDATION_LOSS : 0.5861155390739441\n",
            "FOLD : 3, EPOCH : 63, TRAIN_LOSS : 0.5568061063164159, VALIDATION_LOSS : 0.583589231967926\n",
            "FOLD : 3, EPOCH : 64, TRAIN_LOSS : 0.5545165099595722, VALIDATION_LOSS : 0.582120931148529\n",
            "FOLD : 3, EPOCH : 65, TRAIN_LOSS : 0.5523406988696048, VALIDATION_LOSS : 0.5794058322906495\n",
            "FOLD : 3, EPOCH : 66, TRAIN_LOSS : 0.5498909291468168, VALIDATION_LOSS : 0.577158260345459\n",
            "FOLD : 3, EPOCH : 67, TRAIN_LOSS : 0.5472310091319837, VALIDATION_LOSS : 0.5746883988380432\n",
            "FOLD : 3, EPOCH : 68, TRAIN_LOSS : 0.5449497040949369, VALIDATION_LOSS : 0.5724098324775696\n",
            "FOLD : 3, EPOCH : 69, TRAIN_LOSS : 0.5426313406542728, VALIDATION_LOSS : 0.5696417927742005\n",
            "FOLD : 3, EPOCH : 70, TRAIN_LOSS : 0.5403560776459543, VALIDATION_LOSS : 0.5682068347930909\n",
            "FOLD : 3, EPOCH : 71, TRAIN_LOSS : 0.5382629695691561, VALIDATION_LOSS : 0.5656043887138367\n",
            "FOLD : 3, EPOCH : 72, TRAIN_LOSS : 0.5357040198225724, VALIDATION_LOSS : 0.5633996367454529\n",
            "FOLD : 3, EPOCH : 73, TRAIN_LOSS : 0.5332342919550443, VALIDATION_LOSS : 0.5610511183738709\n",
            "FOLD : 3, EPOCH : 74, TRAIN_LOSS : 0.5310270315722415, VALIDATION_LOSS : 0.5585530757904053\n",
            "FOLD : 3, EPOCH : 75, TRAIN_LOSS : 0.52879357024243, VALIDATION_LOSS : 0.5568966865539551\n",
            "FOLD : 3, EPOCH : 76, TRAIN_LOSS : 0.5265924397267794, VALIDATION_LOSS : 0.5545628428459167\n",
            "FOLD : 3, EPOCH : 77, TRAIN_LOSS : 0.5240405201911926, VALIDATION_LOSS : 0.5520875692367554\n",
            "FOLD : 3, EPOCH : 78, TRAIN_LOSS : 0.5219701120727941, VALIDATION_LOSS : 0.5501085638999939\n",
            "FOLD : 3, EPOCH : 79, TRAIN_LOSS : 0.5198283415091666, VALIDATION_LOSS : 0.5476421475410461\n",
            "FOLD : 3, EPOCH : 80, TRAIN_LOSS : 0.5176142705114264, VALIDATION_LOSS : 0.5453201413154602\n",
            "FOLD : 3, EPOCH : 81, TRAIN_LOSS : 0.5151843114903099, VALIDATION_LOSS : 0.5432626843452454\n",
            "FOLD : 3, EPOCH : 82, TRAIN_LOSS : 0.5129963975203665, VALIDATION_LOSS : 0.5414985895156861\n",
            "FOLD : 3, EPOCH : 83, TRAIN_LOSS : 0.5110762652597929, VALIDATION_LOSS : 0.5389960646629334\n",
            "FOLD : 3, EPOCH : 84, TRAIN_LOSS : 0.5088404699375755, VALIDATION_LOSS : 0.5373547196388244\n",
            "FOLD : 3, EPOCH : 85, TRAIN_LOSS : 0.5064198908052946, VALIDATION_LOSS : 0.535272228717804\n",
            "FOLD : 3, EPOCH : 86, TRAIN_LOSS : 0.504225094067423, VALIDATION_LOSS : 0.5323332905769348\n",
            "FOLD : 3, EPOCH : 87, TRAIN_LOSS : 0.5024187345253793, VALIDATION_LOSS : 0.5304884910583496\n",
            "FOLD : 3, EPOCH : 88, TRAIN_LOSS : 0.4998994297102878, VALIDATION_LOSS : 0.5285725116729736\n",
            "FOLD : 3, EPOCH : 89, TRAIN_LOSS : 0.4978826642036438, VALIDATION_LOSS : 0.5266042470932006\n",
            "FOLD : 3, EPOCH : 90, TRAIN_LOSS : 0.4958129289903139, VALIDATION_LOSS : 0.5251680612564087\n",
            "FOLD : 3, EPOCH : 91, TRAIN_LOSS : 0.49376303428097773, VALIDATION_LOSS : 0.5237395763397217\n",
            "FOLD : 3, EPOCH : 92, TRAIN_LOSS : 0.4915366110048796, VALIDATION_LOSS : 0.520701789855957\n",
            "FOLD : 3, EPOCH : 93, TRAIN_LOSS : 0.4894888244177166, VALIDATION_LOSS : 0.5190375685691834\n",
            "FOLD : 3, EPOCH : 94, TRAIN_LOSS : 0.4873430274034801, VALIDATION_LOSS : 0.5168611884117127\n",
            "FOLD : 3, EPOCH : 95, TRAIN_LOSS : 0.48543902604203476, VALIDATION_LOSS : 0.5150371789932251\n",
            "FOLD : 3, EPOCH : 96, TRAIN_LOSS : 0.483593507816917, VALIDATION_LOSS : 0.5129722356796265\n",
            "FOLD : 3, EPOCH : 97, TRAIN_LOSS : 0.481258058234265, VALIDATION_LOSS : 0.5113980412483216\n",
            "FOLD : 3, EPOCH : 98, TRAIN_LOSS : 0.4792804733703011, VALIDATION_LOSS : 0.5095999479293823\n",
            "FOLD : 3, EPOCH : 99, TRAIN_LOSS : 0.4771870421735864, VALIDATION_LOSS : 0.5074003338813782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 0, TRAIN_LOSS : 0.7211227260137859, VALIDATION_LOSS : 0.6927578687667847\n",
            "FOLD : 4, EPOCH : 1, TRAIN_LOSS : 0.7183453377924467, VALIDATION_LOSS : 0.6915111660957336\n",
            "FOLD : 4, EPOCH : 2, TRAIN_LOSS : 0.7155055372338546, VALIDATION_LOSS : 0.6907449007034302\n",
            "FOLD : 4, EPOCH : 3, TRAIN_LOSS : 0.7129587499718917, VALIDATION_LOSS : 0.690044903755188\n",
            "FOLD : 4, EPOCH : 4, TRAIN_LOSS : 0.7106836249953822, VALIDATION_LOSS : 0.6897180795669555\n",
            "FOLD : 4, EPOCH : 5, TRAIN_LOSS : 0.7080895273309005, VALIDATION_LOSS : 0.6887727737426758\n",
            "FOLD : 4, EPOCH : 6, TRAIN_LOSS : 0.7056702281299391, VALIDATION_LOSS : 0.6881655693054199\n",
            "FOLD : 4, EPOCH : 7, TRAIN_LOSS : 0.7031386149557013, VALIDATION_LOSS : 0.6873313784599304\n",
            "FOLD : 4, EPOCH : 8, TRAIN_LOSS : 0.7005119888406051, VALIDATION_LOSS : 0.6866261124610901\n",
            "FOLD : 4, EPOCH : 9, TRAIN_LOSS : 0.6978146433830261, VALIDATION_LOSS : 0.6857253789901734\n",
            "FOLD : 4, EPOCH : 10, TRAIN_LOSS : 0.6955729691605819, VALIDATION_LOSS : 0.6849137902259826\n",
            "FOLD : 4, EPOCH : 11, TRAIN_LOSS : 0.6929708562399212, VALIDATION_LOSS : 0.6839255809783935\n",
            "FOLD : 4, EPOCH : 12, TRAIN_LOSS : 0.690227819116492, VALIDATION_LOSS : 0.6828174948692322\n",
            "FOLD : 4, EPOCH : 13, TRAIN_LOSS : 0.6877578340078655, VALIDATION_LOSS : 0.6819759011268616\n",
            "FOLD : 4, EPOCH : 14, TRAIN_LOSS : 0.6854319321481805, VALIDATION_LOSS : 0.6810812592506409\n",
            "FOLD : 4, EPOCH : 15, TRAIN_LOSS : 0.6826703360206202, VALIDATION_LOSS : 0.6802023649215698\n",
            "FOLD : 4, EPOCH : 16, TRAIN_LOSS : 0.6800106167793274, VALIDATION_LOSS : 0.6789447665214539\n",
            "FOLD : 4, EPOCH : 17, TRAIN_LOSS : 0.6776989980747825, VALIDATION_LOSS : 0.6776931643486023\n",
            "FOLD : 4, EPOCH : 18, TRAIN_LOSS : 0.6748867881925482, VALIDATION_LOSS : 0.6766278743743896\n",
            "FOLD : 4, EPOCH : 19, TRAIN_LOSS : 0.6723374724388123, VALIDATION_LOSS : 0.6751451849937439\n",
            "FOLD : 4, EPOCH : 20, TRAIN_LOSS : 0.6698468327522278, VALIDATION_LOSS : 0.6741400241851807\n",
            "FOLD : 4, EPOCH : 21, TRAIN_LOSS : 0.6673857726548847, VALIDATION_LOSS : 0.6728342771530151\n",
            "FOLD : 4, EPOCH : 22, TRAIN_LOSS : 0.6646370197597303, VALIDATION_LOSS : 0.6713758707046509\n",
            "FOLD : 4, EPOCH : 23, TRAIN_LOSS : 0.6617828136996219, VALIDATION_LOSS : 0.6698079466819763\n",
            "FOLD : 4, EPOCH : 24, TRAIN_LOSS : 0.6593118278603805, VALIDATION_LOSS : 0.6686275124549865\n",
            "FOLD : 4, EPOCH : 25, TRAIN_LOSS : 0.6567749914370085, VALIDATION_LOSS : 0.6669311881065368\n",
            "FOLD : 4, EPOCH : 26, TRAIN_LOSS : 0.6537900033750033, VALIDATION_LOSS : 0.6653345704078675\n",
            "FOLD : 4, EPOCH : 27, TRAIN_LOSS : 0.6513277292251587, VALIDATION_LOSS : 0.6639395594596863\n",
            "FOLD : 4, EPOCH : 28, TRAIN_LOSS : 0.6485255172378138, VALIDATION_LOSS : 0.6620500206947326\n",
            "FOLD : 4, EPOCH : 29, TRAIN_LOSS : 0.64576382386057, VALIDATION_LOSS : 0.6606008172035217\n",
            "FOLD : 4, EPOCH : 30, TRAIN_LOSS : 0.6431955161847567, VALIDATION_LOSS : 0.6591084957122803\n",
            "FOLD : 4, EPOCH : 31, TRAIN_LOSS : 0.6403866849447551, VALIDATION_LOSS : 0.6573463678359985\n",
            "FOLD : 4, EPOCH : 32, TRAIN_LOSS : 0.6377895850884286, VALIDATION_LOSS : 0.655655026435852\n",
            "FOLD : 4, EPOCH : 33, TRAIN_LOSS : 0.6349977443092748, VALIDATION_LOSS : 0.6539218783378601\n",
            "FOLD : 4, EPOCH : 34, TRAIN_LOSS : 0.6323457830830624, VALIDATION_LOSS : 0.6521613955497741\n",
            "FOLD : 4, EPOCH : 35, TRAIN_LOSS : 0.6295615748355263, VALIDATION_LOSS : 0.650381350517273\n",
            "FOLD : 4, EPOCH : 36, TRAIN_LOSS : 0.6270173599845484, VALIDATION_LOSS : 0.648669707775116\n",
            "FOLD : 4, EPOCH : 37, TRAIN_LOSS : 0.6243984040461088, VALIDATION_LOSS : 0.6472107529640198\n",
            "FOLD : 4, EPOCH : 38, TRAIN_LOSS : 0.6216809812345003, VALIDATION_LOSS : 0.6449664115905762\n",
            "FOLD : 4, EPOCH : 39, TRAIN_LOSS : 0.6187430839789542, VALIDATION_LOSS : 0.643644368648529\n",
            "FOLD : 4, EPOCH : 40, TRAIN_LOSS : 0.61601070667568, VALIDATION_LOSS : 0.6419743061065674\n",
            "FOLD : 4, EPOCH : 41, TRAIN_LOSS : 0.613455571626362, VALIDATION_LOSS : 0.6398763656616211\n",
            "FOLD : 4, EPOCH : 42, TRAIN_LOSS : 0.6110222904305709, VALIDATION_LOSS : 0.6379417181015015\n",
            "FOLD : 4, EPOCH : 43, TRAIN_LOSS : 0.6080139718557659, VALIDATION_LOSS : 0.6362089514732361\n",
            "FOLD : 4, EPOCH : 44, TRAIN_LOSS : 0.6057795631258112, VALIDATION_LOSS : 0.6343554139137269\n",
            "FOLD : 4, EPOCH : 45, TRAIN_LOSS : 0.6030311019797074, VALIDATION_LOSS : 0.6323033094406127\n",
            "FOLD : 4, EPOCH : 46, TRAIN_LOSS : 0.60042426146959, VALIDATION_LOSS : 0.6306105494499207\n",
            "FOLD : 4, EPOCH : 47, TRAIN_LOSS : 0.5978012837861714, VALIDATION_LOSS : 0.6289334893226624\n",
            "FOLD : 4, EPOCH : 48, TRAIN_LOSS : 0.595264732837677, VALIDATION_LOSS : 0.6270501136779785\n",
            "FOLD : 4, EPOCH : 49, TRAIN_LOSS : 0.5926084455690885, VALIDATION_LOSS : 0.6249764323234558\n",
            "FOLD : 4, EPOCH : 50, TRAIN_LOSS : 0.5901512189915306, VALIDATION_LOSS : 0.6230238318443299\n",
            "FOLD : 4, EPOCH : 51, TRAIN_LOSS : 0.5875919774958962, VALIDATION_LOSS : 0.6212068557739258\n",
            "FOLD : 4, EPOCH : 52, TRAIN_LOSS : 0.5849176864874991, VALIDATION_LOSS : 0.6188938975334167\n",
            "FOLD : 4, EPOCH : 53, TRAIN_LOSS : 0.5825676604321128, VALIDATION_LOSS : 0.6174482107162476\n",
            "FOLD : 4, EPOCH : 54, TRAIN_LOSS : 0.5798507489656147, VALIDATION_LOSS : 0.6158046364784241\n",
            "FOLD : 4, EPOCH : 55, TRAIN_LOSS : 0.577351639145299, VALIDATION_LOSS : 0.6137243986129761\n",
            "FOLD : 4, EPOCH : 56, TRAIN_LOSS : 0.574844617592661, VALIDATION_LOSS : 0.611647093296051\n",
            "FOLD : 4, EPOCH : 57, TRAIN_LOSS : 0.5723936400915447, VALIDATION_LOSS : 0.6098907947540283\n",
            "FOLD : 4, EPOCH : 58, TRAIN_LOSS : 0.5702064852965506, VALIDATION_LOSS : 0.6083243489265442\n",
            "FOLD : 4, EPOCH : 59, TRAIN_LOSS : 0.567560054753956, VALIDATION_LOSS : 0.6064087748527527\n",
            "FOLD : 4, EPOCH : 60, TRAIN_LOSS : 0.5648758913341322, VALIDATION_LOSS : 0.6051462173461915\n",
            "FOLD : 4, EPOCH : 61, TRAIN_LOSS : 0.5625701295702081, VALIDATION_LOSS : 0.603027606010437\n",
            "FOLD : 4, EPOCH : 62, TRAIN_LOSS : 0.5601641629871569, VALIDATION_LOSS : 0.6003642916679383\n",
            "FOLD : 4, EPOCH : 63, TRAIN_LOSS : 0.5579550423120198, VALIDATION_LOSS : 0.5988543033599854\n",
            "FOLD : 4, EPOCH : 64, TRAIN_LOSS : 0.5554066049425226, VALIDATION_LOSS : 0.5968007326126099\n",
            "FOLD : 4, EPOCH : 65, TRAIN_LOSS : 0.5530671038125691, VALIDATION_LOSS : 0.5949968695640564\n",
            "FOLD : 4, EPOCH : 66, TRAIN_LOSS : 0.550749232894496, VALIDATION_LOSS : 0.5938447713851929\n",
            "FOLD : 4, EPOCH : 67, TRAIN_LOSS : 0.5481130668991491, VALIDATION_LOSS : 0.5916016697883606\n",
            "FOLD : 4, EPOCH : 68, TRAIN_LOSS : 0.5458805215986151, VALIDATION_LOSS : 0.5895397424697876\n",
            "FOLD : 4, EPOCH : 69, TRAIN_LOSS : 0.5434851269972952, VALIDATION_LOSS : 0.5873491168022156\n",
            "FOLD : 4, EPOCH : 70, TRAIN_LOSS : 0.5411783707769293, VALIDATION_LOSS : 0.5862026572227478\n",
            "FOLD : 4, EPOCH : 71, TRAIN_LOSS : 0.5388322849022714, VALIDATION_LOSS : 0.5844370603561402\n",
            "FOLD : 4, EPOCH : 72, TRAIN_LOSS : 0.5368312126711795, VALIDATION_LOSS : 0.5826928853988648\n",
            "FOLD : 4, EPOCH : 73, TRAIN_LOSS : 0.5342326666179457, VALIDATION_LOSS : 0.5806643486022949\n",
            "FOLD : 4, EPOCH : 74, TRAIN_LOSS : 0.5319088822916934, VALIDATION_LOSS : 0.5790925741195678\n",
            "FOLD : 4, EPOCH : 75, TRAIN_LOSS : 0.5296058152851305, VALIDATION_LOSS : 0.576951003074646\n",
            "FOLD : 4, EPOCH : 76, TRAIN_LOSS : 0.5277343611968192, VALIDATION_LOSS : 0.5752955794334411\n",
            "FOLD : 4, EPOCH : 77, TRAIN_LOSS : 0.5253114072900069, VALIDATION_LOSS : 0.574127197265625\n",
            "FOLD : 4, EPOCH : 78, TRAIN_LOSS : 0.5229597311270865, VALIDATION_LOSS : 0.5721138000488282\n",
            "FOLD : 4, EPOCH : 79, TRAIN_LOSS : 0.5207123411329169, VALIDATION_LOSS : 0.5703665375709533\n",
            "FOLD : 4, EPOCH : 80, TRAIN_LOSS : 0.5187331281210247, VALIDATION_LOSS : 0.5690293192863465\n",
            "FOLD : 4, EPOCH : 81, TRAIN_LOSS : 0.5161697990015933, VALIDATION_LOSS : 0.566870653629303\n",
            "FOLD : 4, EPOCH : 82, TRAIN_LOSS : 0.5140793919563293, VALIDATION_LOSS : 0.5651185035705566\n",
            "FOLD : 4, EPOCH : 83, TRAIN_LOSS : 0.5117873518090499, VALIDATION_LOSS : 0.5632321238517761\n",
            "FOLD : 4, EPOCH : 84, TRAIN_LOSS : 0.5097594167056837, VALIDATION_LOSS : 0.5615538835525513\n",
            "FOLD : 4, EPOCH : 85, TRAIN_LOSS : 0.5075149442020216, VALIDATION_LOSS : 0.560171115398407\n",
            "FOLD : 4, EPOCH : 86, TRAIN_LOSS : 0.5052147037104556, VALIDATION_LOSS : 0.5587629079818726\n",
            "FOLD : 4, EPOCH : 87, TRAIN_LOSS : 0.503337844421989, VALIDATION_LOSS : 0.5568123459815979\n",
            "FOLD : 4, EPOCH : 88, TRAIN_LOSS : 0.5010096493520235, VALIDATION_LOSS : 0.5547617077827454\n",
            "FOLD : 4, EPOCH : 89, TRAIN_LOSS : 0.4987556730446063, VALIDATION_LOSS : 0.5536535620689392\n",
            "FOLD : 4, EPOCH : 90, TRAIN_LOSS : 0.4966755932883212, VALIDATION_LOSS : 0.5514398694038392\n",
            "FOLD : 4, EPOCH : 91, TRAIN_LOSS : 0.4946063788313615, VALIDATION_LOSS : 0.549921703338623\n",
            "FOLD : 4, EPOCH : 92, TRAIN_LOSS : 0.4925209111288974, VALIDATION_LOSS : 0.5482420325279236\n",
            "FOLD : 4, EPOCH : 93, TRAIN_LOSS : 0.49039293433490555, VALIDATION_LOSS : 0.5472150206565857\n",
            "FOLD : 4, EPOCH : 94, TRAIN_LOSS : 0.48835440058457225, VALIDATION_LOSS : 0.5451616287231446\n",
            "FOLD : 4, EPOCH : 95, TRAIN_LOSS : 0.4861107970538892, VALIDATION_LOSS : 0.5438703417778015\n",
            "FOLD : 4, EPOCH : 96, TRAIN_LOSS : 0.4842346263559241, VALIDATION_LOSS : 0.5417580604553223\n",
            "FOLD : 4, EPOCH : 97, TRAIN_LOSS : 0.4821887173150715, VALIDATION_LOSS : 0.5400032877922059\n",
            "FOLD : 4, EPOCH : 98, TRAIN_LOSS : 0.4800683103109661, VALIDATION_LOSS : 0.5387523651123047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-11-01 14:16:30,361]\u001b[0m Trial 1 finished with value: 0.5280126667022704 and parameters: {'num_layers': 5, 'hidden_size': 419, 'dropout': 0.43325578224094596, 'learning_rate': 1.8772396050092454e-06}. Best is trial 0 with value: 0.016165807619690897.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 99, TRAIN_LOSS : 0.47824197066457647, VALIDATION_LOSS : 0.5375503301620483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 0, EPOCH : 0, TRAIN_LOSS : 0.15876877072610354, VALIDATION_LOSS : 0.19771230220794678\n",
            "FOLD : 0, EPOCH : 1, TRAIN_LOSS : 0.02279984666720817, VALIDATION_LOSS : 0.08406617194414139\n",
            "FOLD : 0, EPOCH : 2, TRAIN_LOSS : 0.02128950722123447, VALIDATION_LOSS : 0.09292066246271133\n",
            "FOLD : 0, EPOCH : 3, TRAIN_LOSS : 0.02054861236951853, VALIDATION_LOSS : 0.05507084652781487\n",
            "FOLD : 0, EPOCH : 4, TRAIN_LOSS : 0.020078213395256745, VALIDATION_LOSS : 0.054095666855573654\n",
            "FOLD : 0, EPOCH : 5, TRAIN_LOSS : 0.019736174199926227, VALIDATION_LOSS : 0.06257250607013702\n",
            "FOLD : 0, EPOCH : 6, TRAIN_LOSS : 0.019388491287827492, VALIDATION_LOSS : 0.045055069774389264\n",
            "FOLD : 0, EPOCH : 7, TRAIN_LOSS : 0.01910831671404211, VALIDATION_LOSS : 0.041938316822052\n",
            "FOLD : 0, EPOCH : 8, TRAIN_LOSS : 0.018725739399853506, VALIDATION_LOSS : 0.0379726953804493\n",
            "FOLD : 0, EPOCH : 9, TRAIN_LOSS : 0.01847383321115845, VALIDATION_LOSS : 0.036936725676059726\n",
            "FOLD : 0, EPOCH : 10, TRAIN_LOSS : 0.018222374253367122, VALIDATION_LOSS : 0.02967194505035877\n",
            "FOLD : 0, EPOCH : 11, TRAIN_LOSS : 0.017985651269555092, VALIDATION_LOSS : 0.028826044872403145\n",
            "FOLD : 0, EPOCH : 12, TRAIN_LOSS : 0.017812797505604595, VALIDATION_LOSS : 0.027908234298229216\n",
            "FOLD : 0, EPOCH : 13, TRAIN_LOSS : 0.0176062239824157, VALIDATION_LOSS : 0.02586873881518841\n",
            "FOLD : 0, EPOCH : 14, TRAIN_LOSS : 0.01746123842895031, VALIDATION_LOSS : 0.02581277973949909\n",
            "FOLD : 0, EPOCH : 15, TRAIN_LOSS : 0.017280655667970057, VALIDATION_LOSS : 0.02434162013232708\n",
            "FOLD : 0, EPOCH : 16, TRAIN_LOSS : 0.017157996563534988, VALIDATION_LOSS : 0.023116509988904\n",
            "FOLD : 0, EPOCH : 17, TRAIN_LOSS : 0.01701751949363633, VALIDATION_LOSS : 0.021920952200889587\n",
            "FOLD : 0, EPOCH : 18, TRAIN_LOSS : 0.016913836625845807, VALIDATION_LOSS : 0.021595286950469018\n",
            "FOLD : 0, EPOCH : 19, TRAIN_LOSS : 0.01677586481367287, VALIDATION_LOSS : 0.020367460325360298\n",
            "FOLD : 0, EPOCH : 20, TRAIN_LOSS : 0.01665527530406651, VALIDATION_LOSS : 0.01975545473396778\n",
            "FOLD : 0, EPOCH : 21, TRAIN_LOSS : 0.016583507096296864, VALIDATION_LOSS : 0.01950408034026623\n",
            "FOLD : 0, EPOCH : 22, TRAIN_LOSS : 0.01645524652772828, VALIDATION_LOSS : 0.01845586933195591\n",
            "FOLD : 0, EPOCH : 23, TRAIN_LOSS : 0.016393882761660376, VALIDATION_LOSS : 0.018461324274539948\n",
            "FOLD : 0, EPOCH : 24, TRAIN_LOSS : 0.016206750499182625, VALIDATION_LOSS : 0.018167293071746825\n",
            "FOLD : 0, EPOCH : 25, TRAIN_LOSS : 0.0162033478386308, VALIDATION_LOSS : 0.017778722941875456\n",
            "FOLD : 0, EPOCH : 26, TRAIN_LOSS : 0.0160589810264738, VALIDATION_LOSS : 0.017379362508654593\n",
            "FOLD : 0, EPOCH : 27, TRAIN_LOSS : 0.016002214513719082, VALIDATION_LOSS : 0.017461664602160455\n",
            "FOLD : 0, EPOCH : 28, TRAIN_LOSS : 0.015908617036123025, VALIDATION_LOSS : 0.01734834648668766\n",
            "FOLD : 0, EPOCH : 29, TRAIN_LOSS : 0.01585232084126849, VALIDATION_LOSS : 0.017083366215229035\n",
            "FOLD : 0, EPOCH : 30, TRAIN_LOSS : 0.01578604900523236, VALIDATION_LOSS : 0.016825799271464346\n",
            "FOLD : 0, EPOCH : 31, TRAIN_LOSS : 0.015669984988083963, VALIDATION_LOSS : 0.016608739644289015\n",
            "FOLD : 0, EPOCH : 32, TRAIN_LOSS : 0.015569488763024933, VALIDATION_LOSS : 0.01675286814570427\n",
            "FOLD : 0, EPOCH : 33, TRAIN_LOSS : 0.015545872922398542, VALIDATION_LOSS : 0.016531913727521896\n",
            "FOLD : 0, EPOCH : 34, TRAIN_LOSS : 0.015396494320348689, VALIDATION_LOSS : 0.01640322618186474\n",
            "FOLD : 0, EPOCH : 35, TRAIN_LOSS : 0.015391857510334566, VALIDATION_LOSS : 0.016318995505571365\n",
            "FOLD : 0, EPOCH : 36, TRAIN_LOSS : 0.015306086818638601, VALIDATION_LOSS : 0.016279000043869018\n",
            "FOLD : 0, EPOCH : 37, TRAIN_LOSS : 0.015248344132774755, VALIDATION_LOSS : 0.016219604387879373\n",
            "FOLD : 0, EPOCH : 38, TRAIN_LOSS : 0.0151017576358036, VALIDATION_LOSS : 0.01619742438197136\n",
            "FOLD : 0, EPOCH : 39, TRAIN_LOSS : 0.015049727927697333, VALIDATION_LOSS : 0.0160914596170187\n",
            "FOLD : 0, EPOCH : 40, TRAIN_LOSS : 0.015023307041510156, VALIDATION_LOSS : 0.016060951352119445\n",
            "FOLD : 0, EPOCH : 41, TRAIN_LOSS : 0.01490463527213586, VALIDATION_LOSS : 0.016107069328427315\n",
            "FOLD : 0, EPOCH : 42, TRAIN_LOSS : 0.01487411749794295, VALIDATION_LOSS : 0.015995651856064795\n",
            "FOLD : 0, EPOCH : 43, TRAIN_LOSS : 0.014741792931760611, VALIDATION_LOSS : 0.016057297587394714\n",
            "FOLD : 0, EPOCH : 44, TRAIN_LOSS : 0.014679843412810251, VALIDATION_LOSS : 0.01595351882278919\n",
            "FOLD : 0, EPOCH : 45, TRAIN_LOSS : 0.014614895280254515, VALIDATION_LOSS : 0.0159311780706048\n",
            "FOLD : 0, EPOCH : 46, TRAIN_LOSS : 0.01455291708637225, VALIDATION_LOSS : 0.015928304567933083\n",
            "FOLD : 0, EPOCH : 47, TRAIN_LOSS : 0.01450251371256615, VALIDATION_LOSS : 0.015851106867194174\n",
            "FOLD : 0, EPOCH : 48, TRAIN_LOSS : 0.014447702389014395, VALIDATION_LOSS : 0.015862534940242767\n",
            "FOLD : 0, EPOCH : 49, TRAIN_LOSS : 0.014429542039962192, VALIDATION_LOSS : 0.015812945924699305\n",
            "FOLD : 0, EPOCH : 50, TRAIN_LOSS : 0.014358229395982466, VALIDATION_LOSS : 0.015771821700036527\n",
            "FOLD : 0, EPOCH : 51, TRAIN_LOSS : 0.014250394201984531, VALIDATION_LOSS : 0.015840475261211396\n",
            "FOLD : 0, EPOCH : 52, TRAIN_LOSS : 0.01423167520643849, VALIDATION_LOSS : 0.015794550254940986\n",
            "FOLD : 0, EPOCH : 53, TRAIN_LOSS : 0.014215164621801753, VALIDATION_LOSS : 0.015794788487255573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 1, EPOCH : 0, TRAIN_LOSS : 0.1601802018520079, VALIDATION_LOSS : 0.16343340873718262\n",
            "FOLD : 1, EPOCH : 1, TRAIN_LOSS : 0.022788347382294506, VALIDATION_LOSS : 0.08685574978590012\n",
            "FOLD : 1, EPOCH : 2, TRAIN_LOSS : 0.021218371528543924, VALIDATION_LOSS : 0.08104480803012848\n",
            "FOLD : 1, EPOCH : 3, TRAIN_LOSS : 0.020480443086279065, VALIDATION_LOSS : 0.05511846989393234\n",
            "FOLD : 1, EPOCH : 4, TRAIN_LOSS : 0.020112910454994755, VALIDATION_LOSS : 0.0549572080373764\n",
            "FOLD : 1, EPOCH : 5, TRAIN_LOSS : 0.019756364194970382, VALIDATION_LOSS : 0.0493245393037796\n",
            "FOLD : 1, EPOCH : 6, TRAIN_LOSS : 0.01943496595087804, VALIDATION_LOSS : 0.04846067428588867\n",
            "FOLD : 1, EPOCH : 7, TRAIN_LOSS : 0.019124702207351987, VALIDATION_LOSS : 0.04401483461260795\n",
            "FOLD : 1, EPOCH : 8, TRAIN_LOSS : 0.018794259154482892, VALIDATION_LOSS : 0.038667571544647214\n",
            "FOLD : 1, EPOCH : 9, TRAIN_LOSS : 0.018553178953497035, VALIDATION_LOSS : 0.03574414700269699\n",
            "FOLD : 1, EPOCH : 10, TRAIN_LOSS : 0.018295552875650555, VALIDATION_LOSS : 0.034062858670949936\n",
            "FOLD : 1, EPOCH : 11, TRAIN_LOSS : 0.01802574901988632, VALIDATION_LOSS : 0.03187690451741219\n",
            "FOLD : 1, EPOCH : 12, TRAIN_LOSS : 0.01788588083888355, VALIDATION_LOSS : 0.028663882240653037\n",
            "FOLD : 1, EPOCH : 13, TRAIN_LOSS : 0.01762609870025986, VALIDATION_LOSS : 0.026971092075109483\n",
            "FOLD : 1, EPOCH : 14, TRAIN_LOSS : 0.017501791154867725, VALIDATION_LOSS : 0.024382252618670462\n",
            "FOLD : 1, EPOCH : 15, TRAIN_LOSS : 0.017321630626132612, VALIDATION_LOSS : 0.024507667124271392\n",
            "FOLD : 1, EPOCH : 16, TRAIN_LOSS : 0.017190145426674894, VALIDATION_LOSS : 0.023877326771616934\n",
            "FOLD : 1, EPOCH : 17, TRAIN_LOSS : 0.017091756588534304, VALIDATION_LOSS : 0.021876535192131997\n",
            "FOLD : 1, EPOCH : 18, TRAIN_LOSS : 0.016934479439729137, VALIDATION_LOSS : 0.020502151176333427\n",
            "FOLD : 1, EPOCH : 19, TRAIN_LOSS : 0.01678928713265218, VALIDATION_LOSS : 0.02050248458981514\n",
            "FOLD : 1, EPOCH : 20, TRAIN_LOSS : 0.016670433216189082, VALIDATION_LOSS : 0.019628644362092017\n",
            "FOLD : 1, EPOCH : 21, TRAIN_LOSS : 0.016598763434510482, VALIDATION_LOSS : 0.018795764073729515\n",
            "FOLD : 1, EPOCH : 22, TRAIN_LOSS : 0.016438145386545283, VALIDATION_LOSS : 0.018570169806480408\n",
            "FOLD : 1, EPOCH : 23, TRAIN_LOSS : 0.01641959716614924, VALIDATION_LOSS : 0.01820489577949047\n",
            "FOLD : 1, EPOCH : 24, TRAIN_LOSS : 0.01626101190126256, VALIDATION_LOSS : 0.018064184486865996\n",
            "FOLD : 1, EPOCH : 25, TRAIN_LOSS : 0.01623774182639624, VALIDATION_LOSS : 0.017907531931996346\n",
            "FOLD : 1, EPOCH : 26, TRAIN_LOSS : 0.016051006209301322, VALIDATION_LOSS : 0.017537618800997735\n",
            "FOLD : 1, EPOCH : 27, TRAIN_LOSS : 0.015931938039629084, VALIDATION_LOSS : 0.01691092550754547\n",
            "FOLD : 1, EPOCH : 28, TRAIN_LOSS : 0.01594332644813939, VALIDATION_LOSS : 0.017009859532117845\n",
            "FOLD : 1, EPOCH : 29, TRAIN_LOSS : 0.01579214338409273, VALIDATION_LOSS : 0.016891075670719145\n",
            "FOLD : 1, EPOCH : 30, TRAIN_LOSS : 0.01571725044203432, VALIDATION_LOSS : 0.016811151057481766\n",
            "FOLD : 1, EPOCH : 31, TRAIN_LOSS : 0.015670333988964558, VALIDATION_LOSS : 0.016568370163440704\n",
            "FOLD : 1, EPOCH : 32, TRAIN_LOSS : 0.015567966344717302, VALIDATION_LOSS : 0.016402509063482285\n",
            "FOLD : 1, EPOCH : 33, TRAIN_LOSS : 0.015499629913584181, VALIDATION_LOSS : 0.016379230096936225\n",
            "FOLD : 1, EPOCH : 34, TRAIN_LOSS : 0.015423120685706013, VALIDATION_LOSS : 0.016303937882184982\n",
            "FOLD : 1, EPOCH : 35, TRAIN_LOSS : 0.015356849780992457, VALIDATION_LOSS : 0.016216354444622993\n",
            "FOLD : 1, EPOCH : 36, TRAIN_LOSS : 0.01528676574755656, VALIDATION_LOSS : 0.016135231405496598\n",
            "FOLD : 1, EPOCH : 37, TRAIN_LOSS : 0.015245374635254083, VALIDATION_LOSS : 0.016048897057771683\n",
            "FOLD : 1, EPOCH : 38, TRAIN_LOSS : 0.015124611458496043, VALIDATION_LOSS : 0.015924420952796937\n",
            "FOLD : 1, EPOCH : 39, TRAIN_LOSS : 0.015067206254523052, VALIDATION_LOSS : 0.015951046347618104\n",
            "FOLD : 1, EPOCH : 40, TRAIN_LOSS : 0.014991427428628268, VALIDATION_LOSS : 0.01587623283267021\n",
            "FOLD : 1, EPOCH : 41, TRAIN_LOSS : 0.014890098307085665, VALIDATION_LOSS : 0.015773308649659156\n",
            "FOLD : 1, EPOCH : 42, TRAIN_LOSS : 0.014813833820976709, VALIDATION_LOSS : 0.015821942314505576\n",
            "FOLD : 1, EPOCH : 43, TRAIN_LOSS : 0.014759985092831286, VALIDATION_LOSS : 0.01571270264685154\n",
            "FOLD : 1, EPOCH : 44, TRAIN_LOSS : 0.014675931416844068, VALIDATION_LOSS : 0.01566044446080923\n",
            "FOLD : 1, EPOCH : 45, TRAIN_LOSS : 0.014618369407559695, VALIDATION_LOSS : 0.015738633275032044\n",
            "FOLD : 1, EPOCH : 46, TRAIN_LOSS : 0.014532124427588363, VALIDATION_LOSS : 0.015619142167270183\n",
            "FOLD : 1, EPOCH : 47, TRAIN_LOSS : 0.014474668981213318, VALIDATION_LOSS : 0.015620283596217633\n",
            "FOLD : 1, EPOCH : 48, TRAIN_LOSS : 0.014465864845796636, VALIDATION_LOSS : 0.01558365225791931\n",
            "FOLD : 1, EPOCH : 49, TRAIN_LOSS : 0.014408518707281664, VALIDATION_LOSS : 0.015579549409449101\n",
            "FOLD : 1, EPOCH : 50, TRAIN_LOSS : 0.014376502238998288, VALIDATION_LOSS : 0.015618471242487431\n",
            "FOLD : 1, EPOCH : 51, TRAIN_LOSS : 0.014272008042194341, VALIDATION_LOSS : 0.015608485974371433\n",
            "FOLD : 1, EPOCH : 52, TRAIN_LOSS : 0.014228028588389096, VALIDATION_LOSS : 0.015536896698176862\n",
            "FOLD : 1, EPOCH : 53, TRAIN_LOSS : 0.014106855727732182, VALIDATION_LOSS : 0.015535897761583328\n",
            "FOLD : 1, EPOCH : 54, TRAIN_LOSS : 0.014063140230351373, VALIDATION_LOSS : 0.01554635763168335\n",
            "FOLD : 1, EPOCH : 55, TRAIN_LOSS : 0.014003714301476353, VALIDATION_LOSS : 0.01557629629969597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 2, EPOCH : 0, TRAIN_LOSS : 0.15785556590478672, VALIDATION_LOSS : 0.20859179198741912\n",
            "FOLD : 2, EPOCH : 1, TRAIN_LOSS : 0.022812995569486367, VALIDATION_LOSS : 0.07751615792512893\n",
            "FOLD : 2, EPOCH : 2, TRAIN_LOSS : 0.0212436543875619, VALIDATION_LOSS : 0.06242748126387596\n",
            "FOLD : 2, EPOCH : 3, TRAIN_LOSS : 0.020389258567439884, VALIDATION_LOSS : 0.04594279602169991\n",
            "FOLD : 2, EPOCH : 4, TRAIN_LOSS : 0.020047831692193683, VALIDATION_LOSS : 0.04754674956202507\n",
            "FOLD : 2, EPOCH : 5, TRAIN_LOSS : 0.01976336342723746, VALIDATION_LOSS : 0.04403437823057175\n",
            "FOLD : 2, EPOCH : 6, TRAIN_LOSS : 0.01940166479662845, VALIDATION_LOSS : 0.04714818298816681\n",
            "FOLD : 2, EPOCH : 7, TRAIN_LOSS : 0.01905731847019572, VALIDATION_LOSS : 0.04013270065188408\n",
            "FOLD : 2, EPOCH : 8, TRAIN_LOSS : 0.018765534029195185, VALIDATION_LOSS : 0.03987767100334168\n",
            "FOLD : 2, EPOCH : 9, TRAIN_LOSS : 0.01852038257608288, VALIDATION_LOSS : 0.03430885076522827\n",
            "FOLD : 2, EPOCH : 10, TRAIN_LOSS : 0.018171878727643115, VALIDATION_LOSS : 0.03204232901334762\n",
            "FOLD : 2, EPOCH : 11, TRAIN_LOSS : 0.017966160060543763, VALIDATION_LOSS : 0.02724033370614052\n",
            "FOLD : 2, EPOCH : 12, TRAIN_LOSS : 0.017779038924919933, VALIDATION_LOSS : 0.02704564668238163\n",
            "FOLD : 2, EPOCH : 13, TRAIN_LOSS : 0.017665139644553785, VALIDATION_LOSS : 0.024242891743779183\n",
            "FOLD : 2, EPOCH : 14, TRAIN_LOSS : 0.017402496188879013, VALIDATION_LOSS : 0.024284404888749122\n",
            "FOLD : 2, EPOCH : 15, TRAIN_LOSS : 0.01727743584074472, VALIDATION_LOSS : 0.023944343999028207\n",
            "FOLD : 2, EPOCH : 16, TRAIN_LOSS : 0.017131981684973364, VALIDATION_LOSS : 0.022466224431991578\n",
            "FOLD : 2, EPOCH : 17, TRAIN_LOSS : 0.017010181161918138, VALIDATION_LOSS : 0.022028886526823045\n",
            "FOLD : 2, EPOCH : 18, TRAIN_LOSS : 0.016858233825156565, VALIDATION_LOSS : 0.020255788043141366\n",
            "FOLD : 2, EPOCH : 19, TRAIN_LOSS : 0.01671069595766695, VALIDATION_LOSS : 0.02052757181227207\n",
            "FOLD : 2, EPOCH : 20, TRAIN_LOSS : 0.016679340238241774, VALIDATION_LOSS : 0.01932738609611988\n",
            "FOLD : 2, EPOCH : 21, TRAIN_LOSS : 0.016488930994742794, VALIDATION_LOSS : 0.01898258402943611\n",
            "FOLD : 2, EPOCH : 22, TRAIN_LOSS : 0.016442775824352315, VALIDATION_LOSS : 0.018636836856603622\n",
            "FOLD : 2, EPOCH : 23, TRAIN_LOSS : 0.016304649069513146, VALIDATION_LOSS : 0.017941758036613464\n",
            "FOLD : 2, EPOCH : 24, TRAIN_LOSS : 0.016231414175739412, VALIDATION_LOSS : 0.017682409286499022\n",
            "FOLD : 2, EPOCH : 25, TRAIN_LOSS : 0.01612073864395681, VALIDATION_LOSS : 0.01751701571047306\n",
            "FOLD : 2, EPOCH : 26, TRAIN_LOSS : 0.016065320392188272, VALIDATION_LOSS : 0.017237035557627678\n",
            "FOLD : 2, EPOCH : 27, TRAIN_LOSS : 0.016023435531870314, VALIDATION_LOSS : 0.01680428721010685\n",
            "FOLD : 2, EPOCH : 28, TRAIN_LOSS : 0.015826606828915447, VALIDATION_LOSS : 0.01685405746102333\n",
            "FOLD : 2, EPOCH : 29, TRAIN_LOSS : 0.01574851396052461, VALIDATION_LOSS : 0.016724658012390137\n",
            "FOLD : 2, EPOCH : 30, TRAIN_LOSS : 0.015714390987628384, VALIDATION_LOSS : 0.01659708619117737\n",
            "FOLD : 2, EPOCH : 31, TRAIN_LOSS : 0.01562760922273523, VALIDATION_LOSS : 0.01636439859867096\n",
            "FOLD : 2, EPOCH : 32, TRAIN_LOSS : 0.015507342685994348, VALIDATION_LOSS : 0.016278452426195144\n",
            "FOLD : 2, EPOCH : 33, TRAIN_LOSS : 0.015488891127078156, VALIDATION_LOSS : 0.01624361574649811\n",
            "FOLD : 2, EPOCH : 34, TRAIN_LOSS : 0.015337577040650342, VALIDATION_LOSS : 0.01621653027832508\n",
            "FOLD : 2, EPOCH : 35, TRAIN_LOSS : 0.015284201130270958, VALIDATION_LOSS : 0.016108008474111556\n",
            "FOLD : 2, EPOCH : 36, TRAIN_LOSS : 0.015195132625338278, VALIDATION_LOSS : 0.016092953830957414\n",
            "FOLD : 2, EPOCH : 37, TRAIN_LOSS : 0.015100275313383654, VALIDATION_LOSS : 0.01595021188259125\n",
            "FOLD : 2, EPOCH : 38, TRAIN_LOSS : 0.015056765785342768, VALIDATION_LOSS : 0.015938035398721694\n",
            "FOLD : 2, EPOCH : 39, TRAIN_LOSS : 0.015035211059607957, VALIDATION_LOSS : 0.015835197269916536\n",
            "FOLD : 2, EPOCH : 40, TRAIN_LOSS : 0.014924498029837483, VALIDATION_LOSS : 0.015797511488199235\n",
            "FOLD : 2, EPOCH : 41, TRAIN_LOSS : 0.014883379598981455, VALIDATION_LOSS : 0.015833525359630583\n",
            "FOLD : 2, EPOCH : 42, TRAIN_LOSS : 0.014781557513695014, VALIDATION_LOSS : 0.015804217010736466\n",
            "FOLD : 2, EPOCH : 43, TRAIN_LOSS : 0.014718712944733469, VALIDATION_LOSS : 0.015737830847501754\n",
            "FOLD : 2, EPOCH : 44, TRAIN_LOSS : 0.014666394036459295, VALIDATION_LOSS : 0.015729582868516445\n",
            "FOLD : 2, EPOCH : 45, TRAIN_LOSS : 0.0145866332183543, VALIDATION_LOSS : 0.015660996176302434\n",
            "FOLD : 2, EPOCH : 46, TRAIN_LOSS : 0.014531314667118224, VALIDATION_LOSS : 0.015679417923092843\n",
            "FOLD : 2, EPOCH : 47, TRAIN_LOSS : 0.014461436259903405, VALIDATION_LOSS : 0.015677771903574465\n",
            "FOLD : 2, EPOCH : 48, TRAIN_LOSS : 0.01431238053268508, VALIDATION_LOSS : 0.015605790168046951\n",
            "FOLD : 2, EPOCH : 49, TRAIN_LOSS : 0.01432210814795996, VALIDATION_LOSS : 0.015701678395271302\n",
            "FOLD : 2, EPOCH : 50, TRAIN_LOSS : 0.014256239084428862, VALIDATION_LOSS : 0.01561785750091076\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 3, EPOCH : 0, TRAIN_LOSS : 0.15962064521093117, VALIDATION_LOSS : 0.15853193700313567\n",
            "FOLD : 3, EPOCH : 1, TRAIN_LOSS : 0.02267589125978319, VALIDATION_LOSS : 0.0856154665350914\n",
            "FOLD : 3, EPOCH : 2, TRAIN_LOSS : 0.02126985494243471, VALIDATION_LOSS : 0.0785579577088356\n",
            "FOLD : 3, EPOCH : 3, TRAIN_LOSS : 0.020525319991927398, VALIDATION_LOSS : 0.05780495628714562\n",
            "FOLD : 3, EPOCH : 4, TRAIN_LOSS : 0.020052278904538406, VALIDATION_LOSS : 0.061308656632900235\n",
            "FOLD : 3, EPOCH : 5, TRAIN_LOSS : 0.019722967555648403, VALIDATION_LOSS : 0.05449108481407165\n",
            "FOLD : 3, EPOCH : 6, TRAIN_LOSS : 0.019443014048432048, VALIDATION_LOSS : 0.05500408634543419\n",
            "FOLD : 3, EPOCH : 7, TRAIN_LOSS : 0.01907899103274471, VALIDATION_LOSS : 0.04620257169008255\n",
            "FOLD : 3, EPOCH : 8, TRAIN_LOSS : 0.018823828940328798, VALIDATION_LOSS : 0.0419271320104599\n",
            "FOLD : 3, EPOCH : 9, TRAIN_LOSS : 0.018588302951110035, VALIDATION_LOSS : 0.03658805042505264\n",
            "FOLD : 3, EPOCH : 10, TRAIN_LOSS : 0.018308803243072408, VALIDATION_LOSS : 0.03291606903076172\n",
            "FOLD : 3, EPOCH : 11, TRAIN_LOSS : 0.018033175091994435, VALIDATION_LOSS : 0.028976744040846825\n",
            "FOLD : 3, EPOCH : 12, TRAIN_LOSS : 0.017834141850471497, VALIDATION_LOSS : 0.028798465430736542\n",
            "FOLD : 3, EPOCH : 13, TRAIN_LOSS : 0.017702458818492136, VALIDATION_LOSS : 0.027865678071975708\n",
            "FOLD : 3, EPOCH : 14, TRAIN_LOSS : 0.01753168023730579, VALIDATION_LOSS : 0.02557866871356964\n",
            "FOLD : 3, EPOCH : 15, TRAIN_LOSS : 0.0173700946922365, VALIDATION_LOSS : 0.02391730770468712\n",
            "FOLD : 3, EPOCH : 16, TRAIN_LOSS : 0.017221636285907345, VALIDATION_LOSS : 0.022313665598630905\n",
            "FOLD : 3, EPOCH : 17, TRAIN_LOSS : 0.017000431685071243, VALIDATION_LOSS : 0.021253722533583642\n",
            "FOLD : 3, EPOCH : 18, TRAIN_LOSS : 0.016928790725375478, VALIDATION_LOSS : 0.020811877399682998\n",
            "FOLD : 3, EPOCH : 19, TRAIN_LOSS : 0.016773095452471784, VALIDATION_LOSS : 0.02027667984366417\n",
            "FOLD : 3, EPOCH : 20, TRAIN_LOSS : 0.016714104108120267, VALIDATION_LOSS : 0.01910836175084114\n",
            "FOLD : 3, EPOCH : 21, TRAIN_LOSS : 0.016580505051503058, VALIDATION_LOSS : 0.01898634247481823\n",
            "FOLD : 3, EPOCH : 22, TRAIN_LOSS : 0.016442389374500828, VALIDATION_LOSS : 0.018731482699513434\n",
            "FOLD : 3, EPOCH : 23, TRAIN_LOSS : 0.016319019965043192, VALIDATION_LOSS : 0.01830945834517479\n",
            "FOLD : 3, EPOCH : 24, TRAIN_LOSS : 0.016237011620480763, VALIDATION_LOSS : 0.017985590547323228\n",
            "FOLD : 3, EPOCH : 25, TRAIN_LOSS : 0.01619053087932499, VALIDATION_LOSS : 0.01782083958387375\n",
            "FOLD : 3, EPOCH : 26, TRAIN_LOSS : 0.0160820442496946, VALIDATION_LOSS : 0.0177161131054163\n",
            "FOLD : 3, EPOCH : 27, TRAIN_LOSS : 0.015951053925642843, VALIDATION_LOSS : 0.017126389592885972\n",
            "FOLD : 3, EPOCH : 28, TRAIN_LOSS : 0.01588651920227628, VALIDATION_LOSS : 0.017250728234648703\n",
            "FOLD : 3, EPOCH : 29, TRAIN_LOSS : 0.015785456438990014, VALIDATION_LOSS : 0.016881755739450454\n",
            "FOLD : 3, EPOCH : 30, TRAIN_LOSS : 0.015661844003357385, VALIDATION_LOSS : 0.016730202361941338\n",
            "FOLD : 3, EPOCH : 31, TRAIN_LOSS : 0.015595078664390664, VALIDATION_LOSS : 0.016609474271535873\n",
            "FOLD : 3, EPOCH : 32, TRAIN_LOSS : 0.015533150075689742, VALIDATION_LOSS : 0.016545820981264114\n",
            "FOLD : 3, EPOCH : 33, TRAIN_LOSS : 0.01552793952195268, VALIDATION_LOSS : 0.01642872616648674\n",
            "FOLD : 3, EPOCH : 34, TRAIN_LOSS : 0.01534866669068211, VALIDATION_LOSS : 0.01651333160698414\n",
            "FOLD : 3, EPOCH : 35, TRAIN_LOSS : 0.015336795513959308, VALIDATION_LOSS : 0.016312836110591887\n",
            "FOLD : 3, EPOCH : 36, TRAIN_LOSS : 0.015222437581733653, VALIDATION_LOSS : 0.016209251806139947\n",
            "FOLD : 3, EPOCH : 37, TRAIN_LOSS : 0.015134084871725031, VALIDATION_LOSS : 0.016111944615840913\n",
            "FOLD : 3, EPOCH : 38, TRAIN_LOSS : 0.015088341492963465, VALIDATION_LOSS : 0.016108671203255653\n",
            "FOLD : 3, EPOCH : 39, TRAIN_LOSS : 0.014997553374422224, VALIDATION_LOSS : 0.01607525907456875\n",
            "FOLD : 3, EPOCH : 40, TRAIN_LOSS : 0.014950204346525041, VALIDATION_LOSS : 0.01590911131352186\n",
            "FOLD : 3, EPOCH : 41, TRAIN_LOSS : 0.01484921746152012, VALIDATION_LOSS : 0.01598950121551752\n",
            "FOLD : 3, EPOCH : 42, TRAIN_LOSS : 0.014833230329187293, VALIDATION_LOSS : 0.015871804393827914\n",
            "FOLD : 3, EPOCH : 43, TRAIN_LOSS : 0.014748575754071536, VALIDATION_LOSS : 0.01585069466382265\n",
            "FOLD : 3, EPOCH : 44, TRAIN_LOSS : 0.014598763498820756, VALIDATION_LOSS : 0.015919128246605397\n",
            "FOLD : 3, EPOCH : 45, TRAIN_LOSS : 0.014586154224449083, VALIDATION_LOSS : 0.015875207632780074\n",
            "FOLD : 3, EPOCH : 46, TRAIN_LOSS : 0.014513216520610609, VALIDATION_LOSS : 0.015845791064202787\n",
            "FOLD : 3, EPOCH : 47, TRAIN_LOSS : 0.014411057100484246, VALIDATION_LOSS : 0.015874447859823705\n",
            "FOLD : 3, EPOCH : 48, TRAIN_LOSS : 0.014439932413791356, VALIDATION_LOSS : 0.015773962065577508\n",
            "FOLD : 3, EPOCH : 49, TRAIN_LOSS : 0.014337921564124133, VALIDATION_LOSS : 0.01578393243253231\n",
            "FOLD : 3, EPOCH : 50, TRAIN_LOSS : 0.014313174754773316, VALIDATION_LOSS : 0.015751410089433194\n",
            "FOLD : 3, EPOCH : 51, TRAIN_LOSS : 0.014242588395350858, VALIDATION_LOSS : 0.015763918124139308\n",
            "FOLD : 3, EPOCH : 52, TRAIN_LOSS : 0.014138770681854925, VALIDATION_LOSS : 0.01569410152733326\n",
            "FOLD : 3, EPOCH : 53, TRAIN_LOSS : 0.014097709453811771, VALIDATION_LOSS : 0.01571989692747593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 0, TRAIN_LOSS : 0.15955850481987, VALIDATION_LOSS : 0.18911505937576295\n",
            "FOLD : 4, EPOCH : 1, TRAIN_LOSS : 0.02274354664902938, VALIDATION_LOSS : 0.09691549390554428\n",
            "FOLD : 4, EPOCH : 2, TRAIN_LOSS : 0.021318027945725543, VALIDATION_LOSS : 0.09056131392717362\n",
            "FOLD : 4, EPOCH : 3, TRAIN_LOSS : 0.0204805572958369, VALIDATION_LOSS : 0.06111673638224602\n",
            "FOLD : 4, EPOCH : 4, TRAIN_LOSS : 0.020009722854746014, VALIDATION_LOSS : 0.057079014182090757\n",
            "FOLD : 4, EPOCH : 5, TRAIN_LOSS : 0.019713477280579116, VALIDATION_LOSS : 0.05999022722244263\n",
            "FOLD : 4, EPOCH : 6, TRAIN_LOSS : 0.019364218374616222, VALIDATION_LOSS : 0.0502686433494091\n",
            "FOLD : 4, EPOCH : 7, TRAIN_LOSS : 0.019126188990316893, VALIDATION_LOSS : 0.0484025664627552\n",
            "FOLD : 4, EPOCH : 8, TRAIN_LOSS : 0.01876546089586459, VALIDATION_LOSS : 0.03951965942978859\n",
            "FOLD : 4, EPOCH : 9, TRAIN_LOSS : 0.01846577521217497, VALIDATION_LOSS : 0.03427026122808456\n",
            "FOLD : 4, EPOCH : 10, TRAIN_LOSS : 0.01821125249721502, VALIDATION_LOSS : 0.034235091507434846\n",
            "FOLD : 4, EPOCH : 11, TRAIN_LOSS : 0.017991112152996817, VALIDATION_LOSS : 0.031194471567869187\n",
            "FOLD : 4, EPOCH : 12, TRAIN_LOSS : 0.017794921111903693, VALIDATION_LOSS : 0.027752963826060295\n",
            "FOLD : 4, EPOCH : 13, TRAIN_LOSS : 0.0176075820467974, VALIDATION_LOSS : 0.02828400768339634\n",
            "FOLD : 4, EPOCH : 14, TRAIN_LOSS : 0.01744854783541278, VALIDATION_LOSS : 0.026185528934001924\n",
            "FOLD : 4, EPOCH : 15, TRAIN_LOSS : 0.017279575039681635, VALIDATION_LOSS : 0.02417945973575115\n",
            "FOLD : 4, EPOCH : 16, TRAIN_LOSS : 0.0171304394147898, VALIDATION_LOSS : 0.022874530777335166\n",
            "FOLD : 4, EPOCH : 17, TRAIN_LOSS : 0.01699627053580786, VALIDATION_LOSS : 0.022837859019637106\n",
            "FOLD : 4, EPOCH : 18, TRAIN_LOSS : 0.01690826270925371, VALIDATION_LOSS : 0.021106119453907012\n",
            "FOLD : 4, EPOCH : 19, TRAIN_LOSS : 0.016711513217734664, VALIDATION_LOSS : 0.02084295339882374\n",
            "FOLD : 4, EPOCH : 20, TRAIN_LOSS : 0.016674667596817017, VALIDATION_LOSS : 0.019935795664787294\n",
            "FOLD : 4, EPOCH : 21, TRAIN_LOSS : 0.01656608871723476, VALIDATION_LOSS : 0.019196226820349695\n",
            "FOLD : 4, EPOCH : 22, TRAIN_LOSS : 0.016368212815570205, VALIDATION_LOSS : 0.01874113529920578\n",
            "FOLD : 4, EPOCH : 23, TRAIN_LOSS : 0.016312619671225548, VALIDATION_LOSS : 0.01837395764887333\n",
            "FOLD : 4, EPOCH : 24, TRAIN_LOSS : 0.01621818395429536, VALIDATION_LOSS : 0.017900804802775384\n",
            "FOLD : 4, EPOCH : 25, TRAIN_LOSS : 0.016113182382756157, VALIDATION_LOSS : 0.017978230491280556\n",
            "FOLD : 4, EPOCH : 26, TRAIN_LOSS : 0.01604622695595026, VALIDATION_LOSS : 0.01757318489253521\n",
            "FOLD : 4, EPOCH : 27, TRAIN_LOSS : 0.015971732767004716, VALIDATION_LOSS : 0.01744122840464115\n",
            "FOLD : 4, EPOCH : 28, TRAIN_LOSS : 0.015838127142112506, VALIDATION_LOSS : 0.017267074435949326\n",
            "FOLD : 4, EPOCH : 29, TRAIN_LOSS : 0.015789129183088477, VALIDATION_LOSS : 0.01700974442064762\n",
            "FOLD : 4, EPOCH : 30, TRAIN_LOSS : 0.015677687025776033, VALIDATION_LOSS : 0.01685403436422348\n",
            "FOLD : 4, EPOCH : 31, TRAIN_LOSS : 0.015535456226452402, VALIDATION_LOSS : 0.01656365692615509\n",
            "FOLD : 4, EPOCH : 32, TRAIN_LOSS : 0.015520702606361163, VALIDATION_LOSS : 0.01653846651315689\n",
            "FOLD : 4, EPOCH : 33, TRAIN_LOSS : 0.015458402076834127, VALIDATION_LOSS : 0.01654353253543377\n",
            "FOLD : 4, EPOCH : 34, TRAIN_LOSS : 0.015349907555470341, VALIDATION_LOSS : 0.016310222446918488\n",
            "FOLD : 4, EPOCH : 35, TRAIN_LOSS : 0.015283325245898021, VALIDATION_LOSS : 0.016361306980252267\n",
            "FOLD : 4, EPOCH : 36, TRAIN_LOSS : 0.015191953531221339, VALIDATION_LOSS : 0.01620994061231613\n",
            "FOLD : 4, EPOCH : 37, TRAIN_LOSS : 0.01511383733074916, VALIDATION_LOSS : 0.01618330292403698\n",
            "FOLD : 4, EPOCH : 38, TRAIN_LOSS : 0.015033271898956676, VALIDATION_LOSS : 0.016198044642806053\n",
            "FOLD : 4, EPOCH : 39, TRAIN_LOSS : 0.014960389731353834, VALIDATION_LOSS : 0.016162915900349618\n",
            "FOLD : 4, EPOCH : 40, TRAIN_LOSS : 0.014859673273014394, VALIDATION_LOSS : 0.016062726452946662\n",
            "FOLD : 4, EPOCH : 41, TRAIN_LOSS : 0.014836364621786695, VALIDATION_LOSS : 0.015999223664402963\n",
            "FOLD : 4, EPOCH : 42, TRAIN_LOSS : 0.014743609157832046, VALIDATION_LOSS : 0.015995510295033454\n",
            "FOLD : 4, EPOCH : 43, TRAIN_LOSS : 0.014701785372668192, VALIDATION_LOSS : 0.01594468206167221\n",
            "FOLD : 4, EPOCH : 44, TRAIN_LOSS : 0.014616635039840875, VALIDATION_LOSS : 0.0160087451338768\n",
            "FOLD : 4, EPOCH : 45, TRAIN_LOSS : 0.014602011265723329, VALIDATION_LOSS : 0.015923532471060754\n",
            "FOLD : 4, EPOCH : 46, TRAIN_LOSS : 0.01451203021171846, VALIDATION_LOSS : 0.015885505080223083\n",
            "FOLD : 4, EPOCH : 47, TRAIN_LOSS : 0.014496293556141225, VALIDATION_LOSS : 0.015858033671975136\n",
            "FOLD : 4, EPOCH : 48, TRAIN_LOSS : 0.014385071338007325, VALIDATION_LOSS : 0.015842106938362122\n",
            "FOLD : 4, EPOCH : 49, TRAIN_LOSS : 0.0143644858739878, VALIDATION_LOSS : 0.015858331695199013\n",
            "FOLD : 4, EPOCH : 50, TRAIN_LOSS : 0.014305403161990015, VALIDATION_LOSS : 0.015834173746407033\n",
            "FOLD : 4, EPOCH : 51, TRAIN_LOSS : 0.014223155712610796, VALIDATION_LOSS : 0.015843214094638826\n",
            "FOLD : 4, EPOCH : 52, TRAIN_LOSS : 0.014145734572881147, VALIDATION_LOSS : 0.015824784711003303\n",
            "FOLD : 4, EPOCH : 53, TRAIN_LOSS : 0.014045397603982374, VALIDATION_LOSS : 0.01581683624535799\n",
            "FOLD : 4, EPOCH : 54, TRAIN_LOSS : 0.014004157463970938, VALIDATION_LOSS : 0.01582295335829258\n",
            "FOLD : 4, EPOCH : 55, TRAIN_LOSS : 0.013933216270647551, VALIDATION_LOSS : 0.015781005658209325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-11-01 14:37:59,803]\u001b[0m Trial 2 finished with value: 0.015677723363041875 and parameters: {'num_layers': 2, 'hidden_size': 1272, 'dropout': 0.6761963193393893, 'learning_rate': 0.0009095634508804573}. Best is trial 2 with value: 0.015677723363041875.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 56, TRAIN_LOSS : 0.013895901067084387, VALIDATION_LOSS : 0.015820485539734364\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 0, EPOCH : 0, TRAIN_LOSS : 0.2933980967653425, VALIDATION_LOSS : 0.17230124473571778\n",
            "FOLD : 0, EPOCH : 1, TRAIN_LOSS : 0.04319359724851031, VALIDATION_LOSS : 0.0676981121301651\n",
            "FOLD : 0, EPOCH : 2, TRAIN_LOSS : 0.027812649152780835, VALIDATION_LOSS : 0.09463340044021606\n",
            "FOLD : 0, EPOCH : 3, TRAIN_LOSS : 0.02510498885653521, VALIDATION_LOSS : 0.06910875886678695\n",
            "FOLD : 0, EPOCH : 4, TRAIN_LOSS : 0.024001773250730413, VALIDATION_LOSS : 0.0510521799325943\n",
            "FOLD : 0, EPOCH : 5, TRAIN_LOSS : 0.023194668618471997, VALIDATION_LOSS : 0.04251079931855202\n",
            "FOLD : 0, EPOCH : 6, TRAIN_LOSS : 0.022587301601704798, VALIDATION_LOSS : 0.03506605997681618\n",
            "FOLD : 0, EPOCH : 7, TRAIN_LOSS : 0.022134585502116305, VALIDATION_LOSS : 0.040160391479730606\n",
            "FOLD : 0, EPOCH : 8, TRAIN_LOSS : 0.02177388809229198, VALIDATION_LOSS : 0.04960305094718933\n",
            "FOLD : 0, EPOCH : 9, TRAIN_LOSS : 0.02157389225536271, VALIDATION_LOSS : 0.0629809893667698\n",
            "FOLD : 0, EPOCH : 10, TRAIN_LOSS : 0.02133430501348094, VALIDATION_LOSS : 0.05922474339604378\n",
            "FOLD : 0, EPOCH : 11, TRAIN_LOSS : 0.021234616931331784, VALIDATION_LOSS : 0.06753222197294236\n",
            "FOLD : 0, EPOCH : 12, TRAIN_LOSS : 0.021174204192663495, VALIDATION_LOSS : 0.06261390745639801\n",
            "FOLD : 0, EPOCH : 13, TRAIN_LOSS : 0.020996665091891038, VALIDATION_LOSS : 0.06672155410051346\n",
            "FOLD : 0, EPOCH : 14, TRAIN_LOSS : 0.020883290097117424, VALIDATION_LOSS : 0.08333270400762557\n",
            "FOLD : 0, EPOCH : 15, TRAIN_LOSS : 0.02086473864160086, VALIDATION_LOSS : 0.07412329614162445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 1, EPOCH : 0, TRAIN_LOSS : 0.29854660638068853, VALIDATION_LOSS : 0.14693099558353423\n",
            "FOLD : 1, EPOCH : 1, TRAIN_LOSS : 0.04342751401035409, VALIDATION_LOSS : 0.04547646716237068\n",
            "FOLD : 1, EPOCH : 2, TRAIN_LOSS : 0.027718422836379, VALIDATION_LOSS : 0.038770923763513564\n",
            "FOLD : 1, EPOCH : 3, TRAIN_LOSS : 0.025076305885848246, VALIDATION_LOSS : 0.031818046048283574\n",
            "FOLD : 1, EPOCH : 4, TRAIN_LOSS : 0.023931864943159253, VALIDATION_LOSS : 0.027698907256126403\n",
            "FOLD : 1, EPOCH : 5, TRAIN_LOSS : 0.02320568390974873, VALIDATION_LOSS : 0.026599083840847016\n",
            "FOLD : 1, EPOCH : 6, TRAIN_LOSS : 0.02269658093389712, VALIDATION_LOSS : 0.024535766616463662\n",
            "FOLD : 1, EPOCH : 7, TRAIN_LOSS : 0.022212788658706767, VALIDATION_LOSS : 0.025339927524328232\n",
            "FOLD : 1, EPOCH : 8, TRAIN_LOSS : 0.02185286542302684, VALIDATION_LOSS : 0.027376355603337288\n",
            "FOLD : 1, EPOCH : 9, TRAIN_LOSS : 0.021562312582605762, VALIDATION_LOSS : 0.028224948421120645\n",
            "FOLD : 1, EPOCH : 10, TRAIN_LOSS : 0.02140188805366817, VALIDATION_LOSS : 0.027705521881580354\n",
            "FOLD : 1, EPOCH : 11, TRAIN_LOSS : 0.0212692822280683, VALIDATION_LOSS : 0.02733246348798275\n",
            "FOLD : 1, EPOCH : 12, TRAIN_LOSS : 0.021129347285942027, VALIDATION_LOSS : 0.029324781149625778\n",
            "FOLD : 1, EPOCH : 13, TRAIN_LOSS : 0.02099602561640112, VALIDATION_LOSS : 0.031319538876414296\n",
            "FOLD : 1, EPOCH : 14, TRAIN_LOSS : 0.02097390925413684, VALIDATION_LOSS : 0.03219577893614769\n",
            "FOLD : 1, EPOCH : 15, TRAIN_LOSS : 0.020821371654930868, VALIDATION_LOSS : 0.03299633637070656\n",
            "FOLD : 1, EPOCH : 16, TRAIN_LOSS : 0.020813167879455967, VALIDATION_LOSS : 0.03188820779323578\n",
            "FOLD : 1, EPOCH : 17, TRAIN_LOSS : 0.020745512000040003, VALIDATION_LOSS : 0.033962202817201616\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 2, EPOCH : 0, TRAIN_LOSS : 0.29504099370617615, VALIDATION_LOSS : 0.1582220494747162\n",
            "FOLD : 2, EPOCH : 1, TRAIN_LOSS : 0.04330791101643914, VALIDATION_LOSS : 0.05432439222931862\n",
            "FOLD : 2, EPOCH : 2, TRAIN_LOSS : 0.02792040925276907, VALIDATION_LOSS : 0.04509725198149681\n",
            "FOLD : 2, EPOCH : 3, TRAIN_LOSS : 0.02504066564142704, VALIDATION_LOSS : 0.03161999396979809\n",
            "FOLD : 2, EPOCH : 4, TRAIN_LOSS : 0.023909760148901688, VALIDATION_LOSS : 0.027911537140607835\n",
            "FOLD : 2, EPOCH : 5, TRAIN_LOSS : 0.023235519465647246, VALIDATION_LOSS : 0.02704278752207756\n",
            "FOLD : 2, EPOCH : 6, TRAIN_LOSS : 0.02256291967473532, VALIDATION_LOSS : 0.027339619770646095\n",
            "FOLD : 2, EPOCH : 7, TRAIN_LOSS : 0.022091185772105268, VALIDATION_LOSS : 0.029286543279886244\n",
            "FOLD : 2, EPOCH : 8, TRAIN_LOSS : 0.021812565526679942, VALIDATION_LOSS : 0.032749561965465544\n",
            "FOLD : 2, EPOCH : 9, TRAIN_LOSS : 0.021599703321331425, VALIDATION_LOSS : 0.04343290701508522\n",
            "FOLD : 2, EPOCH : 10, TRAIN_LOSS : 0.021389174128049297, VALIDATION_LOSS : 0.056654810160398486\n",
            "FOLD : 2, EPOCH : 11, TRAIN_LOSS : 0.021222696590580438, VALIDATION_LOSS : 0.0624205119907856\n",
            "FOLD : 2, EPOCH : 12, TRAIN_LOSS : 0.02108516926436048, VALIDATION_LOSS : 0.06500216871500016\n",
            "FOLD : 2, EPOCH : 13, TRAIN_LOSS : 0.021003051808005886, VALIDATION_LOSS : 0.09054343849420547\n",
            "FOLD : 2, EPOCH : 14, TRAIN_LOSS : 0.02088372056421481, VALIDATION_LOSS : 0.08338264673948288\n",
            "FOLD : 2, EPOCH : 15, TRAIN_LOSS : 0.020799656055475537, VALIDATION_LOSS : 0.08720098882913589\n",
            "FOLD : 2, EPOCH : 16, TRAIN_LOSS : 0.020793346590117404, VALIDATION_LOSS : 0.09540036767721176\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 3, EPOCH : 0, TRAIN_LOSS : 0.2951018159326754, VALIDATION_LOSS : 0.16785112619400025\n",
            "FOLD : 3, EPOCH : 1, TRAIN_LOSS : 0.04305665665551236, VALIDATION_LOSS : 0.04890035316348076\n",
            "FOLD : 3, EPOCH : 2, TRAIN_LOSS : 0.027699391112515803, VALIDATION_LOSS : 0.04403486624360085\n",
            "FOLD : 3, EPOCH : 3, TRAIN_LOSS : 0.02504924518105231, VALIDATION_LOSS : 0.034615575522184375\n",
            "FOLD : 3, EPOCH : 4, TRAIN_LOSS : 0.023968884721398354, VALIDATION_LOSS : 0.02931462340056896\n",
            "FOLD : 3, EPOCH : 5, TRAIN_LOSS : 0.02321176132873485, VALIDATION_LOSS : 0.02592644318938255\n",
            "FOLD : 3, EPOCH : 6, TRAIN_LOSS : 0.022688134916518863, VALIDATION_LOSS : 0.023507822304964066\n",
            "FOLD : 3, EPOCH : 7, TRAIN_LOSS : 0.022245456219503756, VALIDATION_LOSS : 0.023880535364151002\n",
            "FOLD : 3, EPOCH : 8, TRAIN_LOSS : 0.02185417035300481, VALIDATION_LOSS : 0.0264963760972023\n",
            "FOLD : 3, EPOCH : 9, TRAIN_LOSS : 0.021625472918937082, VALIDATION_LOSS : 0.029247520864009856\n",
            "FOLD : 3, EPOCH : 10, TRAIN_LOSS : 0.021399012913829403, VALIDATION_LOSS : 0.03232669457793236\n",
            "FOLD : 3, EPOCH : 11, TRAIN_LOSS : 0.021326230348725068, VALIDATION_LOSS : 0.03249870911240578\n",
            "FOLD : 3, EPOCH : 12, TRAIN_LOSS : 0.021148389695506347, VALIDATION_LOSS : 0.03519011214375496\n",
            "FOLD : 3, EPOCH : 13, TRAIN_LOSS : 0.021008117908709927, VALIDATION_LOSS : 0.03943849727511406\n",
            "FOLD : 3, EPOCH : 14, TRAIN_LOSS : 0.020946974817075227, VALIDATION_LOSS : 0.04681303054094314\n",
            "FOLD : 3, EPOCH : 15, TRAIN_LOSS : 0.020847467117403682, VALIDATION_LOSS : 0.044883888214826584\n",
            "FOLD : 3, EPOCH : 16, TRAIN_LOSS : 0.02076265362924651, VALIDATION_LOSS : 0.04414776340126991\n",
            "FOLD : 3, EPOCH : 17, TRAIN_LOSS : 0.02078963571081036, VALIDATION_LOSS : 0.04771229699254036\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 0, TRAIN_LOSS : 0.2933626645489743, VALIDATION_LOSS : 0.15758065283298492\n",
            "FOLD : 4, EPOCH : 1, TRAIN_LOSS : 0.04300328618601749, VALIDATION_LOSS : 0.04473458901047707\n",
            "FOLD : 4, EPOCH : 2, TRAIN_LOSS : 0.027730109758282964, VALIDATION_LOSS : 0.043103355914354324\n",
            "FOLD : 4, EPOCH : 3, TRAIN_LOSS : 0.025041064835692708, VALIDATION_LOSS : 0.032555441558361056\n",
            "FOLD : 4, EPOCH : 4, TRAIN_LOSS : 0.02397794835269451, VALIDATION_LOSS : 0.027066540718078614\n",
            "FOLD : 4, EPOCH : 5, TRAIN_LOSS : 0.02325794296829324, VALIDATION_LOSS : 0.02583923377096653\n",
            "FOLD : 4, EPOCH : 6, TRAIN_LOSS : 0.022710343626768964, VALIDATION_LOSS : 0.025806159898638725\n",
            "FOLD : 4, EPOCH : 7, TRAIN_LOSS : 0.022217773979431706, VALIDATION_LOSS : 0.025963082537055017\n",
            "FOLD : 4, EPOCH : 8, TRAIN_LOSS : 0.021859462323941682, VALIDATION_LOSS : 0.027262550964951515\n",
            "FOLD : 4, EPOCH : 9, TRAIN_LOSS : 0.02158733604377822, VALIDATION_LOSS : 0.027695467695593834\n",
            "FOLD : 4, EPOCH : 10, TRAIN_LOSS : 0.021401232598643554, VALIDATION_LOSS : 0.029421190172433852\n",
            "FOLD : 4, EPOCH : 11, TRAIN_LOSS : 0.02121673161654096, VALIDATION_LOSS : 0.03305046111345291\n",
            "FOLD : 4, EPOCH : 12, TRAIN_LOSS : 0.021124605579595817, VALIDATION_LOSS : 0.03770570382475853\n",
            "FOLD : 4, EPOCH : 13, TRAIN_LOSS : 0.021015293504062452, VALIDATION_LOSS : 0.046005716919898985\n",
            "FOLD : 4, EPOCH : 14, TRAIN_LOSS : 0.02089555355671205, VALIDATION_LOSS : 0.0474669486284256\n",
            "FOLD : 4, EPOCH : 15, TRAIN_LOSS : 0.020799124515370318, VALIDATION_LOSS : 0.060820122808218004\n",
            "FOLD : 4, EPOCH : 16, TRAIN_LOSS : 0.02074013052410201, VALIDATION_LOSS : 0.06174643114209175\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-11-01 14:45:44,648]\u001b[0m Trial 3 finished with value: 0.027191719263792036 and parameters: {'num_layers': 7, 'hidden_size': 821, 'dropout': 0.5860100922357673, 'learning_rate': 0.0005616076447883366}. Best is trial 2 with value: 0.015677723363041875.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 17, TRAIN_LOSS : 0.020718488646181005, VALIDATION_LOSS : 0.06553540974855424\n",
            "Best trial: \n",
            "[0.015677723363041875]\n",
            "{'num_layers': 2, 'hidden_size': 1272, 'dropout': 0.6761963193393893, 'learning_rate': 0.0009095634508804573}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 0, EPOCH : 0, TRAIN_LOSS : 0.15795078981471689, VALIDATION_LOSS : 0.1812789887189865\n",
            "FOLD : 0, EPOCH : 1, TRAIN_LOSS : 0.022748822248295733, VALIDATION_LOSS : 0.0884871944785118\n",
            "FOLD : 0, EPOCH : 2, TRAIN_LOSS : 0.021283002472237536, VALIDATION_LOSS : 0.08623944371938705\n",
            "FOLD : 0, EPOCH : 3, TRAIN_LOSS : 0.020504420721217206, VALIDATION_LOSS : 0.05425342172384262\n",
            "FOLD : 0, EPOCH : 4, TRAIN_LOSS : 0.020039148530677744, VALIDATION_LOSS : 0.0690152332186699\n",
            "FOLD : 0, EPOCH : 5, TRAIN_LOSS : 0.019759347172159897, VALIDATION_LOSS : 0.056414347141981125\n",
            "FOLD : 0, EPOCH : 6, TRAIN_LOSS : 0.019399544224143028, VALIDATION_LOSS : 0.048364656418561934\n",
            "FOLD : 0, EPOCH : 7, TRAIN_LOSS : 0.01910681748076489, VALIDATION_LOSS : 0.043444673717021945\n",
            "FOLD : 0, EPOCH : 8, TRAIN_LOSS : 0.018779676897745384, VALIDATION_LOSS : 0.037227227538824084\n",
            "FOLD : 0, EPOCH : 9, TRAIN_LOSS : 0.0184721297731525, VALIDATION_LOSS : 0.03577036410570145\n",
            "FOLD : 0, EPOCH : 10, TRAIN_LOSS : 0.018256823777368193, VALIDATION_LOSS : 0.03231059014797211\n",
            "FOLD : 0, EPOCH : 11, TRAIN_LOSS : 0.01806425224793585, VALIDATION_LOSS : 0.03112959340214729\n",
            "FOLD : 0, EPOCH : 12, TRAIN_LOSS : 0.017814422124310544, VALIDATION_LOSS : 0.02912185750901699\n",
            "FOLD : 0, EPOCH : 13, TRAIN_LOSS : 0.017700750870924247, VALIDATION_LOSS : 0.02819673754274845\n",
            "FOLD : 0, EPOCH : 14, TRAIN_LOSS : 0.01746478519941631, VALIDATION_LOSS : 0.025529009103775025\n",
            "FOLD : 0, EPOCH : 15, TRAIN_LOSS : 0.017348955728505786, VALIDATION_LOSS : 0.023990536108613014\n",
            "FOLD : 0, EPOCH : 16, TRAIN_LOSS : 0.017185058150636524, VALIDATION_LOSS : 0.02269621826708317\n",
            "FOLD : 0, EPOCH : 17, TRAIN_LOSS : 0.016987167886997525, VALIDATION_LOSS : 0.020933881029486658\n",
            "FOLD : 0, EPOCH : 18, TRAIN_LOSS : 0.016920306474754686, VALIDATION_LOSS : 0.022233734652400017\n",
            "FOLD : 0, EPOCH : 19, TRAIN_LOSS : 0.01680036300891324, VALIDATION_LOSS : 0.0207746934145689\n",
            "FOLD : 0, EPOCH : 20, TRAIN_LOSS : 0.016684584711727343, VALIDATION_LOSS : 0.020201636478304863\n",
            "FOLD : 0, EPOCH : 21, TRAIN_LOSS : 0.016591576467219152, VALIDATION_LOSS : 0.019831613823771476\n",
            "FOLD : 0, EPOCH : 22, TRAIN_LOSS : 0.01646982260832661, VALIDATION_LOSS : 0.018990515172481535\n",
            "FOLD : 0, EPOCH : 23, TRAIN_LOSS : 0.016360865513745108, VALIDATION_LOSS : 0.01888773515820503\n",
            "FOLD : 0, EPOCH : 24, TRAIN_LOSS : 0.01628853429697062, VALIDATION_LOSS : 0.018315631523728372\n",
            "FOLD : 0, EPOCH : 25, TRAIN_LOSS : 0.016139159763329906, VALIDATION_LOSS : 0.01797110289335251\n",
            "FOLD : 0, EPOCH : 26, TRAIN_LOSS : 0.016041145022762448, VALIDATION_LOSS : 0.01780126094818115\n",
            "FOLD : 0, EPOCH : 27, TRAIN_LOSS : 0.0159562268343411, VALIDATION_LOSS : 0.017514992505311966\n",
            "FOLD : 0, EPOCH : 28, TRAIN_LOSS : 0.015906853846421366, VALIDATION_LOSS : 0.01730736568570137\n",
            "FOLD : 0, EPOCH : 29, TRAIN_LOSS : 0.01581787886588197, VALIDATION_LOSS : 0.017423248663544656\n",
            "FOLD : 0, EPOCH : 30, TRAIN_LOSS : 0.01573375009588505, VALIDATION_LOSS : 0.016788163036108018\n",
            "FOLD : 0, EPOCH : 31, TRAIN_LOSS : 0.015669607851458222, VALIDATION_LOSS : 0.016763683408498764\n",
            "FOLD : 0, EPOCH : 32, TRAIN_LOSS : 0.015520181604906133, VALIDATION_LOSS : 0.016837501153349876\n",
            "FOLD : 0, EPOCH : 33, TRAIN_LOSS : 0.015499419728784184, VALIDATION_LOSS : 0.016592806950211526\n",
            "FOLD : 0, EPOCH : 34, TRAIN_LOSS : 0.015390490034693166, VALIDATION_LOSS : 0.016519856452941895\n",
            "FOLD : 0, EPOCH : 35, TRAIN_LOSS : 0.01533803554545892, VALIDATION_LOSS : 0.01646745763719082\n",
            "FOLD : 0, EPOCH : 36, TRAIN_LOSS : 0.01530117007266534, VALIDATION_LOSS : 0.01631408669054508\n",
            "FOLD : 0, EPOCH : 37, TRAIN_LOSS : 0.015168101722864728, VALIDATION_LOSS : 0.01634931154549122\n",
            "FOLD : 0, EPOCH : 38, TRAIN_LOSS : 0.015079848174201814, VALIDATION_LOSS : 0.016253513842821123\n",
            "FOLD : 0, EPOCH : 39, TRAIN_LOSS : 0.015077141750799982, VALIDATION_LOSS : 0.01621609218418598\n",
            "FOLD : 0, EPOCH : 40, TRAIN_LOSS : 0.015008422742156606, VALIDATION_LOSS : 0.01617303192615509\n",
            "FOLD : 0, EPOCH : 41, TRAIN_LOSS : 0.0148818252706214, VALIDATION_LOSS : 0.016017601266503333\n",
            "FOLD : 0, EPOCH : 42, TRAIN_LOSS : 0.014817326525716405, VALIDATION_LOSS : 0.016026143729686738\n",
            "FOLD : 0, EPOCH : 43, TRAIN_LOSS : 0.014748456446748031, VALIDATION_LOSS : 0.01603166349232197\n",
            "FOLD : 0, EPOCH : 44, TRAIN_LOSS : 0.014649726450443268, VALIDATION_LOSS : 0.015963136777281763\n",
            "FOLD : 0, EPOCH : 45, TRAIN_LOSS : 0.014686241255779015, VALIDATION_LOSS : 0.015888942033052446\n",
            "FOLD : 0, EPOCH : 46, TRAIN_LOSS : 0.014543020411541588, VALIDATION_LOSS : 0.015887967310845852\n",
            "FOLD : 0, EPOCH : 47, TRAIN_LOSS : 0.014497467561771995, VALIDATION_LOSS : 0.015900466963648795\n",
            "FOLD : 0, EPOCH : 48, TRAIN_LOSS : 0.014395880856012044, VALIDATION_LOSS : 0.01590153630822897\n",
            "FOLD : 0, EPOCH : 49, TRAIN_LOSS : 0.014323643555766657, VALIDATION_LOSS : 0.015881554596126078\n",
            "FOLD : 0, EPOCH : 50, TRAIN_LOSS : 0.014285977439660775, VALIDATION_LOSS : 0.01591678038239479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 1, EPOCH : 0, TRAIN_LOSS : 0.15825895749424634, VALIDATION_LOSS : 0.20093975961208344\n",
            "FOLD : 1, EPOCH : 1, TRAIN_LOSS : 0.022558587456220074, VALIDATION_LOSS : 0.08933288753032684\n",
            "FOLD : 1, EPOCH : 2, TRAIN_LOSS : 0.021230383138907582, VALIDATION_LOSS : 0.06513268351554871\n",
            "FOLD : 1, EPOCH : 3, TRAIN_LOSS : 0.02046709880232811, VALIDATION_LOSS : 0.04738219827413559\n",
            "FOLD : 1, EPOCH : 4, TRAIN_LOSS : 0.020060329649009202, VALIDATION_LOSS : 0.053177923709154126\n",
            "FOLD : 1, EPOCH : 5, TRAIN_LOSS : 0.019716942682862282, VALIDATION_LOSS : 0.05423742607235908\n",
            "FOLD : 1, EPOCH : 6, TRAIN_LOSS : 0.019369211145921758, VALIDATION_LOSS : 0.04637903794646263\n",
            "FOLD : 1, EPOCH : 7, TRAIN_LOSS : 0.019017769611979787, VALIDATION_LOSS : 0.03788623288273811\n",
            "FOLD : 1, EPOCH : 8, TRAIN_LOSS : 0.0187127170594115, VALIDATION_LOSS : 0.03587283045053482\n",
            "FOLD : 1, EPOCH : 9, TRAIN_LOSS : 0.018468066559810387, VALIDATION_LOSS : 0.03588520511984825\n",
            "FOLD : 1, EPOCH : 10, TRAIN_LOSS : 0.018216266639922794, VALIDATION_LOSS : 0.03363835662603378\n",
            "FOLD : 1, EPOCH : 11, TRAIN_LOSS : 0.017984306243689435, VALIDATION_LOSS : 0.03251788318157196\n",
            "FOLD : 1, EPOCH : 12, TRAIN_LOSS : 0.017786193148870217, VALIDATION_LOSS : 0.02999960966408253\n",
            "FOLD : 1, EPOCH : 13, TRAIN_LOSS : 0.017606508084817937, VALIDATION_LOSS : 0.02704581804573536\n",
            "FOLD : 1, EPOCH : 14, TRAIN_LOSS : 0.017432180184282754, VALIDATION_LOSS : 0.024257250502705573\n",
            "FOLD : 1, EPOCH : 15, TRAIN_LOSS : 0.01734890828007146, VALIDATION_LOSS : 0.02236363962292671\n",
            "FOLD : 1, EPOCH : 16, TRAIN_LOSS : 0.01717743434404072, VALIDATION_LOSS : 0.022554215788841248\n",
            "FOLD : 1, EPOCH : 17, TRAIN_LOSS : 0.01704451451568227, VALIDATION_LOSS : 0.022161927074193954\n",
            "FOLD : 1, EPOCH : 18, TRAIN_LOSS : 0.016917198406238305, VALIDATION_LOSS : 0.020110319554805755\n",
            "FOLD : 1, EPOCH : 19, TRAIN_LOSS : 0.01681467439783247, VALIDATION_LOSS : 0.019512777775526048\n",
            "FOLD : 1, EPOCH : 20, TRAIN_LOSS : 0.016655342604376767, VALIDATION_LOSS : 0.01909284070134163\n",
            "FOLD : 1, EPOCH : 21, TRAIN_LOSS : 0.016594950992025827, VALIDATION_LOSS : 0.01895993947982788\n",
            "FOLD : 1, EPOCH : 22, TRAIN_LOSS : 0.016481351107358932, VALIDATION_LOSS : 0.018746711686253546\n",
            "FOLD : 1, EPOCH : 23, TRAIN_LOSS : 0.01637572653003429, VALIDATION_LOSS : 0.018379838764667512\n",
            "FOLD : 1, EPOCH : 24, TRAIN_LOSS : 0.016256588413135, VALIDATION_LOSS : 0.01795511357486248\n",
            "FOLD : 1, EPOCH : 25, TRAIN_LOSS : 0.016135028220321004, VALIDATION_LOSS : 0.01772371754050255\n",
            "FOLD : 1, EPOCH : 26, TRAIN_LOSS : 0.016033954918384552, VALIDATION_LOSS : 0.017460643872618677\n",
            "FOLD : 1, EPOCH : 27, TRAIN_LOSS : 0.015930873979079097, VALIDATION_LOSS : 0.017210594937205316\n",
            "FOLD : 1, EPOCH : 28, TRAIN_LOSS : 0.015910280182173376, VALIDATION_LOSS : 0.017004832997918128\n",
            "FOLD : 1, EPOCH : 29, TRAIN_LOSS : 0.0157913047036058, VALIDATION_LOSS : 0.016809719428420068\n",
            "FOLD : 1, EPOCH : 30, TRAIN_LOSS : 0.015719703839797722, VALIDATION_LOSS : 0.016584868356585503\n",
            "FOLD : 1, EPOCH : 31, TRAIN_LOSS : 0.015608812976432474, VALIDATION_LOSS : 0.016457049921154977\n",
            "FOLD : 1, EPOCH : 32, TRAIN_LOSS : 0.015615939554807386, VALIDATION_LOSS : 0.01637565754354\n",
            "FOLD : 1, EPOCH : 33, TRAIN_LOSS : 0.015490069201118067, VALIDATION_LOSS : 0.016203249618411065\n",
            "FOLD : 1, EPOCH : 34, TRAIN_LOSS : 0.015419754199683666, VALIDATION_LOSS : 0.016148176789283753\n",
            "FOLD : 1, EPOCH : 35, TRAIN_LOSS : 0.015319233466135828, VALIDATION_LOSS : 0.01620499901473522\n",
            "FOLD : 1, EPOCH : 36, TRAIN_LOSS : 0.015247454572665064, VALIDATION_LOSS : 0.016010768339037897\n",
            "FOLD : 1, EPOCH : 37, TRAIN_LOSS : 0.015201692910570847, VALIDATION_LOSS : 0.01594771072268486\n",
            "FOLD : 1, EPOCH : 38, TRAIN_LOSS : 0.015139387577380004, VALIDATION_LOSS : 0.015924417600035667\n",
            "FOLD : 1, EPOCH : 39, TRAIN_LOSS : 0.015011311312647243, VALIDATION_LOSS : 0.01583721898496151\n",
            "FOLD : 1, EPOCH : 40, TRAIN_LOSS : 0.014962321784543363, VALIDATION_LOSS : 0.01583217494189739\n",
            "FOLD : 1, EPOCH : 41, TRAIN_LOSS : 0.014868498779833317, VALIDATION_LOSS : 0.015747728385031225\n",
            "FOLD : 1, EPOCH : 42, TRAIN_LOSS : 0.01483168109859291, VALIDATION_LOSS : 0.015788206830620766\n",
            "FOLD : 1, EPOCH : 43, TRAIN_LOSS : 0.014733727580230487, VALIDATION_LOSS : 0.01568922884762287\n",
            "FOLD : 1, EPOCH : 44, TRAIN_LOSS : 0.014690242609695384, VALIDATION_LOSS : 0.015654179640114306\n",
            "FOLD : 1, EPOCH : 45, TRAIN_LOSS : 0.014614890917743506, VALIDATION_LOSS : 0.015670044347643852\n",
            "FOLD : 1, EPOCH : 46, TRAIN_LOSS : 0.014504804913150636, VALIDATION_LOSS : 0.015609415620565415\n",
            "FOLD : 1, EPOCH : 47, TRAIN_LOSS : 0.014468461275100708, VALIDATION_LOSS : 0.015580954402685166\n",
            "FOLD : 1, EPOCH : 48, TRAIN_LOSS : 0.014407890554713575, VALIDATION_LOSS : 0.015577845089137555\n",
            "FOLD : 1, EPOCH : 49, TRAIN_LOSS : 0.014351576958831987, VALIDATION_LOSS : 0.015544552356004715\n",
            "FOLD : 1, EPOCH : 50, TRAIN_LOSS : 0.014258890755866704, VALIDATION_LOSS : 0.015543647296726703\n",
            "FOLD : 1, EPOCH : 51, TRAIN_LOSS : 0.014242413600808695, VALIDATION_LOSS : 0.015539765916764736\n",
            "FOLD : 1, EPOCH : 52, TRAIN_LOSS : 0.014167941518520055, VALIDATION_LOSS : 0.015519093722105026\n",
            "FOLD : 1, EPOCH : 53, TRAIN_LOSS : 0.014114512277669028, VALIDATION_LOSS : 0.015560981072485446\n",
            "FOLD : 1, EPOCH : 54, TRAIN_LOSS : 0.014061642320532548, VALIDATION_LOSS : 0.015504405088722705\n",
            "FOLD : 1, EPOCH : 55, TRAIN_LOSS : 0.014029903876546183, VALIDATION_LOSS : 0.015507486835122108\n",
            "FOLD : 1, EPOCH : 56, TRAIN_LOSS : 0.01393463634150593, VALIDATION_LOSS : 0.015492813847959041\n",
            "FOLD : 1, EPOCH : 57, TRAIN_LOSS : 0.013882898921637158, VALIDATION_LOSS : 0.01553503293544054\n",
            "FOLD : 1, EPOCH : 58, TRAIN_LOSS : 0.013846113444551042, VALIDATION_LOSS : 0.015534738637506961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 2, EPOCH : 0, TRAIN_LOSS : 0.15632270472614387, VALIDATION_LOSS : 0.17744550108909607\n",
            "FOLD : 2, EPOCH : 1, TRAIN_LOSS : 0.022731197311689978, VALIDATION_LOSS : 0.07453968673944474\n",
            "FOLD : 2, EPOCH : 2, TRAIN_LOSS : 0.02137107627564355, VALIDATION_LOSS : 0.08487599641084671\n",
            "FOLD : 2, EPOCH : 3, TRAIN_LOSS : 0.020549028621692406, VALIDATION_LOSS : 0.05417899563908577\n",
            "FOLD : 2, EPOCH : 4, TRAIN_LOSS : 0.0200641268962308, VALIDATION_LOSS : 0.058543752133846286\n",
            "FOLD : 2, EPOCH : 5, TRAIN_LOSS : 0.019748192966768618, VALIDATION_LOSS : 0.06119646802544594\n",
            "FOLD : 2, EPOCH : 6, TRAIN_LOSS : 0.01946859395033435, VALIDATION_LOSS : 0.055536966770887375\n",
            "FOLD : 2, EPOCH : 7, TRAIN_LOSS : 0.0191166019557338, VALIDATION_LOSS : 0.04772274121642113\n",
            "FOLD : 2, EPOCH : 8, TRAIN_LOSS : 0.018816347969205754, VALIDATION_LOSS : 0.04568613916635513\n",
            "FOLD : 2, EPOCH : 9, TRAIN_LOSS : 0.018504781060312923, VALIDATION_LOSS : 0.036514962464571\n",
            "FOLD : 2, EPOCH : 10, TRAIN_LOSS : 0.01827210668278368, VALIDATION_LOSS : 0.03493516519665718\n",
            "FOLD : 2, EPOCH : 11, TRAIN_LOSS : 0.018077978178074484, VALIDATION_LOSS : 0.031516721844673155\n",
            "FOLD : 2, EPOCH : 12, TRAIN_LOSS : 0.01790080003832516, VALIDATION_LOSS : 0.028371371701359747\n",
            "FOLD : 2, EPOCH : 13, TRAIN_LOSS : 0.017619583265561806, VALIDATION_LOSS : 0.028255086019635202\n",
            "FOLD : 2, EPOCH : 14, TRAIN_LOSS : 0.017508030525947873, VALIDATION_LOSS : 0.02653317078948021\n",
            "FOLD : 2, EPOCH : 15, TRAIN_LOSS : 0.01734157298740588, VALIDATION_LOSS : 0.023707248643040656\n",
            "FOLD : 2, EPOCH : 16, TRAIN_LOSS : 0.017219176025767075, VALIDATION_LOSS : 0.023767638579010965\n",
            "FOLD : 2, EPOCH : 17, TRAIN_LOSS : 0.01704954659860385, VALIDATION_LOSS : 0.02224530354142189\n",
            "FOLD : 2, EPOCH : 18, TRAIN_LOSS : 0.016943702964406265, VALIDATION_LOSS : 0.020818060263991356\n",
            "FOLD : 2, EPOCH : 19, TRAIN_LOSS : 0.016769338889341606, VALIDATION_LOSS : 0.01987641118466854\n",
            "FOLD : 2, EPOCH : 20, TRAIN_LOSS : 0.016638917652399915, VALIDATION_LOSS : 0.01952604204416275\n",
            "FOLD : 2, EPOCH : 21, TRAIN_LOSS : 0.016569077086291815, VALIDATION_LOSS : 0.019019221141934394\n",
            "FOLD : 2, EPOCH : 22, TRAIN_LOSS : 0.016507849097251892, VALIDATION_LOSS : 0.01873486414551735\n",
            "FOLD : 2, EPOCH : 23, TRAIN_LOSS : 0.016375426693182243, VALIDATION_LOSS : 0.018413452431559563\n",
            "FOLD : 2, EPOCH : 24, TRAIN_LOSS : 0.016265917765466792, VALIDATION_LOSS : 0.017804297804832458\n",
            "FOLD : 2, EPOCH : 25, TRAIN_LOSS : 0.016205585561692715, VALIDATION_LOSS : 0.017832636088132858\n",
            "FOLD : 2, EPOCH : 26, TRAIN_LOSS : 0.016042682881418028, VALIDATION_LOSS : 0.01731535606086254\n",
            "FOLD : 2, EPOCH : 27, TRAIN_LOSS : 0.016022947126705395, VALIDATION_LOSS : 0.01717299595475197\n",
            "FOLD : 2, EPOCH : 28, TRAIN_LOSS : 0.01592848523470916, VALIDATION_LOSS : 0.016882364079356192\n",
            "FOLD : 2, EPOCH : 29, TRAIN_LOSS : 0.015847798632948024, VALIDATION_LOSS : 0.016981907188892365\n",
            "FOLD : 2, EPOCH : 30, TRAIN_LOSS : 0.015702806805309496, VALIDATION_LOSS : 0.016590721905231476\n",
            "FOLD : 2, EPOCH : 31, TRAIN_LOSS : 0.015684984134216057, VALIDATION_LOSS : 0.016594483703374862\n",
            "FOLD : 2, EPOCH : 32, TRAIN_LOSS : 0.015580285438581518, VALIDATION_LOSS : 0.016615772619843483\n",
            "FOLD : 2, EPOCH : 33, TRAIN_LOSS : 0.015464448909226217, VALIDATION_LOSS : 0.016355619579553605\n",
            "FOLD : 2, EPOCH : 34, TRAIN_LOSS : 0.015401219164854601, VALIDATION_LOSS : 0.01641102023422718\n",
            "FOLD : 2, EPOCH : 35, TRAIN_LOSS : 0.015309106754629235, VALIDATION_LOSS : 0.016262127831578255\n",
            "FOLD : 2, EPOCH : 36, TRAIN_LOSS : 0.015253983438014984, VALIDATION_LOSS : 0.01619112230837345\n",
            "FOLD : 2, EPOCH : 37, TRAIN_LOSS : 0.015131301001498574, VALIDATION_LOSS : 0.01616148240864277\n",
            "FOLD : 2, EPOCH : 38, TRAIN_LOSS : 0.015128181413992456, VALIDATION_LOSS : 0.016034923493862152\n",
            "FOLD : 2, EPOCH : 39, TRAIN_LOSS : 0.01501870473944827, VALIDATION_LOSS : 0.015978139638900758\n",
            "FOLD : 2, EPOCH : 40, TRAIN_LOSS : 0.014962308059789632, VALIDATION_LOSS : 0.01590094044804573\n",
            "FOLD : 2, EPOCH : 41, TRAIN_LOSS : 0.014904103879081575, VALIDATION_LOSS : 0.015939322113990784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 3, EPOCH : 0, TRAIN_LOSS : 0.15870020430731147, VALIDATION_LOSS : 0.19400401711463927\n",
            "FOLD : 3, EPOCH : 1, TRAIN_LOSS : 0.0227673728215067, VALIDATION_LOSS : 0.07523739486932754\n",
            "FOLD : 3, EPOCH : 2, TRAIN_LOSS : 0.02123340915300344, VALIDATION_LOSS : 0.0754309356212616\n",
            "FOLD : 3, EPOCH : 3, TRAIN_LOSS : 0.02047009766101837, VALIDATION_LOSS : 0.05876034274697304\n",
            "FOLD : 3, EPOCH : 4, TRAIN_LOSS : 0.02007108524833855, VALIDATION_LOSS : 0.04700796976685524\n",
            "FOLD : 3, EPOCH : 5, TRAIN_LOSS : 0.01974183330802541, VALIDATION_LOSS : 0.04910018220543862\n",
            "FOLD : 3, EPOCH : 6, TRAIN_LOSS : 0.019328253245667407, VALIDATION_LOSS : 0.049600125104188916\n",
            "FOLD : 3, EPOCH : 7, TRAIN_LOSS : 0.019065940360489645, VALIDATION_LOSS : 0.04316105768084526\n",
            "FOLD : 3, EPOCH : 8, TRAIN_LOSS : 0.018784207929121822, VALIDATION_LOSS : 0.039908699691295624\n",
            "FOLD : 3, EPOCH : 9, TRAIN_LOSS : 0.01842432704411055, VALIDATION_LOSS : 0.03450139462947845\n",
            "FOLD : 3, EPOCH : 10, TRAIN_LOSS : 0.018256490854056256, VALIDATION_LOSS : 0.030154716596007346\n",
            "FOLD : 3, EPOCH : 11, TRAIN_LOSS : 0.01802991075735343, VALIDATION_LOSS : 0.02739870399236679\n",
            "FOLD : 3, EPOCH : 12, TRAIN_LOSS : 0.017886001812784297, VALIDATION_LOSS : 0.027759544551372528\n",
            "FOLD : 3, EPOCH : 13, TRAIN_LOSS : 0.01766524463891983, VALIDATION_LOSS : 0.029001956805586815\n",
            "FOLD : 3, EPOCH : 14, TRAIN_LOSS : 0.017452439195231387, VALIDATION_LOSS : 0.025198701396584512\n",
            "FOLD : 3, EPOCH : 15, TRAIN_LOSS : 0.017297872685288127, VALIDATION_LOSS : 0.023253031075000763\n",
            "FOLD : 3, EPOCH : 16, TRAIN_LOSS : 0.017160864644928983, VALIDATION_LOSS : 0.020853089913725854\n",
            "FOLD : 3, EPOCH : 17, TRAIN_LOSS : 0.017043035085264006, VALIDATION_LOSS : 0.0203199177980423\n",
            "FOLD : 3, EPOCH : 18, TRAIN_LOSS : 0.0168899309478308, VALIDATION_LOSS : 0.020159202069044112\n",
            "FOLD : 3, EPOCH : 19, TRAIN_LOSS : 0.01674232200572365, VALIDATION_LOSS : 0.02004757709801197\n",
            "FOLD : 3, EPOCH : 20, TRAIN_LOSS : 0.016641037048477875, VALIDATION_LOSS : 0.019291677698493003\n",
            "FOLD : 3, EPOCH : 21, TRAIN_LOSS : 0.016498914282572896, VALIDATION_LOSS : 0.019100483134388925\n",
            "FOLD : 3, EPOCH : 22, TRAIN_LOSS : 0.016417089065438824, VALIDATION_LOSS : 0.018391256034374238\n",
            "FOLD : 3, EPOCH : 23, TRAIN_LOSS : 0.016307158542698937, VALIDATION_LOSS : 0.01797802299261093\n",
            "FOLD : 3, EPOCH : 24, TRAIN_LOSS : 0.016244960899807905, VALIDATION_LOSS : 0.01765974424779415\n",
            "FOLD : 3, EPOCH : 25, TRAIN_LOSS : 0.01616901821015697, VALIDATION_LOSS : 0.017598573490977286\n",
            "FOLD : 3, EPOCH : 26, TRAIN_LOSS : 0.01598405842914393, VALIDATION_LOSS : 0.017241936549544333\n",
            "FOLD : 3, EPOCH : 27, TRAIN_LOSS : 0.015958696260656182, VALIDATION_LOSS : 0.016934097930788993\n",
            "FOLD : 3, EPOCH : 28, TRAIN_LOSS : 0.015841086444101836, VALIDATION_LOSS : 0.016930225491523742\n",
            "FOLD : 3, EPOCH : 29, TRAIN_LOSS : 0.015736017572252375, VALIDATION_LOSS : 0.016706200316548347\n",
            "FOLD : 3, EPOCH : 30, TRAIN_LOSS : 0.01568341304204966, VALIDATION_LOSS : 0.01656631864607334\n",
            "FOLD : 3, EPOCH : 31, TRAIN_LOSS : 0.01555176383178485, VALIDATION_LOSS : 0.016697171330451965\n",
            "FOLD : 3, EPOCH : 32, TRAIN_LOSS : 0.01551803108304739, VALIDATION_LOSS : 0.016323264688253403\n",
            "FOLD : 3, EPOCH : 33, TRAIN_LOSS : 0.015421557240188122, VALIDATION_LOSS : 0.01627369746565819\n",
            "FOLD : 3, EPOCH : 34, TRAIN_LOSS : 0.01534929092189199, VALIDATION_LOSS : 0.016214879974722863\n",
            "FOLD : 3, EPOCH : 35, TRAIN_LOSS : 0.015250304027607567, VALIDATION_LOSS : 0.016104980930686\n",
            "FOLD : 3, EPOCH : 36, TRAIN_LOSS : 0.015168987263582255, VALIDATION_LOSS : 0.01613316237926483\n",
            "FOLD : 3, EPOCH : 37, TRAIN_LOSS : 0.015113633077003454, VALIDATION_LOSS : 0.016028616204857828\n",
            "FOLD : 3, EPOCH : 38, TRAIN_LOSS : 0.01508365546990382, VALIDATION_LOSS : 0.01597360074520111\n",
            "FOLD : 3, EPOCH : 39, TRAIN_LOSS : 0.01493699662387371, VALIDATION_LOSS : 0.015942992642521858\n",
            "FOLD : 3, EPOCH : 40, TRAIN_LOSS : 0.014912366720014497, VALIDATION_LOSS : 0.01595545597374439\n",
            "FOLD : 3, EPOCH : 41, TRAIN_LOSS : 0.014841798300805845, VALIDATION_LOSS : 0.015874005481600763\n",
            "FOLD : 3, EPOCH : 42, TRAIN_LOSS : 0.014740331000403353, VALIDATION_LOSS : 0.015862849354743958\n",
            "FOLD : 3, EPOCH : 43, TRAIN_LOSS : 0.01470807557435412, VALIDATION_LOSS : 0.015852391347289087\n",
            "FOLD : 3, EPOCH : 44, TRAIN_LOSS : 0.014662166273123339, VALIDATION_LOSS : 0.015838195756077766\n",
            "FOLD : 3, EPOCH : 45, TRAIN_LOSS : 0.014557229845147384, VALIDATION_LOSS : 0.015824411809444428\n",
            "FOLD : 3, EPOCH : 46, TRAIN_LOSS : 0.014550790827917425, VALIDATION_LOSS : 0.015752326138317584\n",
            "FOLD : 3, EPOCH : 47, TRAIN_LOSS : 0.014405140947354468, VALIDATION_LOSS : 0.01576022747904062\n",
            "FOLD : 3, EPOCH : 48, TRAIN_LOSS : 0.014415182957523748, VALIDATION_LOSS : 0.01576325986534357\n",
            "FOLD : 3, EPOCH : 49, TRAIN_LOSS : 0.014350371239216704, VALIDATION_LOSS : 0.015739541873335837\n",
            "FOLD : 3, EPOCH : 50, TRAIN_LOSS : 0.014231050239973947, VALIDATION_LOSS : 0.015764728002250195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning:\n",
            "\n",
            "This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FOLD : 4, EPOCH : 0, TRAIN_LOSS : 0.15769445327551743, VALIDATION_LOSS : 0.22202714383602143\n",
            "FOLD : 4, EPOCH : 1, TRAIN_LOSS : 0.022735428947367166, VALIDATION_LOSS : 0.09433613121509551\n",
            "FOLD : 4, EPOCH : 2, TRAIN_LOSS : 0.021278662999209604, VALIDATION_LOSS : 0.07304844111204148\n",
            "FOLD : 4, EPOCH : 3, TRAIN_LOSS : 0.020517781572906596, VALIDATION_LOSS : 0.050241556763648984\n",
            "FOLD : 4, EPOCH : 4, TRAIN_LOSS : 0.02004499106030715, VALIDATION_LOSS : 0.05904196947813034\n",
            "FOLD : 4, EPOCH : 5, TRAIN_LOSS : 0.01977852888797459, VALIDATION_LOSS : 0.05036391094326973\n",
            "FOLD : 4, EPOCH : 6, TRAIN_LOSS : 0.01939354680086437, VALIDATION_LOSS : 0.04645088762044906\n",
            "FOLD : 4, EPOCH : 7, TRAIN_LOSS : 0.019036975934317236, VALIDATION_LOSS : 0.03880562409758568\n",
            "FOLD : 4, EPOCH : 8, TRAIN_LOSS : 0.018743264047723068, VALIDATION_LOSS : 0.0354189045727253\n",
            "FOLD : 4, EPOCH : 9, TRAIN_LOSS : 0.018479825634705394, VALIDATION_LOSS : 0.03321818709373474\n",
            "FOLD : 4, EPOCH : 10, TRAIN_LOSS : 0.018148611642812427, VALIDATION_LOSS : 0.03025185242295265\n",
            "FOLD : 4, EPOCH : 11, TRAIN_LOSS : 0.01795017856516336, VALIDATION_LOSS : 0.02692412957549095\n",
            "FOLD : 4, EPOCH : 12, TRAIN_LOSS : 0.017750311054681476, VALIDATION_LOSS : 0.026143359392881392\n",
            "FOLD : 4, EPOCH : 13, TRAIN_LOSS : 0.01754807837699589, VALIDATION_LOSS : 0.026493634283542632\n",
            "FOLD : 4, EPOCH : 14, TRAIN_LOSS : 0.01740788295865059, VALIDATION_LOSS : 0.024377842620015144\n",
            "FOLD : 4, EPOCH : 15, TRAIN_LOSS : 0.017237607977892224, VALIDATION_LOSS : 0.022264737263321878\n",
            "FOLD : 4, EPOCH : 16, TRAIN_LOSS : 0.017083527618332914, VALIDATION_LOSS : 0.022458474710583688\n",
            "FOLD : 4, EPOCH : 17, TRAIN_LOSS : 0.016900679390681416, VALIDATION_LOSS : 0.021614139527082445\n",
            "FOLD : 4, EPOCH : 18, TRAIN_LOSS : 0.01680657483245197, VALIDATION_LOSS : 0.020421373844146728\n",
            "FOLD : 4, EPOCH : 19, TRAIN_LOSS : 0.016689233775985867, VALIDATION_LOSS : 0.02070544995367527\n",
            "FOLD : 4, EPOCH : 20, TRAIN_LOSS : 0.016634651410736535, VALIDATION_LOSS : 0.019983118027448656\n",
            "FOLD : 4, EPOCH : 21, TRAIN_LOSS : 0.016455334464186115, VALIDATION_LOSS : 0.018577880784869195\n",
            "FOLD : 4, EPOCH : 22, TRAIN_LOSS : 0.016374526790490274, VALIDATION_LOSS : 0.018425095081329345\n",
            "FOLD : 4, EPOCH : 23, TRAIN_LOSS : 0.016300584826814502, VALIDATION_LOSS : 0.018300793319940566\n",
            "FOLD : 4, EPOCH : 24, TRAIN_LOSS : 0.016260508643953425, VALIDATION_LOSS : 0.0176306277513504\n",
            "FOLD : 4, EPOCH : 25, TRAIN_LOSS : 0.016059484038698047, VALIDATION_LOSS : 0.017730353772640227\n",
            "FOLD : 4, EPOCH : 26, TRAIN_LOSS : 0.0160179424442743, VALIDATION_LOSS : 0.017527611553668977\n",
            "FOLD : 4, EPOCH : 27, TRAIN_LOSS : 0.01597325469514257, VALIDATION_LOSS : 0.017166923359036447\n",
            "FOLD : 4, EPOCH : 28, TRAIN_LOSS : 0.01581829276524092, VALIDATION_LOSS : 0.016867046430706977\n",
            "FOLD : 4, EPOCH : 29, TRAIN_LOSS : 0.01576999481767416, VALIDATION_LOSS : 0.016942547634243965\n",
            "FOLD : 4, EPOCH : 30, TRAIN_LOSS : 0.015648452172938147, VALIDATION_LOSS : 0.016925355046987535\n",
            "FOLD : 4, EPOCH : 31, TRAIN_LOSS : 0.015563041903078556, VALIDATION_LOSS : 0.01656471975147724\n",
            "FOLD : 4, EPOCH : 32, TRAIN_LOSS : 0.015495085304504946, VALIDATION_LOSS : 0.01653829626739025\n",
            "FOLD : 4, EPOCH : 33, TRAIN_LOSS : 0.015415961952193788, VALIDATION_LOSS : 0.01639261357486248\n",
            "FOLD : 4, EPOCH : 34, TRAIN_LOSS : 0.015375774647844466, VALIDATION_LOSS : 0.016286753490567206\n",
            "FOLD : 4, EPOCH : 35, TRAIN_LOSS : 0.015307271313902578, VALIDATION_LOSS : 0.01633573919534683\n",
            "FOLD : 4, EPOCH : 36, TRAIN_LOSS : 0.015213150972206341, VALIDATION_LOSS : 0.016280926391482355\n",
            "FOLD : 4, EPOCH : 37, TRAIN_LOSS : 0.015105029715127066, VALIDATION_LOSS : 0.016159918159246445\n",
            "FOLD : 4, EPOCH : 38, TRAIN_LOSS : 0.015075163229515678, VALIDATION_LOSS : 0.01610603965818882\n",
            "FOLD : 4, EPOCH : 39, TRAIN_LOSS : 0.014940442811501654, VALIDATION_LOSS : 0.016084389016032218\n",
            "FOLD : 4, EPOCH : 40, TRAIN_LOSS : 0.014871962858658088, VALIDATION_LOSS : 0.01610429510474205\n",
            "FOLD : 4, EPOCH : 41, TRAIN_LOSS : 0.01479425746947527, VALIDATION_LOSS : 0.015989153087139128\n",
            "FOLD : 4, EPOCH : 42, TRAIN_LOSS : 0.014740778084256147, VALIDATION_LOSS : 0.016007321327924727\n",
            "0.01580080077052116\n"
          ]
        }
      ],
      "source": [
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "EPOCS = 100\n",
        "\n",
        "\n",
        "def run_training(fold, params, save_model=False):\n",
        "    df = pd.read_csv('/content/train_features.csv')\n",
        "    df = df.drop([\"cp_type\", \"cp_time\", \"cp_dose\"], axis=1)\n",
        "    targets_df = pd.read_csv(\"/content/train_targets_fold.csv\")\n",
        "\n",
        "    feature_cols = df.drop(\"sig_id\", axis=1).columns\n",
        "    target_cols = targets_df.drop([\"sig_id\", \"kfold\"], axis=1).columns\n",
        "\n",
        "    df = df.merge(targets_df, on=\"sig_id\", how=\"left\")\n",
        "\n",
        "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    xtrain = train_df[feature_cols].to_numpy()\n",
        "    ytrain = train_df[target_cols].to_numpy()\n",
        "\n",
        "    xvalid = valid_df[feature_cols].to_numpy()\n",
        "    yvalid = valid_df[target_cols].to_numpy()\n",
        "\n",
        "    train_dataset = MoaDataset(features=xtrain, targets=ytrain)\n",
        "    valid_dataset = MoaDataset(features=xvalid, targets=yvalid)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=1024, num_workers=8, shuffle=True\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=1024, num_workers=8\n",
        "    )\n",
        "\n",
        "    model = Model(\n",
        "        num_features=xtrain.shape[1],\n",
        "        num_targets=ytrain.shape[1],\n",
        "        num_layers=params[\"num_layers\"],\n",
        "        hidden_size=params[\"hidden_size\"],\n",
        "        dropout=params[\"dropout\"]\n",
        "    )\n",
        "\n",
        "    model.to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=params[\"learning_rate\"])\n",
        "    eng = Engine(model, optimizer=optimizer, device=DEVICE)\n",
        "\n",
        "    best_loss = np.inf\n",
        "    early_stopping_iter = 10\n",
        "    early_stopping_counter = 0\n",
        "\n",
        "    for epoch in range(EPOCS):\n",
        "        train_loss = eng.train(train_loader)\n",
        "        valid_loss = eng.evaluate(valid_loader)\n",
        "        print(f\"FOLD : {fold}, EPOCH : {epoch}, TRAIN_LOSS : {train_loss}, VALIDATION_LOSS : {valid_loss}\")\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            if save_model:\n",
        "                torch.save(model.state_dict(), f\"Model_{fold}.bin\")\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        if early_stopping_counter > early_stopping_iter:\n",
        "            break\n",
        "    return best_loss\n",
        "\n",
        "\n",
        "# Optuna functions\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 7),\n",
        "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 16, 2048),\n",
        "        \"dropout\": trial.suggest_uniform(\"dropout\", 0.1, 0.7),\n",
        "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3)\n",
        "    }\n",
        "    all_loss = []\n",
        "    for f in range(5):\n",
        "        temp_loss = run_training(f, params, save_model=False)\n",
        "        all_loss.append(temp_loss)\n",
        "\n",
        "    return np.mean(all_loss)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    study =optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(objective, n_trials=4)\n",
        "\n",
        "    print(\"Best trial: \")\n",
        "    trial_ = study.best_trial\n",
        "\n",
        "    print(trial_.values)\n",
        "    print(trial_.params)\n",
        "    scores = 0\n",
        "    for j in range(5):\n",
        "        scr = run_training(j, trial_.params, save_model=True)\n",
        "        scores += scr\n",
        "\n",
        "    print(scores / 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GbsWt6mbKTjn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello\n"
          ]
        }
      ],
      "source": [
        "print('Hello')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMdzlzLYyz/DeZACZZSc5Vq",
      "include_colab_link": true,
      "name": "GPU - MoA Optimizing_NN (using Optuna)",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
